{"segment_id": "ml::SEG::873a581320d928249609d3c07229d5af182a379c::limitation::conclusion::000", "track": "ml", "paper_id": "873a581320d928249609d3c07229d5af182a379c", "unit_id": "ml::T011", "topic_id": "T011", "year": 2023, "conference": "Conference on Empirical Methods in Natural Language Processing", "label_type": "limitation", "section": "conclusion", "span_start": 269, "span_end": 1488, "text": "demonstrated the effectiveness and current limitations of ChatGPT in different types of NLP tasks.\n\nFor example, as a powerful generalist model, on one hand, ChatGPT is good at reasoning and dialogue tasks; on the other hand, ChatGPT still faces challenges when solving specific tasks, such as sequence tagging. We hope that this study can inspire future works, such as leveraging the reasoning and dialogue capabilities of ChatGPT in NLP tasks and addressing limitations of generalist models in tasks where they currently struggle with.\n\nThis work is an empirical study on the zero-shot learning ability of ChatGPT 3 , and it has several limitations. First, due to the cost of ChatGPT, this work excludes larger-scale datasets and more task categories, which might prevent further insights. Besides, we report the best result in the corresponding paper for models that are not publicly available (e.g., PaLM) and report the result based on the best prompt found for public models, which is consistent with the previous work  (Wei et al., 2022; Kojima et al., 2022; Tay et al., 2022) . A further im-  Q: Bianca had 45 coloring books. If she gave away 6 of them, but then bought 20 more, how many would she have total?", "sentences": ["demonstrated the effectiveness and current limitations of ChatGPT in different types of NLP tasks.", "We hope that this study can inspire future works, such as leveraging the reasoning and dialogue capabilities of ChatGPT in NLP tasks and addressing limitations of generalist models in tasks where they currently struggle with.", "This work is an empirical study on the zero-shot learning ability of ChatGPT 3 , and it has several limitations."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::ad06c8a5fd292af518f878c7ced132b61739cdd8::limitation::conclusion::000", "track": "ml", "paper_id": "ad06c8a5fd292af518f878c7ced132b61739cdd8", "unit_id": "ml::T011", "topic_id": "T011", "year": 2024, "conference": "Artificial Intelligence Review", "label_type": "limitation", "section": "conclusion", "span_start": 0, "span_end": 2156, "text": "CNN has made impressive strides, particularly in image processing and video-related tasks, which has rekindled interest in deep learning among academics. Several studies have been done in this context to enhance CNN's performance, including activation, optimization, regularization, and innovations in architecture. This paper reviews the research progress of CNN architecture in computer vision, especially in image classification, target detection, and video prediction. In addition, this paper also covers the fundamental elements of CNN, its applications, challenges, and future directions. We have shown that CNN outperforms classical methods when it comes to classification, detection, and prediction. Through exploiting depth and other structural modifications, CNN's learning performance has dramatically improved over time. According to recent literature, the increase in CNN performance is primarily attributable to the replacement of the conventional layer structure with blocks. The function of an auxiliary learner can be performed by a block in a network. These additional learners leverage spatial or feature-map information or even enhance input channels to increase performance. Additionally, modular learning is supported by CNN's block-based design, which makes the structure easier to grasp. As a review, this paper will inevitably suffer from the following shortcomings: First, it is limited by the scope of literature and time, resulting in the failure to comprehensively cover all relevant research work. Research on certain emerging areas or specific application scenarios may fail to be covered, and there are certain research blind spots. Second, considering the influence of subjectivity, we realize that the review may be influenced by the subjective judgment of the authors, which may have a certain impact on the objectivity of the research area. As a result, in future studies, we will need to sift through the relevant literature more thoroughly and deal with the subjective factors more cautiously in order to comprehend and investigate the application of CNN in computer vision in a more comprehensive and in-depth manner.", "sentences": ["As a review, this paper will inevitably suffer from the following shortcomings: First, it is limited by the scope of literature and time, resulting in the failure to comprehensively cover all relevant research work."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::ad06c8a5fd292af518f878c7ced132b61739cdd8::future_work::conclusion::001", "track": "ml", "paper_id": "ad06c8a5fd292af518f878c7ced132b61739cdd8", "unit_id": "ml::T011", "topic_id": "T011", "year": 2024, "conference": "Artificial Intelligence Review", "label_type": "future_work", "section": "conclusion", "span_start": 0, "span_end": 2156, "text": "CNN has made impressive strides, particularly in image processing and video-related tasks, which has rekindled interest in deep learning among academics. Several studies have been done in this context to enhance CNN's performance, including activation, optimization, regularization, and innovations in architecture. This paper reviews the research progress of CNN architecture in computer vision, especially in image classification, target detection, and video prediction. In addition, this paper also covers the fundamental elements of CNN, its applications, challenges, and future directions. We have shown that CNN outperforms classical methods when it comes to classification, detection, and prediction. Through exploiting depth and other structural modifications, CNN's learning performance has dramatically improved over time. According to recent literature, the increase in CNN performance is primarily attributable to the replacement of the conventional layer structure with blocks. The function of an auxiliary learner can be performed by a block in a network. These additional learners leverage spatial or feature-map information or even enhance input channels to increase performance. Additionally, modular learning is supported by CNN's block-based design, which makes the structure easier to grasp. As a review, this paper will inevitably suffer from the following shortcomings: First, it is limited by the scope of literature and time, resulting in the failure to comprehensively cover all relevant research work. Research on certain emerging areas or specific application scenarios may fail to be covered, and there are certain research blind spots. Second, considering the influence of subjectivity, we realize that the review may be influenced by the subjective judgment of the authors, which may have a certain impact on the objectivity of the research area. As a result, in future studies, we will need to sift through the relevant literature more thoroughly and deal with the subjective factors more cautiously in order to comprehend and investigate the application of CNN in computer vision in a more comprehensive and in-depth manner.", "sentences": ["As a result, in future studies, we will need to sift through the relevant literature more thoroughly and deal with the subjective factors more cautiously in order to comprehend and investigate the application of CNN in computer vision in a more comprehensive and in-depth manner."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::c8b25fab5608c3e033d34b4483ec47e68ba109b7::contribution::introduction::000", "track": "ml", "paper_id": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "unit_id": "ml::T002", "topic_id": "T002", "year": 2021, "conference": "IEEE International Conference on Computer Vision", "label_type": "contribution", "section": "introduction", "span_start": 1258, "span_end": 3518, "text": "In this paper, we seek to expand the applicability of Transformer such that it can serve as a general-purpose backbone for computer vision, as it does for NLP and as CNNs do in vision. We observe that significant challenges in transferring its high performance in the language domain to the visual domain can be explained by differences between the two modalities. One of these differences involves scale. Unlike the word tokens that serve as the basic elements of processing in language Transformers, visual elements can vary substantially in scale, a problem that receives attention in tasks such as object detection  [42, 53, 54] . In existing Transformer-based models  [64, 20] , tokens are all of a fixed scale, a property unsuitable for these vision applications. Another difference is the much higher resolution of pixels in images compared to words in passages of text. There exist many vision tasks such as semantic segmentation that require dense prediction at the pixel level, and this would be intractable for Transformer on high-resolution images, as the computational complexity of its self-attention is quadratic to image size. To overcome these issues, we propose a generalpurpose Transformer backbone, called Swin Transformer, which constructs hierarchical feature maps and has linear computational complexity to image size. As illustrated in Figure  1 (a), Swin Transformer constructs a hierarchical representation by starting from small-sized patches (outlined in gray) and gradually merging neighboring patches in deeper Transformer layers. With these hierarchical feature maps, the Swin Transformer model can conveniently leverage advanced techniques for dense prediction such as feature pyramid networks (FPN)  [42]  or U-Net  [51] . The linear computational complexity is achieved by computing self-attention locally within non-overlapping windows that partition an image (outlined in red). The number of patches in each window is fixed, and thus the complexity becomes linear to image size. These merits make Swin Transformer suitable as a general-purpose backbone for various vision tasks, in contrast to previous Transformer based architectures  [20]  which produce feature maps of a single resolution and have quadratic complexity.", "sentences": ["To overcome these issues, we propose a generalpurpose Transformer backbone, called Swin Transformer, which constructs hierarchical feature maps and has linear computational complexity to image size."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["introduction", "abstract", "conclusion"]}}
{"segment_id": "ml::SEG::6351ebb4a3287f5f3e1273464b3b91e5df5a16d7::contribution::introduction::000", "track": "ml", "paper_id": "6351ebb4a3287f5f3e1273464b3b91e5df5a16d7", "unit_id": "ml::T011", "topic_id": "T011", "year": 2021, "conference": "Computer Vision and Pattern Recognition", "label_type": "contribution", "section": "introduction", "span_start": 2151, "span_end": 3630, "text": "(ii) Information density is different between language and vision. Languages are human-generated signals that are highly semantic and information-dense. When training a model to predict only a few missing words per sentence, this task appears to induce sophisticated language understanding. Images, on the contrary, are natural signals with heavy spatial redundancy-e.g., a missing patch can be recovered from neighboring patches with little high-level un-Figure  2 . Example results on ImageNet validation images. For each triplet, we show the masked image (left), our MAE reconstruction ‚Ä† (middle), and the ground-truth (right). The masking ratio is 80%, leaving only 39 out of 196 patches. More examples are in the appendix. ‚Ä† As no loss is computed on visible patches, the model output on visible patches is qualitatively worse. One can simply overlay the output with the visible patches to improve visual quality. We intentionally opt not to do this, so we can more comprehensively demonstrate the method's behavior. derstanding of parts, objects, and scenes. To overcome this difference and encourage learning useful features, we show that a simple strategy works well in computer vision: masking a very high portion of random patches. This strategy largely reduces redundancy and creates a challenging selfsupervisory task that requires holistic understanding beyond low-level image statistics. To get a qualitative sense of our reconstruction task, see Figures  2 3 4 .", "sentences": ["For each triplet, we show the masked image (left), our MAE reconstruction ‚Ä† (middle), and the ground-truth (right)."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["introduction", "abstract", "conclusion"]}}
{"segment_id": "ml::SEG::6351ebb4a3287f5f3e1273464b3b91e5df5a16d7::contribution::introduction::001", "track": "ml", "paper_id": "6351ebb4a3287f5f3e1273464b3b91e5df5a16d7", "unit_id": "ml::T011", "topic_id": "T011", "year": 2021, "conference": "Computer Vision and Pattern Recognition", "label_type": "contribution", "section": "introduction", "span_start": 2151, "span_end": 3630, "text": "(ii) Information density is different between language and vision. Languages are human-generated signals that are highly semantic and information-dense. When training a model to predict only a few missing words per sentence, this task appears to induce sophisticated language understanding. Images, on the contrary, are natural signals with heavy spatial redundancy-e.g., a missing patch can be recovered from neighboring patches with little high-level un-Figure  2 . Example results on ImageNet validation images. For each triplet, we show the masked image (left), our MAE reconstruction ‚Ä† (middle), and the ground-truth (right). The masking ratio is 80%, leaving only 39 out of 196 patches. More examples are in the appendix. ‚Ä† As no loss is computed on visible patches, the model output on visible patches is qualitatively worse. One can simply overlay the output with the visible patches to improve visual quality. We intentionally opt not to do this, so we can more comprehensively demonstrate the method's behavior. derstanding of parts, objects, and scenes. To overcome this difference and encourage learning useful features, we show that a simple strategy works well in computer vision: masking a very high portion of random patches. This strategy largely reduces redundancy and creates a challenging selfsupervisory task that requires holistic understanding beyond low-level image statistics. To get a qualitative sense of our reconstruction task, see Figures  2 3 4 .", "sentences": ["To overcome this difference and encourage learning useful features, we show that a simple strategy works well in computer vision: masking a very high portion of random patches."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["introduction", "abstract", "conclusion"]}}
{"segment_id": "ml::SEG::6351ebb4a3287f5f3e1273464b3b91e5df5a16d7::contribution::introduction::002", "track": "ml", "paper_id": "6351ebb4a3287f5f3e1273464b3b91e5df5a16d7", "unit_id": "ml::T011", "topic_id": "T011", "year": 2021, "conference": "Computer Vision and Pattern Recognition", "label_type": "contribution", "section": "introduction", "span_start": 4211, "span_end": 5180, "text": "Driven by this analysis, we present a simple, effective, and scalable form of a masked autoencoder (MAE) for visual representation learning. Our MAE masks random patches from the input image and reconstructs the missing patches in the pixel space. It has an asymmetric encoderdecoder design. Our encoder operates only on the visible subset of patches (without mask tokens), and our decoder is lightweight and reconstructs the input from the latent representation along with mask tokens (Figure  1 ). Shifting the mask tokens to the small decoder in our asymmetric encoder-decoder results in a large reduction in computation. Under this design, a very high masking ratio (e.g., 75%) can achieve a win-win scenario: it optimizes accuracy while allowing the encoder to process only a small portion (e.g., 25%) of patches. This can reduce overall pre-training time by 3√ó or more and likewise reduce memory consumption, enabling us to easily scale our MAE to large models.", "sentences": ["Driven by this analysis, we present a simple, effective, and scalable form of a masked autoencoder (MAE) for visual representation learning."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["introduction", "abstract", "conclusion"]}}
{"segment_id": "ml::SEG::6351ebb4a3287f5f3e1273464b3b91e5df5a16d7::future_work::discussion::003", "track": "ml", "paper_id": "6351ebb4a3287f5f3e1273464b3b91e5df5a16d7", "unit_id": "ml::T011", "topic_id": "T011", "year": 2021, "conference": "Computer Vision and Pattern Recognition", "label_type": "future_work", "section": "discussion", "span_start": 604, "span_end": 1691, "text": "On the other hand, we note that images and languages are signals of a different nature and this difference must be addressed carefully. Images are merely recorded light without a semantic decomposition into the visual analogue of words. Instead of attempting to remove objects, we remove random patches that most likely do not form a semantic segment. Likewise, our MAE reconstructs pixels, which are not semantic entities. Nevertheless, we observe (e.g., Figure  4 ) that our MAE infers complex, holistic reconstructions, suggesting it has learned numerous visual concepts, i.e., semantics. We hypothesize that this behavior occurs by way of a rich hidden representation inside the MAE. We hope this perspective will inspire future work.\n\nBroader impacts. The proposed method predicts content based on learned statistics of the training dataset and as such will reflect biases in those data, including ones with negative societal impacts. The model may generate inexistent content. These issues warrant further research and consideration when building upon this work to generate images.", "sentences": ["We hope this perspective will inspire future work.", "These issues warrant further research and consideration when building upon this work to generate images."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::0090023afc66cd2741568599057f4e82b566137c::contribution::introduction::000", "track": "ml", "paper_id": "0090023afc66cd2741568599057f4e82b566137c", "unit_id": "ml::T011", "topic_id": "T011", "year": 2019, "conference": "ACM Computing Surveys", "label_type": "contribution", "section": "introduction", "span_start": 2450, "span_end": 3220, "text": "We begin the review with several highly visible real-world cases of where unfair machine learning algorithms have led to suboptimal and discriminatory outcomes in Section 2. In Section 3, we describe the different types and sources of biases that occur within the data-algorithms-users loop mentioned above. Next, in Section 4, we present the different ways that the concept of fairness has been operationalized and studied in the literature. We discuss the ways in which these two concepts are coupled. Last, we will focus on different families of machine learning approaches, how fairness manifests differently in each one, and the current state-of-the-art for tackling them in Section 5, followed by potential areas of future work in each of the domains in Section 6.", "sentences": ["Next, in Section 4, we present the different ways that the concept of fairness has been operationalized and studied in the literature."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["introduction", "abstract", "conclusion"]}}
{"segment_id": "ml::SEG::0090023afc66cd2741568599057f4e82b566137c::limitation::conclusion::001", "track": "ml", "paper_id": "0090023afc66cd2741568599057f4e82b566137c", "unit_id": "ml::T011", "topic_id": "T011", "year": 2019, "conference": "ACM Computing Surveys", "label_type": "limitation", "section": "conclusion", "span_start": 0, "span_end": 1179, "text": "In this survey we introduced problems that can adversely affect AI systems in terms of bias and unfairness. The issues were viewed primarily from two dimensions: data and algorithms. We illustrated problems that demonstrate why fairness is an important issue. We further showed examples of the potential real-world harm that unfairness can have on society-such as applications in judicial systems, face recognition, and promoting algorithms. We then went over the definitions of fairness and bias that have been proposed by researchers. To further stimulate the interest of readers, we provided some of the work done in different areas in terms of addressing the biases that may affect AI systems and different methods and domains in AI, such as general machine learning, deep learning and natural language processing. We then further subdivided the fields into a more fine-grained analysis of each subdomain and the work being done to address fairness constraints in each. The hope is to expand the horizons of the readers to think deeply while working on a system or a method to ensure that it has a low likelihood of causing potential harm or bias toward a particular group.", "sentences": ["We then further subdivided the fields into a more fine-grained analysis of each subdomain and the work being done to address fairness constraints in each."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::0090023afc66cd2741568599057f4e82b566137c::future_work::conclusion::002", "track": "ml", "paper_id": "0090023afc66cd2741568599057f4e82b566137c", "unit_id": "ml::T011", "topic_id": "T011", "year": 2019, "conference": "ACM Computing Surveys", "label_type": "future_work", "section": "conclusion", "span_start": 1485, "span_end": 1633, "text": "Other possible future work and directions can be taken to address the existing problems and biases in AI that we discussed in the previous sections.", "sentences": ["Other possible future work and directions can be taken to address the existing problems and biases in AI that we discussed in the previous sections."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::f0dcc9aa31dc9b31b836bcac1b140c8c94a2982d::contribution::introduction::000", "track": "ml", "paper_id": "f0dcc9aa31dc9b31b836bcac1b140c8c94a2982d", "unit_id": "ml::T011", "topic_id": "T011", "year": 2016, "conference": "IEEE Symposium on Security and Privacy", "label_type": "contribution", "section": "introduction", "span_start": 1242, "span_end": 1827, "text": "Our contributions. We focus on the fundamental question known as membership inference: given a machine learning model and a record, determine whether this record was used as * This research was performed while the author was at Cornell Tech. part of the model's training dataset or not. We investigate this question in the most difficult setting, where the adversary's access to the model is limited to black-box queries that return the model's output on a given input. In summary, we quantify membership information leakage through the prediction outputs of machine learning models.", "sentences": ["Our contributions."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["introduction", "abstract", "conclusion"]}}
{"segment_id": "ml::SEG::f0dcc9aa31dc9b31b836bcac1b140c8c94a2982d::contribution::introduction::001", "track": "ml", "paper_id": "f0dcc9aa31dc9b31b836bcac1b140c8c94a2982d", "unit_id": "ml::T011", "topic_id": "T011", "year": 2016, "conference": "IEEE Symposium on Security and Privacy", "label_type": "contribution", "section": "introduction", "span_start": 8206, "span_end": 9914, "text": "Machine learning as a service. Major Internet companies now offer machine learning as a service on their cloud platforms. Examples include Google Prediction API,  1  Amazon Machine Learning (Amazon ML),  2  Microsoft Azure Machine Learning (Azure ML),  3  and BigML.  4 These platforms provide simple APIs for uploading the data and for training and querying models, thus making machine learning technologies available to any customer. For example, a developer may create an app that gathers data from users, uploads it into the cloud platform to train a model (or update an existing model with new data), and then uses the model's predictions inside the app to improve its features or better interact with the users. Some platforms even envision data holders training a model and then sharing it with others through the platform's API for profit.  5 The details of the models and the training algorithms are hidden from the data owners. The type of the model may be chosen by the service adaptively, depending on the data and perhaps accuracy on validation subsets. Service providers do not warn customers about the consequences of overfitting and provide little or no control over regularization. For example, Google Prediction API hides all details, while Amazon ML provides only a very limited set of pre-defined options (L1-or L2-norm regularization). The models cannot be downloaded and are accessed only through the service's API. Service providers derive revenue mainly by charging customers for queries through this API. Therefore, we treat \"machine learning as a service\" as a black box. All inference attacks we demonstrate in this paper are performed entirely through the services' standard APIs.", "sentences": ["All inference attacks we demonstrate in this paper are performed entirely through the services' standard APIs."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["introduction", "abstract", "conclusion"]}}
{"segment_id": "ml::SEG::f0dcc9aa31dc9b31b836bcac1b140c8c94a2982d::limitation::conclusion::002", "track": "ml", "paper_id": "f0dcc9aa31dc9b31b836bcac1b140c8c94a2982d", "unit_id": "ml::T011", "topic_id": "T011", "year": 2016, "conference": "IEEE Symposium on Security and Privacy", "label_type": "limitation", "section": "conclusion", "span_start": 485, "span_end": 963, "text": "Our key technical innovation is the shadow training technique that trains an attack model to distinguish the target model's outputs on members versus non-members of its training dataset. We demonstrate that shadow models used in this attack can be effectively created using synthetic or noisy data. In the case of synthetic data generated from the target model itself, the attack does not require any prior knowledge about the distribution of the target model's training data.", "sentences": ["In the case of synthetic data generated from the target model itself, the attack does not require any prior knowledge about the distribution of the target model's training data."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::fd1cf28a2b8caf2fe29af5e7fa9191cecfedf84d::contribution::introduction::000", "track": "ml", "paper_id": "fd1cf28a2b8caf2fe29af5e7fa9191cecfedf84d", "unit_id": "ml::T000", "topic_id": "T000", "year": 2022, "conference": "Robotics: Science and Systems", "label_type": "contribution", "section": "introduction", "span_start": 3968, "span_end": 5748, "text": "The second challenge lies in the design of the model itself. Effective robotic multi-task learning requires a high capacity model, and Transformer  (Vaswani et al., 2017)  models excel in this regard, particularly when it is necessary to learn many tasks conditioned, as in our case, on language instructions. However, robotic controllers must also be efficient enough to run in real time, which presents a major challenge for Transformers in particular. We propose a novel architecture that we call RT-1 (Robotics Transformer 1), which by encoding high-dimensional inputs and outputs, including camera images, instructions and motor commands into compact token representations to be used by the Transformer, allows for efficient inference at runtime to make real-time control feasible.\n\nOur contribution is the RT-1 model and experiments with this model on a large and broad dataset of real-world robotic tasks. Our experiments not only demonstrate that RT-1 can exhibit significantly improved generalization and robustness compared to prior techniques, but also evaluate and ablate many design choices in both the model and in the composition of the training set. Our results show that RT-1 can perform over 700 training instructions at 97% success rate, and can generalize to new tasks, distractors, and backgrounds 25%, 36% and 18% better than the next best baseline, respectively. This level of performance allows us to execute very long-horizon tasks in the SayCan  (Ahn et al., 2022)  framework, with as many as 50 stages. We further show that RT-1 can incorporate data from simulation or even other robot types, retaining performance on the original tasks and improving generalization to new scenarios. A short overview of RT-1 capabilities is presented in Fig.  1b   2  .", "sentences": ["We propose a novel architecture that we call RT-1 (Robotics Transformer 1), which by encoding high-dimensional inputs and outputs, including camera images, instructions and motor commands into compact token representations to be used by the Transformer, allows for efficient inference at runtime to make real-time control feasible.", "Our contribution is the RT-1 model and experiments with this model on a large and broad dataset of real-world robotic tasks."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["introduction", "abstract", "conclusion"]}}
{"segment_id": "ml::SEG::fd1cf28a2b8caf2fe29af5e7fa9191cecfedf84d::limitation::conclusion::001", "track": "ml", "paper_id": "fd1cf28a2b8caf2fe29af5e7fa9191cecfedf84d", "unit_id": "ml::T000", "topic_id": "T000", "year": 2022, "conference": "Robotics: Science and Systems", "label_type": "limitation", "section": "conclusion", "span_start": 939, "span_end": 1686, "text": "While RT-1 presents a promising step towards large-scale robot learning with an data-absorbent model, it comes with a number of limitations. First, it is an imitation learning method, which inherits the challenges of that class of approaches such as the fact that it may not be able to surpass the performance of the demonstrators. Second, the generalization to new instructions is limited to the combinations of previously seen concepts and RT-1 is not yet able to generalize to a completely new motion that has not been seen before. Lastly, our method is presented on a large but not very dexterous set of manipulation tasks. We plan to continue extending the set of instructions that RT-1 enables and generalizes to to address this challenge.", "sentences": ["While RT-1 presents a promising step towards large-scale robot learning with an data-absorbent model, it comes with a number of limitations."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::fd1cf28a2b8caf2fe29af5e7fa9191cecfedf84d::future_work::conclusion::002", "track": "ml", "paper_id": "fd1cf28a2b8caf2fe29af5e7fa9191cecfedf84d", "unit_id": "ml::T000", "topic_id": "T000", "year": 2022, "conference": "Robotics: Science and Systems", "label_type": "future_work", "section": "conclusion", "span_start": 939, "span_end": 1686, "text": "While RT-1 presents a promising step towards large-scale robot learning with an data-absorbent model, it comes with a number of limitations. First, it is an imitation learning method, which inherits the challenges of that class of approaches such as the fact that it may not be able to surpass the performance of the demonstrators. Second, the generalization to new instructions is limited to the combinations of previously seen concepts and RT-1 is not yet able to generalize to a completely new motion that has not been seen before. Lastly, our method is presented on a large but not very dexterous set of manipulation tasks. We plan to continue extending the set of instructions that RT-1 enables and generalizes to to address this challenge.", "sentences": ["We plan to continue extending the set of instructions that RT-1 enables and generalizes to to address this challenge."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::5f0b826ffe17faa2cdec21752e7d1863bd909f2c::contribution::introduction::000", "track": "ml", "paper_id": "5f0b826ffe17faa2cdec21752e7d1863bd909f2c", "unit_id": "ml::T000", "topic_id": "T000", "year": 2023, "conference": "Int. J. Robotics Res.", "label_type": "contribution", "section": "introduction", "span_start": 8023, "span_end": 9520, "text": "This survey is organized as follows: In Section II, we provide an introduction to foundation models including LLMs, vision transformers, VLMs, embodied multimodal language models, and visual generative models. In addition, in the last part of this section, we discuss different training methods used to train foundation models. In Section III, we present a review of how foundation models are integrated into different tasks for decision-making in robotics. First, we discuss robot policy learning using language-conditioned imitation learning, and language-assisted reinforcement learning. Then, we discuss how to use foundation models to design a languageconditioned value function that can be used for planning purposes. Next, robot task specification and code generation for task planning using foundation models are presented. In Section IV, we study various perception tasks in robotics that have the potential to be enhanced by employing foundation models. These tasks include semantic segmentation, 3D scene representation, zero-shot 3D classification, affordance prediction, and dynamics prediction. In Section V, we present papers about Embodied AI agents, generalist AI agents, as well as simulators and benchmarks developed for embodied AI research. In Section VI, we conclude the survey by discussing different challenges for employing foundation models in robotic systems and proposing potential avenues for future research. Finally, in Section VII we offer the concluding remarks.", "sentences": ["In Section III, we present a review of how foundation models are integrated into different tasks for decision-making in robotics."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["introduction", "abstract", "conclusion"]}}
{"segment_id": "ml::SEG::5f0b826ffe17faa2cdec21752e7d1863bd909f2c::contribution::introduction::001", "track": "ml", "paper_id": "5f0b826ffe17faa2cdec21752e7d1863bd909f2c", "unit_id": "ml::T000", "topic_id": "T000", "year": 2023, "conference": "Int. J. Robotics Res.", "label_type": "contribution", "section": "introduction", "span_start": 8023, "span_end": 9520, "text": "This survey is organized as follows: In Section II, we provide an introduction to foundation models including LLMs, vision transformers, VLMs, embodied multimodal language models, and visual generative models. In addition, in the last part of this section, we discuss different training methods used to train foundation models. In Section III, we present a review of how foundation models are integrated into different tasks for decision-making in robotics. First, we discuss robot policy learning using language-conditioned imitation learning, and language-assisted reinforcement learning. Then, we discuss how to use foundation models to design a languageconditioned value function that can be used for planning purposes. Next, robot task specification and code generation for task planning using foundation models are presented. In Section IV, we study various perception tasks in robotics that have the potential to be enhanced by employing foundation models. These tasks include semantic segmentation, 3D scene representation, zero-shot 3D classification, affordance prediction, and dynamics prediction. In Section V, we present papers about Embodied AI agents, generalist AI agents, as well as simulators and benchmarks developed for embodied AI research. In Section VI, we conclude the survey by discussing different challenges for employing foundation models in robotic systems and proposing potential avenues for future research. Finally, in Section VII we offer the concluding remarks.", "sentences": ["In Section V, we present papers about Embodied AI agents, generalist AI agents, as well as simulators and benchmarks developed for embodied AI research."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["introduction", "abstract", "conclusion"]}}
{"segment_id": "ml::SEG::5f0b826ffe17faa2cdec21752e7d1863bd909f2c::contribution::introduction::002", "track": "ml", "paper_id": "5f0b826ffe17faa2cdec21752e7d1863bd909f2c", "unit_id": "ml::T000", "topic_id": "T000", "year": 2023, "conference": "Int. J. Robotics Res.", "label_type": "contribution", "section": "introduction", "span_start": 9520, "span_end": 10575, "text": "Foundation models have billions of parameters and are pretrained on massive internet-scale datasets. Training models of such scale and complexity involve substantial costs. Acquiring, processing, and managing data can be costly. The training process demands significant computational resources, requiring specialized hardware such as GPUs or TPUs, as well as software and infrastructure for model training which requires financial resources. Additionally, training a foundation model is time-intensive, which can translate to even higher costs. Hence these models are often used as plug-and-play modules (which refers to the integration of foundation models into various applications without the need for extensive customization). Table  I  provides details about commonly used foundation models. In the rest of this section, we introduce LLMs, vision transformers, VLMs, embodied multi-modal language models, and visual generative models. In the last part of this section, we introduce different training methods that are used to train foundation models.", "sentences": ["In the rest of this section, we introduce LLMs, vision transformers, VLMs, embodied multi-modal language models, and visual generative models.", "In the last part of this section, we introduce different training methods that are used to train foundation models."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["introduction", "abstract", "conclusion"]}}
{"segment_id": "ml::SEG::5f0b826ffe17faa2cdec21752e7d1863bd909f2c::limitation::conclusion::003", "track": "ml", "paper_id": "5f0b826ffe17faa2cdec21752e7d1863bd909f2c", "unit_id": "ml::T000", "topic_id": "T000", "year": 2023, "conference": "Int. J. Robotics Res.", "label_type": "limitation", "section": "conclusion", "span_start": 1792, "span_end": 2947, "text": "Through examination of the recent literature, we have surveyed the diverse and promising applications of foundation models in robotics. We have delved into how these models have enhanced the capabilities of robots in areas such as decision-making, planning and control, and perception. We also discussed the literature on embodied AI and generalist AI, with an eye toward opportunities for roboticists to extend the concepts in that research field to real-world robotic applications. Generalization, zero-shot capabilities, multimodal capabilities, and scalability of foundation models have the potential to transform robotics. However, as we navigate through this paradigm shift in incorporating foundation models in robotics applications, it is imperative to recognize the challenges and potential risks that must be addressed in future research. Data scarcity in robotics applications, high variability in robotics settings, uncertainty quantification, safety evaluation, and realtime performance remain significant concerns that demand future research. We have delved into some of these challenges and have discussed potential avenues for improvement.", "sentences": ["However, as we navigate through this paradigm shift in incorporating foundation models in robotics applications, it is imperative to recognize the challenges and potential risks that must be addressed in future research."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::5f0b826ffe17faa2cdec21752e7d1863bd909f2c::future_work::conclusion::004", "track": "ml", "paper_id": "5f0b826ffe17faa2cdec21752e7d1863bd909f2c", "unit_id": "ml::T000", "topic_id": "T000", "year": 2023, "conference": "Int. J. Robotics Res.", "label_type": "future_work", "section": "conclusion", "span_start": 1792, "span_end": 2947, "text": "Through examination of the recent literature, we have surveyed the diverse and promising applications of foundation models in robotics. We have delved into how these models have enhanced the capabilities of robots in areas such as decision-making, planning and control, and perception. We also discussed the literature on embodied AI and generalist AI, with an eye toward opportunities for roboticists to extend the concepts in that research field to real-world robotic applications. Generalization, zero-shot capabilities, multimodal capabilities, and scalability of foundation models have the potential to transform robotics. However, as we navigate through this paradigm shift in incorporating foundation models in robotics applications, it is imperative to recognize the challenges and potential risks that must be addressed in future research. Data scarcity in robotics applications, high variability in robotics settings, uncertainty quantification, safety evaluation, and realtime performance remain significant concerns that demand future research. We have delved into some of these challenges and have discussed potential avenues for improvement.", "sentences": ["However, as we navigate through this paradigm shift in incorporating foundation models in robotics applications, it is imperative to recognize the challenges and potential risks that must be addressed in future research."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::3396609b96dd24cac3b1542aec686ce362f32fe2::contribution::introduction::000", "track": "ml", "paper_id": "3396609b96dd24cac3b1542aec686ce362f32fe2", "unit_id": "ml::T011", "topic_id": "T011", "year": 2023, "conference": "Robotics: Science and Systems", "label_type": "contribution", "section": "introduction", "span_start": 3124, "span_end": 4816, "text": "Motivated by this, we present Voltron, a framework for languagedriven visual representation learning for robotics that learns representations that capture both low-level and high-level features, empirically outperforming prior approaches over all applications. Voltron models take videos and associated language captions as input to a masked autoencoding pipeline, reconstructing one (or more) frames from a masked context. The novelty of our framework is in how we use language supervision. Depending on a tunable probability ùõº, we either condition on (ùõº = 0), or generate (ùõº > 0) the associated caption. Explicitly conditioning on words in different contexts allows for low-level pattern recognition at the local, spatial level, while generating language from our learned visual Figure  1 : Voltron Evaluation Suite. We introduce a suite of evaluation problems spanning five applications within robotics, including grasp affordance prediction, referring expression grounding, single-task visuomotor control (in simulation), language-conditioned imitation learning (on a real robot), and intent scoring. encoding allow us to infer higher-level features around affordances and intents. Furthermore, guided by the hypothesis that language is especially useful in describing change, we study dual-frame contexts consisting of the initial and current observation in multi-timestep tasks. Altogether, we examine three different Voltron variants: V -Cond (Language Conditioning: single frame, ùõº = 0), V -Dual (Adding Context: dual-frame conditioning, ùõº = 0), and V -Gen (Adding Language Generation: dual-frame, ùõº = 0.5 -we find that ùõº = 1 with no language-conditioning at all hurts performance).", "sentences": ["Motivated by this, we present Voltron, a framework for languagedriven visual representation learning for robotics that learns representations that capture both low-level and high-level features, empirically outperforming prior approaches over all applications."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["introduction", "abstract", "conclusion"]}}
{"segment_id": "ml::SEG::3396609b96dd24cac3b1542aec686ce362f32fe2::contribution::introduction::001", "track": "ml", "paper_id": "3396609b96dd24cac3b1542aec686ce362f32fe2", "unit_id": "ml::T011", "topic_id": "T011", "year": 2023, "conference": "Robotics: Science and Systems", "label_type": "contribution", "section": "introduction", "span_start": 3124, "span_end": 4816, "text": "Motivated by this, we present Voltron, a framework for languagedriven visual representation learning for robotics that learns representations that capture both low-level and high-level features, empirically outperforming prior approaches over all applications. Voltron models take videos and associated language captions as input to a masked autoencoding pipeline, reconstructing one (or more) frames from a masked context. The novelty of our framework is in how we use language supervision. Depending on a tunable probability ùõº, we either condition on (ùõº = 0), or generate (ùõº > 0) the associated caption. Explicitly conditioning on words in different contexts allows for low-level pattern recognition at the local, spatial level, while generating language from our learned visual Figure  1 : Voltron Evaluation Suite. We introduce a suite of evaluation problems spanning five applications within robotics, including grasp affordance prediction, referring expression grounding, single-task visuomotor control (in simulation), language-conditioned imitation learning (on a real robot), and intent scoring. encoding allow us to infer higher-level features around affordances and intents. Furthermore, guided by the hypothesis that language is especially useful in describing change, we study dual-frame contexts consisting of the initial and current observation in multi-timestep tasks. Altogether, we examine three different Voltron variants: V -Cond (Language Conditioning: single frame, ùõº = 0), V -Dual (Adding Context: dual-frame conditioning, ùõº = 0), and V -Gen (Adding Language Generation: dual-frame, ùõº = 0.5 -we find that ùõº = 1 with no language-conditioning at all hurts performance).", "sentences": ["We introduce a suite of evaluation problems spanning five applications within robotics, including grasp affordance prediction, referring expression grounding, single-task visuomotor control (in simulation), language-conditioned imitation learning (on a real robot), and intent scoring."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["introduction", "abstract", "conclusion"]}}
{"segment_id": "ml::SEG::3396609b96dd24cac3b1542aec686ce362f32fe2::contribution::introduction::002", "track": "ml", "paper_id": "3396609b96dd24cac3b1542aec686ce362f32fe2", "unit_id": "ml::T011", "topic_id": "T011", "year": 2023, "conference": "Robotics: Science and Systems", "label_type": "contribution", "section": "introduction", "span_start": 5814, "span_end": 6976, "text": "Through experiments controlling for pretraining data and model capacity, we show that the simplest Voltron representations (from V -Cond) strictly outperform both MVP and R3M representations across all evaluation domains. Furthermore, by adapting our models to learn from multiple frame contexts and that favor generation (e.g., with V -Dual and V -Gen), we show that we can further boost performance on evaluations requiring higher-level features such as with language-conditioned policy learning (on a real robot) and intent scoring. Though language-conditioning offers universal performance gains, there are tradeoffs between Voltron models; adding language generation hurts performance on some control tasks, even though its necessary for strong performance on intent scoring. Furthermore, Voltron with single-frame language conditioning performs well on non-episodic tasks (e.g., grasping), but underperforms multi-frame models on control tasks. There is not yet a silver bullet -a single representation strong on all tasks -but the ability to balance tradeoffs between encoding low and high-level features offers a net win over restrictions of past work.", "sentences": ["Through experiments controlling for pretraining data and model capacity, we show that the simplest Voltron representations (from V -Cond) strictly outperform both MVP and R3M representations across all evaluation domains.", "Furthermore, by adapting our models to learn from multiple frame contexts and that favor generation (e.g., with V -Dual and V -Gen), we show that we can further boost performance on evaluations requiring higher-level features such as with language-conditioned policy learning (on a real robot) and intent scoring."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["introduction", "abstract", "conclusion"]}}
{"segment_id": "ml::SEG::3396609b96dd24cac3b1542aec686ce362f32fe2::contribution::introduction::003", "track": "ml", "paper_id": "3396609b96dd24cac3b1542aec686ce362f32fe2", "unit_id": "ml::T011", "topic_id": "T011", "year": 2023, "conference": "Robotics: Science and Systems", "label_type": "contribution", "section": "introduction", "span_start": 6976, "span_end": 7627, "text": "Contributions. 1) We present Voltron, a framework for languagedriven visual representation learning. Through controlled experiments and comprehensive ablations we demonstrate that Voltron's representations strictly outperform the prior art across 2) a new evaluation suite composed of five distinct problem domains within robotics. Finally, 3) we analyze the tradeoffs between different Voltron models that balance different types of feature learning, outlining several directions for future work. We release all models, the evaluation suite, code (pretraining and adaptation), and preprocessed data (https://sites.google.com/view/voltron-robotics).", "sentences": ["1) We present Voltron, a framework for languagedriven visual representation learning.", "Through controlled experiments and comprehensive ablations we demonstrate that Voltron's representations strictly outperform the prior art across 2) a new evaluation suite composed of five distinct problem domains within robotics."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["introduction", "abstract", "conclusion"]}}
{"segment_id": "ml::SEG::3396609b96dd24cac3b1542aec686ce362f32fe2::limitation::discussion::004", "track": "ml", "paper_id": "3396609b96dd24cac3b1542aec686ce362f32fe2", "unit_id": "ml::T011", "topic_id": "T011", "year": 2023, "conference": "Robotics: Science and Systems", "label_type": "limitation", "section": "discussion", "span_start": 380, "span_end": 1342, "text": "Ablation: The Impact of Language Supervision. The second row of Table  4  shows a subset of evaluation results across three different problem domains when training a \"no-language\" variant of the V -Cond architecture -this variant is in essence an alternate version of a masked autoencoder that uses the small architecture modifications we added for training stability in ¬ß4. As such, it also serves as an architecture ablation when compared to the R-MVP results, enabling us to isolate the impact of the small stability modifications described in ¬ß4. Indeed, the results confirm our hypotheses: first, removing language results in a definitive drop in performance across all evaluation applications. Second, the respective results for each evaluation application are on par with the corresponding results for the R-MVP model, demonstrating that the performance of Voltron models does not stem from the architecture. We delve further into this ablation in ¬ßC.1.", "sentences": ["Second, the respective results for each evaluation application are on par with the corresponding results for the R-MVP model, demonstrating that the performance of Voltron models does not stem from the architecture."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::3396609b96dd24cac3b1542aec686ce362f32fe2::limitation::discussion::005", "track": "ml", "paper_id": "3396609b96dd24cac3b1542aec686ce362f32fe2", "unit_id": "ml::T011", "topic_id": "T011", "year": 2023, "conference": "Robotics: Science and Systems", "label_type": "limitation", "section": "discussion", "span_start": 7496, "span_end": 8557, "text": "These results are to be taken with a grain of salt, given the limited pretraining duration. However, we worry that with ùõº = 1, we might suffer doubly for 1) never conditioning on language, which is so clearly helpful from our results, and 2) potentially fall into the same failure mode as the R-M3AE multimodal masked autoencoder from Section ¬ß6 in the main text, overfitting to the language loss. In general, V -Gen with ùõº = 0.5 already converges to a substantially higher reconstruction loss as V -Cond and V -Dual, as shown in the pretraining curves in ¬ßB.3. That being said, it is a promising avenue for future work to understand if this is inherent or a problem with the specific optimization procedure we used -perhaps changing the relative scaling of the two losses over the course of pretraining may mitigate this issue, or even adaptively clipping the gradient updates depending on the relative contribution of the visual reconstructor or language generator. Q3. Why does language during pretraining help for downstream tasks that don't use language?", "sentences": ["However, we worry that with ùõº = 1, we might suffer doubly for 1) never conditioning on language, which is so clearly helpful from our results, and 2) potentially fall into the same failure mode as the R-M3AE multimodal masked autoencoder from Section ¬ß6 in the main text, overfitting to the language loss."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::3396609b96dd24cac3b1542aec686ce362f32fe2::future_work::discussion::006", "track": "ml", "paper_id": "3396609b96dd24cac3b1542aec686ce362f32fe2", "unit_id": "ml::T011", "topic_id": "T011", "year": 2023, "conference": "Robotics: Science and Systems", "label_type": "future_work", "section": "discussion", "span_start": 1342, "span_end": 3130, "text": "Ablation: Generative vs. Masked Language Modeling. Looking at the Voltron objective, a natural question to ask is why we chose language generation over masked language modeling. Furthermore, recent and concurrent work propose learning multimodal masked autoencoders (M3AE) both within and outside of robotics  [Geng et al. 2022; Liu et al. 2022] , showing promising results in learning visual representations for image classification tasks, amongst others. To assess the differences, we choose to reproduce the M3AE model in a manner similar to our reproduction of MVP and R3M; we keep the same Something-Something-v2 pretraining data, adopting the exact procedure described in  Geng et al. [2022] , then evaluating the resulting representations on the same subset of evaluation domains as in the prior ablation (third row of Table  4 ). Surprisingly, we see drastic drops in performance across the board. Looking at the pretraining curves, we identify a possible reason for this failure: in optimizing M3AE on Sth-Sth, we see the language modeling loss go to zero almost immediately, leading to overfitting. A possible explanation is that the masked language modeling conditioned on visual contexts in datasets annotated with short, predictable narrations leads to degenerate representations, while generative language modeling is not susceptible to the same types of collapse; looking at ways to mitigate this seems like a promising direction for future work. Explicit details around pretraining and evaluating R-M3AE, with an in-depth discussion are in ¬ßC.2. the 22M in the ViT-Small). We see universal improvement: Top-5% precision for grasping (Table  2 ; middle row) increases by 15%, expression grounding accuracy improves (Table  3 ; middle row), as does performance on control.", "sentences": ["A possible explanation is that the masked language modeling conditioned on visual contexts in datasets annotated with short, predictable narrations leads to degenerate representations, while generative language modeling is not susceptible to the same types of collapse; looking at ways to mitigate this seems like a promising direction for future work."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::3396609b96dd24cac3b1542aec686ce362f32fe2::future_work::discussion::007", "track": "ml", "paper_id": "3396609b96dd24cac3b1542aec686ce362f32fe2", "unit_id": "ml::T011", "topic_id": "T011", "year": 2023, "conference": "Robotics: Science and Systems", "label_type": "future_work", "section": "discussion", "span_start": 3852, "span_end": 5212, "text": "We propose Voltron, a framework for language-driven representation learning that balances conditioning and generation to shape the balance of low and high-level features captured. We introduce an evaluation suite spanning five diverse problems within robotics for holistically evaluating visual representations. Through controlled experiments and ablations, we validate the strengths of our representations; across all evaluation tasks, Voltron models that balance language conditioning and generation strictly outperform prior approaches such as R3M and MVP, and in many cases show performance competitive with or exceeding that of approaches that use orders of magnitude more data or more expressive models. Yet, while language is a pivotal source of supervision, there are still key questions to answer. Why is language-based pretraining helpful on tasks that have nothing to do with language? Why not try to learn one model that can encode both low-level and high-level features, without tradeoffs? While there is not a silver bullet yet we hope that future work takes a deep, grounded look at these questions, identifying what existing representations capture -and more importantly, what they miss. Our hope is that Voltron serves as a starting point; a flexible, unified framework for future improvements in visual representation learning for robotics.", "sentences": ["While there is not a silver bullet yet we hope that future work takes a deep, grounded look at these questions, identifying what existing representations capture -and more importantly, what they miss."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::3396609b96dd24cac3b1542aec686ce362f32fe2::future_work::discussion::008", "track": "ml", "paper_id": "3396609b96dd24cac3b1542aec686ce362f32fe2", "unit_id": "ml::T011", "topic_id": "T011", "year": 2023, "conference": "Robotics: Science and Systems", "label_type": "future_work", "section": "discussion", "span_start": 7496, "span_end": 8557, "text": "These results are to be taken with a grain of salt, given the limited pretraining duration. However, we worry that with ùõº = 1, we might suffer doubly for 1) never conditioning on language, which is so clearly helpful from our results, and 2) potentially fall into the same failure mode as the R-M3AE multimodal masked autoencoder from Section ¬ß6 in the main text, overfitting to the language loss. In general, V -Gen with ùõº = 0.5 already converges to a substantially higher reconstruction loss as V -Cond and V -Dual, as shown in the pretraining curves in ¬ßB.3. That being said, it is a promising avenue for future work to understand if this is inherent or a problem with the specific optimization procedure we used -perhaps changing the relative scaling of the two losses over the course of pretraining may mitigate this issue, or even adaptively clipping the gradient updates depending on the relative contribution of the visual reconstructor or language generator. Q3. Why does language during pretraining help for downstream tasks that don't use language?", "sentences": ["That being said, it is a promising avenue for future work to understand if this is inherent or a problem with the specific optimization procedure we used -perhaps changing the relative scaling of the two losses over the course of pretraining may mitigate this issue, or even adaptively clipping the gradient updates depending on the relative contribution of the visual reconstructor or language generator."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::44dc896ec1d1abf65a88a8f076515d26b54c6047::limitation::discussion::000", "track": "ml", "paper_id": "44dc896ec1d1abf65a88a8f076515d26b54c6047", "unit_id": "ml::T011", "topic_id": "T011", "year": 2001, "conference": "Proceedings IEEE International Conference on Cluster Computing", "label_type": "limitation", "section": "discussion", "span_start": 977, "span_end": 1251, "text": "We partition the discussion to four parts: The use of ITMs, the use of identities, the externalwrite mechanism, and the modeling of resource-bounded computation. It is stressed however that the partitioning is somewhat arbitrary and all topics are of course inter-related.", "sentences": ["It is stressed however that the partitioning is somewhat arbitrary and all topics are of course inter-related."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::44dc896ec1d1abf65a88a8f076515d26b54c6047::limitation::discussion::001", "track": "ml", "paper_id": "44dc896ec1d1abf65a88a8f076515d26b54c6047", "unit_id": "ml::T011", "topic_id": "T011", "year": 2001, "conference": "Proceedings IEEE International Conference on Cluster Computing", "label_type": "limitation", "section": "discussion", "span_start": 4422, "span_end": 5057, "text": "It is stressed, however, that the UC theorem is, in general, false in settings where systems of ITMs cannot be simulated on a single ITM from the same class. We exemplify this point for the case where all entities in the system are bound to be PPT, except for the protocol œÜ which is not PPT.  23  More specifically, we present an ideal functionality F that is not PPT, and a PPT protocol œÄ that UC-realizes F with respect to PPT environments. Then we present a protocol œÅ, that calls two sessions of the ideal protocol for F, and such that œÅ F ‚ÜíœÄ does not UC-emulate œÅ. In fact, for any PPT œÄ we have that œÅ F ‚ÜíœÄ does not emulate œÅ.", "sentences": ["It is stressed, however, that the UC theorem is, in general, false in settings where systems of ITMs cannot be simulated on a single ITM from the same class.", "Then we present a protocol œÅ, that calls two sessions of the ideal protocol for F, and such that œÅ F ‚ÜíœÄ does not UC-emulate œÅ.", "In fact, for any PPT œÄ we have that œÅ F ‚ÜíœÄ does not emulate œÅ."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::44dc896ec1d1abf65a88a8f076515d26b54c6047::limitation::discussion::002", "track": "ml", "paper_id": "44dc896ec1d1abf65a88a8f076515d26b54c6047", "unit_id": "ml::T011", "topic_id": "T011", "year": 2001, "conference": "Proceedings IEEE International Conference on Cluster Computing", "label_type": "limitation", "section": "discussion", "span_start": 5630, "span_end": 6627, "text": "It is easy to see that œÄ UC-realizes F: Since S is evasive, then the probability that the input x is in the set s k,i is negligible, thus F outputs success only with negligible probability. Furthermore, F outputs a pseudorandom k-bit value, which is indistinguishable from the output of œÄ. Now, consider the following F-hybrid protocol œÅ. œÅ runs two sessions of F, denoted F 1 and F 2 . Upon invocation with security parameter k, it activates F 1 and F 2 with k, and obtains the indices i 1 and i 2 . Next, it chooses x 1 R ‚Üê {0, 1} k , and feeds (x 1 , i 2 ) to F 1 . If F 1 outputs success then œÅ outputs success and halts. Otherwise, œÄ feeds the value x 2 obtained from F 1 to F 2 . If F 2 outputs success then œÅ outputs success; otherwise it outputs fail. It is easy to see that œÅ always outputs success. However, œÅ F ‚ÜíœÄ never outputs success. In fact, the separation is stronger: F any PPT protocol œÄ that UC-realizes F, we have that œÅ F ‚ÜíœÄ outputs success only with negligible probability.", "sentences": ["However, œÅ F ‚ÜíœÄ never outputs success."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::44dc896ec1d1abf65a88a8f076515d26b54c6047::limitation::discussion::003", "track": "ml", "paper_id": "44dc896ec1d1abf65a88a8f076515d26b54c6047", "unit_id": "ml::T011", "topic_id": "T011", "year": 2001, "conference": "Proceedings IEEE International Conference on Cluster Computing", "label_type": "limitation", "section": "discussion", "span_start": 6627, "span_end": 7198, "text": "As discussed earlier, the basic model of computation provides no explicit mechanism for modeling communication over a network. It also provides only a single, limited mechanism for scheduling processes in a distributed setting, and no explicit mechanism for expressing adversarial control over, or infiltration of, computational entities. It also does not provide explicit ways to express leakage of information from computing devices. Indeed, the bare model does not immediately provide natural ways to represent realistic protocols, attacks, or security requirements.", "sentences": ["It also does not provide explicit ways to express leakage of information from computing devices.", "Indeed, the bare model does not immediately provide natural ways to represent realistic protocols, attacks, or security requirements."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::27e57cc2f22c1921d2a1c3954d5062e3fe391553::limitation::discussion::000", "track": "ml", "paper_id": "27e57cc2f22c1921d2a1c3954d5062e3fe391553", "unit_id": "ml::T008", "topic_id": "T008", "year": 2009, "conference": "Empirical Software Engineering", "label_type": "limitation", "section": "discussion", "span_start": 1587, "span_end": 3183, "text": "There were different objectives of the three example cases. The objective of study XP was to investigate how an agile process can coexist with a stage-gate management organization. The objective of study RE was to evaluate a method for prioritization of requirements, and the objective of study QA was to find quantitative prediction models and procedures for defect data. Study XP is considered an embedded case study with two units of analysis from two different companies, although it might be seen as two holistic case studies, as denoted above. RE is a holistic case study with one unit of analysis, while QA is an embedded case study in one company with three different projects as units of analysis. All the companies were selected based on existing academia-industry relations, while the units of analysis were selected to fit the specific case study purposes. Concerning the frame of reference, no explicit theories are referred to in studies XP and RE. However, the investigated approaches are based on existing methods that, to some extent, already have been investigated. Earlier studies thereby affected the designs of the studies. Study QA was partly a replication, which means that the original study formed a frame of reference from which theories on, for example, the Pareto principle and fault persistence between test phases were used when hypotheses were defined. Data were primarily collected using interviews in the XP case. In the RE case, questionnaires constituted the major source of data, while in the QA case, defect metrics from a company was the major data source.", "sentences": ["However, the investigated approaches are based on existing methods that, to some extent, already have been investigated."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::27e57cc2f22c1921d2a1c3954d5062e3fe391553::limitation::discussion::001", "track": "ml", "paper_id": "27e57cc2f22c1921d2a1c3954d5062e3fe391553", "unit_id": "ml::T008", "topic_id": "T008", "year": 2009, "conference": "Empirical Software Engineering", "label_type": "limitation", "section": "discussion", "span_start": 4080, "span_end": 5039, "text": "Issues on confidentiality and publication should also be regulated in a contract between the researcher and the studied organization. However, not only can information be sensitive when leaking outside a company. Data collected from and opinions stated by individual employees may be sensitive if presented e.g. to their managers  (Singer and Vinson 2002) . The researchers must have the right to keep their integrity and adhere to agreed procedures in this kind of cases. Companies may not know academic practices for publication and dissemination, and must hence be explicitly informed about those. From a publication point of view, the relevant data to publish is rarely sensitive to the company since data may be made anonymous. However, it is important to remember that it is not always sufficient to remove names of companies or individuals. They may be identified by their characteristics if they are selected from a small set of people or companies.", "sentences": ["However, not only can information be sensitive when leaking outside a company."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::27e57cc2f22c1921d2a1c3954d5062e3fe391553::limitation::discussion::002", "track": "ml", "paper_id": "27e57cc2f22c1921d2a1c3954d5062e3fe391553", "unit_id": "ml::T008", "topic_id": "T008", "year": 2009, "conference": "Empirical Software Engineering", "label_type": "limitation", "section": "discussion", "span_start": 4080, "span_end": 5039, "text": "Issues on confidentiality and publication should also be regulated in a contract between the researcher and the studied organization. However, not only can information be sensitive when leaking outside a company. Data collected from and opinions stated by individual employees may be sensitive if presented e.g. to their managers  (Singer and Vinson 2002) . The researchers must have the right to keep their integrity and adhere to agreed procedures in this kind of cases. Companies may not know academic practices for publication and dissemination, and must hence be explicitly informed about those. From a publication point of view, the relevant data to publish is rarely sensitive to the company since data may be made anonymous. However, it is important to remember that it is not always sufficient to remove names of companies or individuals. They may be identified by their characteristics if they are selected from a small set of people or companies.", "sentences": ["However, it is important to remember that it is not always sufficient to remove names of companies or individuals."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::27e57cc2f22c1921d2a1c3954d5062e3fe391553::limitation::discussion::003", "track": "ml", "paper_id": "27e57cc2f22c1921d2a1c3954d5062e3fe391553", "unit_id": "ml::T008", "topic_id": "T008", "year": 2009, "conference": "Empirical Software Engineering", "label_type": "limitation", "section": "discussion", "span_start": 9321, "span_end": 10184, "text": "In study RE and study QC the main analyses were conducted with quantitative methods, mainly through analysis of correlation and descriptive statistics, such as scatter plots. In the QC case, the quantitative data acted as a trigger for deeper understanding. Patterns in the data, and lack thereof generated questions in the feedback session. The answers lead to changes in the data analysis, e.g. filtering out some data sources, and to identification of real patterns in the data. In study XP, the main analysis was conducted with qualitative methods, but this was combined with a limited quantitative analysis of number of defects found during different years in one of the organizations. However, there would probably have been possibilities to conduct more complementary analyses in order to corroborate or develop the results from the qualitative analysis.", "sentences": ["However, there would probably have been possibilities to conduct more complementary analyses in order to corroborate or develop the results from the qualitative analysis."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::27e57cc2f22c1921d2a1c3954d5062e3fe391553::limitation::discussion::004", "track": "ml", "paper_id": "27e57cc2f22c1921d2a1c3954d5062e3fe391553", "unit_id": "ml::T008", "topic_id": "T008", "year": 2009, "conference": "Empirical Software Engineering", "label_type": "limitation", "section": "discussion", "span_start": 15156, "span_end": 15755, "text": "One example of a useful technique for analysis is tabulation, where the coded data is arranged in tables, which makes it possible to get an overview of the data. The data can, for example be organized in a table where the rows represent codes of interest and the columns represent interview subjects. However, how to do this must be decided for every case study.\n\nThere are specialized software tools available to support qualitative data analysis, e.g. NVivo and Atlas. However, in some cases standard tools such as word processors and spreadsheet tools are useful when managing the textual data.", "sentences": ["However, how to do this must be decided for every case study.", "However, in some cases standard tools such as word processors and spreadsheet tools are useful when managing the textual data."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::27e57cc2f22c1921d2a1c3954d5062e3fe391553::limitation::discussion::005", "track": "ml", "paper_id": "27e57cc2f22c1921d2a1c3954d5062e3fe391553", "unit_id": "ml::T008", "topic_id": "T008", "year": 2009, "conference": "Empirical Software Engineering", "label_type": "limitation", "section": "discussion", "span_start": 15755, "span_end": 16774, "text": "In study XP, the transcribed interviews were initially analyzed by one of the researchers. A preliminary set of codes were derived from the informal notes and applied to the transcripts. The preliminary set of codes was: project model, communication, planning, follow-up, quality, technical issues and attitudes. Each statement in the transcribed interviews was given a unique identification, and classified by two researchers. The transcribed data was then filled into tables, allowing for analysis of patterns in the data by sorting issues found by, for example, interviewee role or company. The chain of evidence is illustrated with the figure below (from  Karlstr√∂m and Runeson 2006)  In study RE and QA the main analysis was quantitative, although some qualitative analysis was conducted on the information that was gathered in feedback sessions. However, this analysis would probably benefit from being conducted in a more structured way, e.g. by recording, transcribing, and coding feedback data before analysis.", "sentences": ["However, this analysis would probably benefit from being conducted in a more structured way, e.g."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::420af69e5ae3686b709c14a8cec7dc9f90a85681::limitation::discussion::000", "track": "ml", "paper_id": "420af69e5ae3686b709c14a8cec7dc9f90a85681", "unit_id": "ml::T010", "topic_id": "T010", "year": 2024, "conference": "Frontiers Artif. Intell.", "label_type": "limitation", "section": "discussion", "span_start": 0, "span_end": 938, "text": "Due to its proficiency in understanding and effectively processing human language, the ChatGPT platform demonstrates significant advantages in the field of customer sentiment analysis  (Harahap et al., 2023) . Trained on comprehensive and diverse datasets, it can understand the context, nuances, and emotional aspects embedded in customer texts. In sentiment analysis, ChatGPT can identify whether the textual input provided by customers contains positive, negative, or neutral emotions  (Sutrisno et al., 2023) .  Sudirjo et al. (2023)  indicate that utilizing ChatGPT has significant potential in improving customer sentiment analysis for commercial enterprises. It can aid in understanding and addressing customer requirements, tendencies, and satisfaction levels. However, it is important to understand that ChatGPT should not be the sole source of information and the analysis results need to be interpreted judiciously by humans.", "sentences": ["However, it is important to understand that ChatGPT should not be the sole source of information and the analysis results need to be interpreted judiciously by humans."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::d89f6b942c4a8c0b09945462688290484493ed6b::contribution::introduction::000", "track": "ml", "paper_id": "d89f6b942c4a8c0b09945462688290484493ed6b", "unit_id": "ml::T002", "topic_id": "T002", "year": 2023, "conference": "Conference on Empirical Methods in Natural Language Processing", "label_type": "contribution", "section": "introduction", "span_start": 1008, "span_end": 2190, "text": "We present the ACL OCL (or OCL for short), an enriched and contemporary scholarly corpus that builds upon the strengths of its predecessors while addressing their limitations. The OCL corpus includes 73,285 papers hosted by the ACL Anthology published from 1952 to September 2022. The OCL further provides higher-quality structured full texts for all papers, instead of previous stringformatted ones, enabling richer textual analyses. For instance, higher-quality full texts better foster the development of document-level information extraction tasks  (Jain et al., 2020; Das et al., 2022) . The structured information in full texts, such as sections and paragraphs, facilitates section-wise tasks such as related work generation (Hoang and  Kan, 2010)  and enables fine-grained linguistic analyses Name #Doc. Text Type Linked KG Fig.  Peer  Source Domain RefSeer  (Huang et al., 2015)  1.0M string CiteSeerX √ó partial WWW multi S2ORC  (Lo et al., 2020)  8.1M structured S2AG √ó partial multi multi CSL  (Li et al., 2022)  396K -self √ó all CCJ multi unarXive  (Saier et al., 2023)  1.9M structured MAG √ó partial arXiv multi ACL ARC  (Bird et al., 2008)     (Jiang et al., 2020a) .", "sentences": ["We present the ACL OCL (or OCL for short), an enriched and contemporary scholarly corpus that builds upon the strengths of its predecessors while addressing their limitations."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["introduction", "abstract", "conclusion"]}}
{"segment_id": "ml::SEG::d89f6b942c4a8c0b09945462688290484493ed6b::limitation::conclusion::001", "track": "ml", "paper_id": "d89f6b942c4a8c0b09945462688290484493ed6b", "unit_id": "ml::T002", "topic_id": "T002", "year": 2023, "conference": "Conference on Empirical Methods in Natural Language Processing", "label_type": "limitation", "section": "conclusion", "span_start": 1535, "span_end": 1973, "text": "To ensure the extraction of high-quality full texts from the provided PDF files, the OCL corpus utilizes the most advanced open-sourced PDF2text toolkit, GROBID. Due to constraints on budget, only open-source toolkits are considered, although it is acknowledged that some paid PDF2text services might yield higher-quality full texts. In addition, previous work such as unarXive use L A T E X files as source documents to avoid PDF2text.", "sentences": ["Due to constraints on budget, only open-source toolkits are considered, although it is acknowledged that some paid PDF2text services might yield higher-quality full texts."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::d89f6b942c4a8c0b09945462688290484493ed6b::future_work::conclusion::002", "track": "ml", "paper_id": "d89f6b942c4a8c0b09945462688290484493ed6b", "unit_id": "ml::T002", "topic_id": "T002", "year": 2023, "conference": "Conference on Empirical Methods in Natural Language Processing", "label_type": "future_work", "section": "conclusion", "span_start": 728, "span_end": 1055, "text": "In the future, we will work on the data currency of OCL, which aims to keep OCL up-to-date with the ACL Anthology data. We plan to update OCL by year to keep it alive. The ultimate solution is to provide full-text extraction and information extraction APIs to ACL Anthology, thus hosting the OCL data on ACL Anthology itself.", "sentences": ["In the future, we will work on the data currency of OCL, which aims to keep OCL up-to-date with the ACL Anthology data.", "We plan to update OCL by year to keep it alive."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::7c9975fedb81929f0115f1fb1f7b7535121f8c4e::contribution::introduction::000", "track": "ml", "paper_id": "7c9975fedb81929f0115f1fb1f7b7535121f8c4e", "unit_id": "ml::T006", "topic_id": "T006", "year": 2022, "conference": "Conference on Empirical Methods in Natural Language Processing", "label_type": "contribution", "section": "introduction", "span_start": 2973, "span_end": 3059, "text": "‚Ä¢ We propose four recommendations to address major issues affecting reproducibility.", "sentences": ["‚Ä¢ We propose four recommendations to address major issues affecting reproducibility."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["introduction", "abstract", "conclusion"]}}
{"segment_id": "ml::SEG::7c9975fedb81929f0115f1fb1f7b7535121f8c4e::contribution::introduction::001", "track": "ml", "paper_id": "7c9975fedb81929f0115f1fb1f7b7535121f8c4e", "unit_id": "ml::T006", "topic_id": "T006", "year": 2022, "conference": "Conference on Empirical Methods in Natural Language Processing", "label_type": "contribution", "section": "introduction", "span_start": 7907, "span_end": 8773, "text": "Conferences in the broad areas of NLP and machine learning have recently adopted reproducibility checklists  (AAAI 2022 (AAAI, 2022 ), NeurIPS 2022 (NeurIPS, 2022) ) which require authors to provide an appendix with the source code used in the experiments. Additionally, they recommend the inclusion of dependency specifications, training and evaluation code, pre-trained models, and a README file containing the information required to achieve the results in the paper. Unfortunately, as we show in the following sections, reproducing publications that follow these good practices is not easy. It requires a considerable amount of engineering involving fixing compilation errors, \"guessing\" configurations not documented, figuring out which code to execute for which experiment, manually processing experimental data, and dealing with obsolete tools or libraries.", "sentences": ["Unfortunately, as we show in the following sections, reproducing publications that follow these good practices is not easy."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["introduction", "abstract", "conclusion"]}}
{"segment_id": "ml::SEG::7c9975fedb81929f0115f1fb1f7b7535121f8c4e::limitation::discussion::002", "track": "ml", "paper_id": "7c9975fedb81929f0115f1fb1f7b7535121f8c4e", "unit_id": "ml::T006", "topic_id": "T006", "year": 2022, "conference": "Conference on Empirical Methods in Natural Language Processing", "label_type": "limitation", "section": "discussion", "span_start": 0, "span_end": 1371, "text": "It is encouraging to observe the recent upward trend in releasing source code across the broad NLP community, thanks to the recent focus on reproducibility. Unsurprisingly, conferences not promoting reproducibility standards have fewer submissions with included code. Therefore, we encourage all conferences to include such standards in their submission process. Unfortunately, our results suggest that submitting the code alone does not seem to be enough, as the released code does not meet a minimum requirement for reproducibility, defined as achieving the results reported in the paper using the provided source code. We believe it is time to improve reproducibility standards to address the concerns we raise in regards to quality of the released source code. In particular, we strongly suggest shifting the focus from source code to research artifacts which include (1) a self-contained runtime environment (e.g., a Docker container or a VM image) with scripts for achieving every single result reported in the paper, (2) smaller experiments to quickly validate the integrity of the artifact, and (3) extensive documentation explaining how to run the code. We took a first step in this direction by packaging all the results in the paper in their own artifact, and releasing it with this paper. These artifacts are available through Zenodo  (Arvan et al., 2022) .", "sentences": ["Unfortunately, our results suggest that submitting the code alone does not seem to be enough, as the released code does not meet a minimum requirement for reproducibility, defined as achieving the results reported in the paper using the provided source code."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::7c9975fedb81929f0115f1fb1f7b7535121f8c4e::limitation::conclusion::003", "track": "ml", "paper_id": "7c9975fedb81929f0115f1fb1f7b7535121f8c4e", "unit_id": "ml::T006", "topic_id": "T006", "year": 2022, "conference": "Conference on Empirical Methods in Natural Language Processing", "label_type": "limitation", "section": "conclusion", "span_start": 825, "span_end": 1477, "text": "We have done our best to provide logical and stepby-step reasoning to describe our work. However, we have also identified a few limitations. First, some papers may have released their source code but not included it in their submission process, leading to inaccuracies in the trends computed based on data scraped from the ACL Anthology portal. Additionally, our reproducibility analysis only examines a small number of recent papers. To avoid the risk of selection bias, we selected the papers randomly. We believe our results were obtained from a representative sample. We have included additional information for each selected paper in Appendix A.", "sentences": ["However, we have also identified a few limitations."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::7c9975fedb81929f0115f1fb1f7b7535121f8c4e::limitation::conclusion::004", "track": "ml", "paper_id": "7c9975fedb81929f0115f1fb1f7b7535121f8c4e", "unit_id": "ml::T006", "topic_id": "T006", "year": 2022, "conference": "Conference on Empirical Methods in Natural Language Processing", "label_type": "limitation", "section": "conclusion", "span_start": 1477, "span_end": 2470, "text": "We failed to reproduce the results for six papers (75%), which may be attributed to our own lack of expertise. We allotted a similar amount of effort and time to each paper. We used this time to fix the issues and contact the authors in case we were not able to do so. In theory, we could have devoted a large enough amount of effort to each paper to reproduce it successfully. However, in practice and without help from the authors, it is unclear how long this would take, and we believe that such an approach would amount to a complete reimplementation of the original paper, which is outside of the scope of this work.\n\nFinally, in our recommendations we emphasized the importance of self-contained environments. However, this may not be achievable in every case. For instance, in the healthcare domain, datasets often contain private and sensitive information. Releasing such datasets is not an option, and thus achieving the same degree of reproducibility is not possible in those fields.", "sentences": ["However, in practice and without help from the authors, it is unclear how long this would take, and we believe that such an approach would amount to a complete reimplementation of the original paper, which is outside of the scope of this work.", "However, this may not be achievable in every case."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::284fcc96d0e51902b466ba15ac76973086a5841d::limitation::conclusion::000", "track": "ml", "paper_id": "284fcc96d0e51902b466ba15ac76973086a5841d", "unit_id": "ml::T002", "topic_id": "T002", "year": 2022, "conference": "Russian Journal of Linguistics", "label_type": "limitation", "section": "conclusion", "span_start": 894, "span_end": 1501, "text": "However, the most important feature of modern research is a vast expansion of research problems and accuracy increase resulting from the abilities of artificial neural networks to learn and modify. Artificial intelligence breakthroughs are attributable to the three main factors: new advanced self-learning algorithms, high computer speeds, and a significant increase in training data. Modern databases, as well as dictionaries and tools for the Russian language developed in recent years, allowed the authors of the special issue to address and successfully solve a number of problems of text complexity.", "sentences": ["However, the most important feature of modern research is a vast expansion of research problems and accuracy increase resulting from the abilities of artificial neural networks to learn and modify."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::44a5d4b7ab16910c101755b0d7d78594f6c58bb3::contribution::introduction::000", "track": "ml", "paper_id": "44a5d4b7ab16910c101755b0d7d78594f6c58bb3", "unit_id": "ml::T002", "topic_id": "T002", "year": 2019, "conference": "International Conference of the Pacific Association for Computaitonal Linguistics", "label_type": "contribution", "section": "introduction", "span_start": 0, "span_end": 650, "text": "In this paper, we argue that Higher-Order Unification (HOU) provides a linguistically adequate tool for modeling the semantics of focus. Building up on  (Pulman, 1995) , we develop a unificationbased analysis of focus which we show favourably compares with two prominent theories of focus, Rooth's Alternative Semantics and Krifka's Structured Meanings theory. For data which is generally viewed as a test-bed for focus theory (utterances with multiple focus operators and second occurrence expressions), we show that contrary to Rooth's and Krifka's theories, the HOU treatment yields a transparent analysis while avoiding under-and over-generation.", "sentences": ["For data which is generally viewed as a test-bed for focus theory (utterances with multiple focus operators and second occurrence expressions), we show that contrary to Rooth's and Krifka's theories, the HOU treatment yields a transparent analysis while avoiding under-and over-generation."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["introduction", "abstract", "conclusion"]}}
{"segment_id": "ml::SEG::44a5d4b7ab16910c101755b0d7d78594f6c58bb3::limitation::discussion::001", "track": "ml", "paper_id": "44a5d4b7ab16910c101755b0d7d78594f6c58bb3", "unit_id": "ml::T002", "topic_id": "T002", "year": 2019, "conference": "International Conference of the Pacific Association for Computaitonal Linguistics", "label_type": "limitation", "section": "discussion", "span_start": 2569, "span_end": 3452, "text": "(4) a. only 1 read the letters that SUE 2 sent to PAUL 1 b. G 1 (p) = Œªx.read(x, l(s, p)) c. G 1 = Œªy.Œªx.read(x, l(s, y)) d. Œªz.‚àÄP [P ‚àà ŒªyŒªx.read(x, l(s, y)) ‚àß P (z) ‚Üí P = Œªx.read(x, l(s, p))] Analysis then proceeds further and the ground equation Comparison with Rooth and Krifka As mentioned in section 4.1, under the Alternative Semantics approach, a focus operator necessarily associates with any focus occurring in its scope. Furthermore in (3b), the scope of only 1 is the whole VP read the letters that SUE 2 sent to PAUL 1 . Hence, if no quantifier raising occurs, only 1 associates with both SUE 2 and PAUL 1 . Thus in order to generate the desired reading, SUE 2 must be moved out of the scope of only 1 . However, since the NP the letters that SUE 2 sent to PAUL 1 is a scope island, quantifier raising is impossible. Hence, the desired reading cannot be generated  5  .", "sentences": ["However, since the NP the letters that SUE 2 sent to PAUL 1 is a scope island, quantifier raising is impossible."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::44a5d4b7ab16910c101755b0d7d78594f6c58bb3::limitation::conclusion::002", "track": "ml", "paper_id": "44a5d4b7ab16910c101755b0d7d78594f6c58bb3", "unit_id": "ml::T002", "topic_id": "T002", "year": 2019, "conference": "International Conference of the Pacific Association for Computaitonal Linguistics", "label_type": "limitation", "section": "conclusion", "span_start": 1614, "span_end": 2211, "text": "Clearly, our approach extends to cases of adverbial quantification. For lack of space we could not develop the theory here; let us just point out that von Fintel's criticism  (von Fintel, 1995)  of semantic approaches to focus, also applies to Krifka's Structured Meanings analysis, but not to the HOU approach presented here. Von Fintel points out that in certain cases of adverbial quantification, a focus operator associates with an unmarked focus and does not associate with a marked focus occurring in its scope -as should be clear from this article, this is unproblematic for our analysis.", "sentences": ["Von Fintel points out that in certain cases of adverbial quantification, a focus operator associates with an unmarked focus and does not associate with a marked focus occurring in its scope -as should be clear from this article, this is unproblematic for our analysis."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::b87a87e4394dd3fbd0e5167d06afdc9ce00ca42a::limitation::discussion::000", "track": "ml", "paper_id": "b87a87e4394dd3fbd0e5167d06afdc9ce00ca42a", "unit_id": "ml::T002", "topic_id": "T002", "year": 2019, "conference": "Scientometrics", "label_type": "limitation", "section": "discussion", "span_start": 10096, "span_end": 11202, "text": "Table  6  Using LDA-based topic modeling to determine 10 most popular topics in COMST and TON. We see different (more coherent) results using LDA-based topic modeling compared to the keywords-based results in Table  5 . One limitation of the analysis above is that it is based on stipulated keywords, which may exclude pertinent topics. Hence, we use Latent Dirichlet Allocation (LDA) to identify important themes within the article's body. LDA takes raw text, the number of topics and a dictionary of words as the input, and outputs the most significant topics with words from the raw data  (Blei et al. 2003) . We kept the number of latent output topics to 10 and iterated our algorithms 400 times on our dataset in order to achieve converged results. Table  6  shows the results of LDA on the COMST and TON datasets. It can be seen that the results are different from those of the results for keywords in Table  5  and refer to different topics such as smart grid, sensor networks, cognitive radios for COMST and optimization algorithms, congestion control solutions, approximation algorithms for TON.", "sentences": ["One limitation of the analysis above is that it is based on stipulated keywords, which may exclude pertinent topics."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::b87a87e4394dd3fbd0e5167d06afdc9ce00ca42a::limitation::conclusion::001", "track": "ml", "paper_id": "b87a87e4394dd3fbd0e5167d06afdc9ce00ca42a", "unit_id": "ml::T002", "topic_id": "T002", "year": 2019, "conference": "Scientometrics", "label_type": "limitation", "section": "conclusion", "span_start": 0, "span_end": 1653, "text": "In this paper, we have performed an in-depth bibliometric study of the publication trends in computer networking literature using article content and metadata of four important computer networking periodicals-IEEE Communications Surveys and Tutorials (COMST), IEEE/ACM Transactions on Networking (TON), ACM Special Interest Group on Data Communications (SIGCOMM), and IEEE International Conference on Computer Communications (INFOCOM)-gathered over the time period 2000-2017. Our work extends the state of the art in bibliometric analysis of computer networking literature by presented comprehensive analyses that shed light on the publication patterns in these journals including which kinds of articles are published where; how are journal and conference publications different in this area; and which different authors, institutes, and countries have been successful in these venues (and how). Although we cannot make strong claims about causality or the parameters responsible for the acceptance/rejection of an article since we did not have access to missing data (rejected articles), we believe that our analyses provide an insightful look into the publication culture in the networking community and can help develop a more nuanced understanding of this research field especially in the light of the limited existing bibliometric work that focused on the computer networking community. In this regard, we have also publicly shared our dataset that includes content, metadata, and citation-related information related to the articles published from 2000 to 2017 in COMST, TON, SIGCOMM, and INFOCOM as our contribution to the research community. 13", "sentences": ["Although we cannot make strong claims about causality or the parameters responsible for the acceptance/rejection of an article since we did not have access to missing data (rejected articles), we believe that our analyses provide an insightful look into the publication culture in the networking community and can help develop a more nuanced understanding of this research field especially in the light of the limited existing bibliometric work that focused on the computer networking community."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::0fe2636446cd686830da3d971b31a004d6094b3c::contribution::introduction::000", "track": "ml", "paper_id": "0fe2636446cd686830da3d971b31a004d6094b3c", "unit_id": "ml::T006", "topic_id": "T006", "year": 2020, "conference": "Findings", "label_type": "contribution", "section": "introduction", "span_start": 857, "span_end": 1831, "text": "In this work, we present CodeBERT, a bimodal pre-trained model for natural language (NL) and programming language (PL) like Python, Java, JavaScript, etc. CodeBERT captures the semantic connection between natural language and programming language, and produces general-purpose representations that can broadly support NL-PL understanding tasks (e.g. natural language code search) and generation tasks (e.g. code documentation generation). It is developed with the multilayer Transformer  (Vaswani et al., 2017) , which is adopted in a majority of large pre-trained models. In order to make use of both bimodal instances of NL-PL pairs and large amount of available unimodal codes, we train CodeBERT with a hybrid objective function, including standard masked language modeling  (Devlin et al., 2018)  and replaced token detection  (Clark et al., 2020) , where unimodal codes help to learn better generators for producing better alternative tokens for the latter objective.", "sentences": ["In this work, we present CodeBERT, a bimodal pre-trained model for natural language (NL) and programming language (PL) like Python, Java, JavaScript, etc."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["introduction", "abstract", "conclusion"]}}
{"segment_id": "ml::SEG::0fe2636446cd686830da3d971b31a004d6094b3c::future_work::conclusion::001", "track": "ml", "paper_id": "0fe2636446cd686830da3d971b31a004d6094b3c", "unit_id": "ml::T006", "topic_id": "T006", "year": 2020, "conference": "Findings", "label_type": "future_work", "section": "conclusion", "span_start": 784, "span_end": 1266, "text": "There are many potential directions for further research on this field. First, one could learn better generators with bimodal evidence or more complicated neural architecture to improve the replaced token detection objective. Second, the loss functions of CodeBERT mainly target on NL-PL understanding tasks. Although CodeBERT achieves strong BLEU scores on code-to-documentation generation, the CodeBERT itself could be further improved by generation-related learning objectives.", "sentences": ["There are many potential directions for further research on this field."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::0fe2636446cd686830da3d971b31a004d6094b3c::future_work::conclusion::002", "track": "ml", "paper_id": "0fe2636446cd686830da3d971b31a004d6094b3c", "unit_id": "ml::T006", "topic_id": "T006", "year": 2020, "conference": "Findings", "label_type": "future_work", "section": "conclusion", "span_start": 1266, "span_end": 1558, "text": "How to successfully incorporate AST into the pretraining step is also an attractive direction. Third, we plan to apply CodeBERT to more NL-PL related tasks, and extend it to more programming languages. Flexible and powerful domain/language adaptation methods are necessary to generalize well.", "sentences": ["Third, we plan to apply CodeBERT to more NL-PL related tasks, and extend it to more programming languages."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::0dac0e73dc0d6f0ebbbd45ea2e3bc60d437200e1::contribution::introduction::000", "track": "ml", "paper_id": "0dac0e73dc0d6f0ebbbd45ea2e3bc60d437200e1", "unit_id": "ml::T006", "topic_id": "T006", "year": 2022, "conference": "International Symposium on Software Testing and Analysis", "label_type": "contribution", "section": "introduction", "span_start": 718, "span_end": 997, "text": "However, to the best of our knowledge, repairing multiple programming languages' defects via a single model is still underexplored. In light of this, we propose to employ the recent pre-trained model T5 as the skeleton and build a repair model that can fix bugs across languages.", "sentences": ["In light of this, we propose to employ the recent pre-trained model T5 as the skeleton and build a repair model that can fix bugs across languages."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["introduction", "abstract", "conclusion"]}}
{"segment_id": "ml::SEG::ae17c900f9cd235f71d8e6dc13b52142f4a54fd5::contribution::introduction::000", "track": "ml", "paper_id": "ae17c900f9cd235f71d8e6dc13b52142f4a54fd5", "unit_id": "ml::T011", "topic_id": "T011", "year": 2021, "conference": "Science of Computer Programming", "label_type": "contribution", "section": "introduction", "span_start": 6830, "span_end": 7864, "text": "Second, we present a second large study in order to provide a validation of our previous energy ranking that uses a more idiomatic and day-to-day code example base. Indeed, we consider a chrestomathy repository, Rosetta Code  [27] , of alternative solutions to programming problems that is maintained with the main goal of assisting programmers in understanding syntactic or semantic aspects of programming languages outside their domain of expertise. Thus, the solutions that are gathered have a clarity and pedagogical concern, which is essentially different when compared to CLBG, whose solutions are strictly performance-oriented. To validate, we considered 9 tasks from Rosetta Code, and their solutions in (up to) the 27 programming languages that we have previously considered. With this, we are also able to study the energy efficiency of program solutions from a performance-oriented source (CLBG) and an educational source (Rosetta), allowing us to analyze how performance vs. comprehensibility affects energy consumption.", "sentences": ["Second, we present a second large study in order to provide a validation of our previous energy ranking that uses a more idiomatic and day-to-day code example base."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["introduction", "abstract", "conclusion"]}}
{"segment_id": "ml::SEG::ae17c900f9cd235f71d8e6dc13b52142f4a54fd5::contribution::introduction::001", "track": "ml", "paper_id": "ae17c900f9cd235f71d8e6dc13b52142f4a54fd5", "unit_id": "ml::T011", "topic_id": "T011", "year": 2021, "conference": "Science of Computer Programming", "label_type": "contribution", "section": "introduction", "span_start": 11489, "span_end": 12461, "text": "The remainder of this paper is organized as follows: Section 2 details previous work which was used as the basis of this paper, which includes the steps of our rigorous and strict methodology to measure and compare the energy efficiency in software languages; this section also includes the description of our data set from CLBG and the study's results. Section 3 presents a discussion and ranking on the energy efficiency of each programming language based on the results. We describe in Section 4, how we structured a new validating study based on our previous methodology in order to produce a secondary ranking using the Rosetta Code chrestomathy repository of representative programs in order to validate our prior one and understand if our results are generalizable. In Section 5 we discuss the threats that may affect the validity of the insights we are drawing. Section 6 presents the related work, and finally, in Section 7 we present the conclusions of our work.", "sentences": ["Section 6 presents the related work, and finally, in Section 7 we present the conclusions of our work."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["introduction", "abstract", "conclusion"]}}
{"segment_id": "ml::SEG::ae17c900f9cd235f71d8e6dc13b52142f4a54fd5::limitation::discussion::002", "track": "ml", "paper_id": "ae17c900f9cd235f71d8e6dc13b52142f4a54fd5", "unit_id": "ml::T011", "topic_id": "T011", "year": 2021, "conference": "Science of Computer Programming", "label_type": "limitation", "section": "discussion", "span_start": 3387, "span_end": 4532, "text": "The results of the four tasks shown in Table  11  also generally follow the CLBG-based ranking. The most energy inefficient languages in our earlier ranking -Ruby, Python, Perl -also appear in the bottom of the individual rankings. This also occurs in the other individual rankings in Tables  10  and 12 . C wins in three of these four tasks, and ranks third in the Removeduplicates task. The Remove-duplicates task, however, does not require the sorting of the resulting elements. Thus, most For the Sieve of Eratosthenes, the results presented in Table  12  are also aligned with the results obtained with CLBG. A remarkable outlier, however, is observed for the Chapel implementation: although it is very well ranked based on CLBG, it is the most inefficient language for this task! In spite of our best effort in trying to understand this corner case, we believe it deserves a more detailed study of its own, that we leave for future reference, and ideally with the involvement of an expert of Chapel. Naturally, we have confirmed that the algorithm implemented in Chapel is the correct one, and so, the result it produces is also correct.", "sentences": ["The Remove-duplicates task, however, does not require the sorting of the resulting elements.", "A remarkable outlier, however, is observed for the Chapel implementation: although it is very well ranked based on CLBG, it is the most inefficient language for this task!", "In spite of our best effort in trying to understand this corner case, we believe it deserves a more detailed study of its own, that we leave for future reference, and ideally with the involvement of an expert of Chapel."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::ae17c900f9cd235f71d8e6dc13b52142f4a54fd5::limitation::conclusion::003", "track": "ml", "paper_id": "ae17c900f9cd235f71d8e6dc13b52142f4a54fd5", "unit_id": "ml::T011", "topic_id": "T011", "year": 2021, "conference": "Science of Computer Programming", "label_type": "limitation", "section": "conclusion", "span_start": 2860, "span_end": 3248, "text": "Fishing is a possible threat as one may be searching for particular results, thus making the analysis not independent  [41] . In the case of our study, we are not evaluating a programming language(PL) that we may have proposed and hence have no particular interest in the outcome. Thus, we are not searching for a particular result, and as such, this threat does not apply to our study.", "sentences": ["Thus, we are not searching for a particular result, and as such, this threat does not apply to our study."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::ae17c900f9cd235f71d8e6dc13b52142f4a54fd5::limitation::conclusion::004", "track": "ml", "paper_id": "ae17c900f9cd235f71d8e6dc13b52142f4a54fd5", "unit_id": "ml::T011", "topic_id": "T011", "year": 2021, "conference": "Science of Computer Programming", "label_type": "limitation", "section": "conclusion", "span_start": 3248, "span_end": 4166, "text": "A common threat is the reliability of measures. In our case, when measuring the energy consumption of the various different programming languages, other factors alongside the different implementations and actual languages themselves may contribute to variations, i.e. specific versions of an interpreter or virtual machine. To avoid this, we executed every language and benchmark solution equally. In each, we measured the energy consumption (CPU and DRAM), execution time, and peak and total memory 10 times, removed the lowest and highest 20% outliers, and calculated the median, mean, standard deviation, min, and max values. This allowed us to minimize the particular states of the tested machine, including uncontrollable system processes and software. However, the measured results are quite consistent, and thus reliable. In addition, the used energy measurement tool has also been proven to be very accurate.", "sentences": ["However, the measured results are quite consistent, and thus reliable."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::ae17c900f9cd235f71d8e6dc13b52142f4a54fd5::limitation::conclusion::005", "track": "ml", "paper_id": "ae17c900f9cd235f71d8e6dc13b52142f4a54fd5", "unit_id": "ml::T011", "topic_id": "T011", "year": 2021, "conference": "Science of Computer Programming", "label_type": "limitation", "section": "conclusion", "span_start": 5139, "span_end": 5602, "text": "Instrumentation is one of the possible causes of internal validity  [41] . This refers to the artifacts used during the experiment. In our case, we used scripts to collect the energy, time and memory used during the execution of the programs. However, these are simple scripts used to call RAPL for measurement during the execution of programs. They were previously validated and tested  [23, 24]  and are also publicly available in the paper's online appendix.", "sentences": ["However, these are simple scripts used to call RAPL for measurement during the execution of programs."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::ae17c900f9cd235f71d8e6dc13b52142f4a54fd5::limitation::conclusion::006", "track": "ml", "paper_id": "ae17c900f9cd235f71d8e6dc13b52142f4a54fd5", "unit_id": "ml::T011", "topic_id": "T011", "year": 2021, "conference": "Science of Computer Programming", "label_type": "limitation", "section": "conclusion", "span_start": 6436, "span_end": 7139, "text": "Regarding the mono-method bias, we have indeed used just a single tool to measure energy and time (RAPL), and another tool for memory (the Unix-based time tool). However, both known to be very precise for measuring energy, time, and memory, thus their results are reliable. The interaction of different treatments is also a possible issue. However, we have used different and independent programs to evaluate the languages. Between each measuring execution (as common practice in measuring energy consumption), there was a two minute idle time rest to allow the system to cool-down, as to reduce over heating (which may affect energy measurements), and to allow the system to treat garbage collecting.", "sentences": ["However, both known to be very precise for measuring energy, time, and memory, thus their results are reliable.", "However, we have used different and independent programs to evaluate the languages."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::ae17c900f9cd235f71d8e6dc13b52142f4a54fd5::future_work::discussion::007", "track": "ml", "paper_id": "ae17c900f9cd235f71d8e6dc13b52142f4a54fd5", "unit_id": "ml::T011", "topic_id": "T011", "year": 2021, "conference": "Science of Computer Programming", "label_type": "future_work", "section": "discussion", "span_start": 821, "span_end": 1204, "text": "In the following subsections, we will present an analysis and discussion on the results of our study. While our main focus is on understanding the energy efficiency in languages, we will also try to understand how energy, time, and memory relate. Additionally, in this section we will try to answer the following three research questions, each with their own designated subsection.", "sentences": ["In the following subsections, we will present an analysis and discussion on the results of our study.", "While our main focus is on understanding the energy efficiency in languages, we will also try to understand how energy, time, and memory relate.", "Additionally, in this section we will try to answer the following three research questions, each with their own designated subsection."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::ae17c900f9cd235f71d8e6dc13b52142f4a54fd5::future_work::conclusion::008", "track": "ml", "paper_id": "ae17c900f9cd235f71d8e6dc13b52142f4a54fd5", "unit_id": "ml::T011", "topic_id": "T011", "year": 2021, "conference": "Science of Computer Programming", "label_type": "future_work", "section": "conclusion", "span_start": 7679, "span_end": 10116, "text": "Another external threat is the interaction of setting and treatment, that is, the experimental setting might not represent the industrial setting. Each PL was evaluated with roughly 10 solutions to the proposed problems, totaling out to almost 270 different cases. The implementation solutions we measured were developed by external experts in each of the programming languages, with the main goal of \"winning\" by producing the best solution for performance time. While the different languages contain different implementations, they were written under the same rules, all produced the same exact output, and were implemented to be the fastest and most efficient as possible. Having these different yet efficient solutions for the same scenarios allows us to compare the different programming languages in a quite just manner as they were all placed against the same problems. Moreover, the compilers and computers used are recent and thus in line with nowadays industry. For the Rosetta the solutions are not so curated. In any case, the authors have reviewed and used solutions that were correct thus solving the underlying problem. While our benchmarking system is server based, studies have shown that there is no statistical difference between server platforms and embedded systems in regards to energy based readings  [26] , thus the results can be generalized directly to embedded systems. In regards to the generalization to mobile systems, this can not be completely assured as results differ slightly between server/embedded based systems and mobile, and sometimes even between independent studies in mobile, if analyzing on a small scale. Overall however, the results seem to maintain their tendencies  [17, 4]  In general, in this category of threats it is paramount to report the characteristics of the experiment in order to understand its applicability to other contexts  [41] . The actual approach and methodology we used also favors easy replications. This can be attributed to the CLBG containing most of the important information needed to run the experiments, these being: the source code, compiler version, and compilation/execution options. Moreover, all the material used and produced is publicly available at https://sites .google .com /view /energy-efficiency-languages. Thus we believe these results can be further generalized, and other researchers and industry can replicate our methodology for future work.", "sentences": ["Thus we believe these results can be further generalized, and other researchers and industry can replicate our methodology for future work."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::ea11192b7f351071f1efaf6ce37f47bc9af6dfb4::limitation::discussion::000", "track": "ml", "paper_id": "ea11192b7f351071f1efaf6ce37f47bc9af6dfb4", "unit_id": "ml::T006", "topic_id": "T006", "year": 2020, "conference": "Scientific Reports", "label_type": "limitation", "section": "discussion", "span_start": 3575, "span_end": 5277, "text": "Though a considerable body of research has investigated the relation between individual differences in alpha power at rest and online cognitive processes  27  , the implications of differences in resting-state beta power for cognitive abilities are more mysterious. Beta oscillations, however, have become increasingly associated with online language processes 28 . They have also been related to the top-down gating of information into working memory  29  . Similarly, according to the Predictive Coding Framework  30  , beta oscillations function both to maintain dynamic representations of meaning during sentence comprehension, and to deploy top-down mechanisms that facilitate comprehension of predicted completions. Linking these theories to the current data, one recent study showed that individual differences in the ability to learn syntactic structures in an artificial grammar task were related to differences in synchronization over beta frequencies during learning  31  . A proposed connection between beta computations and resting-state measures is offered by Raichle and Schneider, who suggest that resting-state network activity reflects \"‚Ä¶ the maintenance of information for interpreting, responding to, and even predicting environmental demands\"  32  . Thus, the data reported herein contribute to a growing body of research suggesting that individual differences in beta power and coherence at rest may reflect differences in the ability to acquire and apply statistical knowledge based on sequentially presented information. This proposition is purely speculative and requires further investigations relating differences in resting-state and task-based EEG to learning parameters.", "sentences": ["Beta oscillations, however, have become increasingly associated with online language processes 28 ."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::ea11192b7f351071f1efaf6ce37f47bc9af6dfb4::future_work::discussion::001", "track": "ml", "paper_id": "ea11192b7f351071f1efaf6ce37f47bc9af6dfb4", "unit_id": "ml::T006", "topic_id": "T006", "year": 2020, "conference": "Scientific Reports", "label_type": "future_work", "section": "discussion", "span_start": 6081, "span_end": 7583, "text": "Taken together, the results reported herein provide foundational information about the neurocognitive characteristics of \"high aptitude\" learners of Python, and by virtue, about who may struggle given equal access to learning environments. We argue, as have others before us  2, 6  , that both educational and engineering practices have proceeded without this critical knowledge about why, and for whom, learning to program is difficult. Contrary to widely held stereotypes, the \"computer whisperers\" investigated herein were facile problem solvers with a high aptitude for natural languages. Although numeracy was a reliable predictor of programming aptitude, it was far from the most significant predictor. Importantly, this research also begins the process of identifying the neural characteristics of individual differences in Python learning aptitude, which can be used as targets for technologies such as neurofeedback and neurostimulation that modify patterns of connectivity and alter corresponding behaviors  33, 34  . Important future work is needed to determine the extent to which our results will translate to classroom learning environments, to less \"user friendly\" languages such as Java that are more widely employed in software engineering spaces, and to higher programming proficiency levels. Still, the research reported herein begins to paint a picture of what a good programmer actually looks like, and that picture is different in important ways from many previously held beliefs.", "sentences": ["Important future work is needed to determine the extent to which our results will translate to classroom learning environments, to less \"user friendly\" languages such as Java that are more widely employed in software engineering spaces, and to higher programming proficiency levels."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::85bfd320fd6aed25614d69d9cff71acf98d111be::contribution::introduction::000", "track": "ml", "paper_id": "85bfd320fd6aed25614d69d9cff71acf98d111be", "unit_id": "ml::T006", "topic_id": "T006", "year": 2020, "conference": "ACM Transactions on Graphics", "label_type": "contribution", "section": "introduction", "span_start": 1927, "span_end": 2295, "text": "Our contributions are twofold. First, we analyze code sharing practices and replicability in computer graphics. We hypothesize strong influence of topics, an increase of replicability over time similar to the trend observed in artificial intelligence  [Hutson 2018] , and an increased impact of replicable papers, as observed in image processing  [Vandewalle 2019 ].", "sentences": ["Our contributions are twofold."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["introduction", "abstract", "conclusion"]}}
{"segment_id": "ml::SEG::85bfd320fd6aed25614d69d9cff71acf98d111be::limitation::discussion::001", "track": "ml", "paper_id": "85bfd320fd6aed25614d69d9cff71acf98d111be", "unit_id": "ml::T006", "topic_id": "T006", "year": 2020, "conference": "ACM Transactions on Graphics", "label_type": "limitation", "section": "discussion", "span_start": 4874, "span_end": 5452, "text": "In the years covered by this study, we found a total of 5 papers with a Replicability Stamp from the Graphics Replicability Stamp Initiative  [Panozzo 2016] . While this number is too low to derive meaningful statistics, one can note that out of these 5 papers, 4 get the maximum score for results replication. This could be expected because this initiative ensures that a script for each single result shown in the paper is provided. A limitation is that these scripts are only guaranteed to work at the time when the stamp is granted -a limitation shared by the present study.", "sentences": ["A limitation is that these scripts are only guaranteed to work at the time when the stamp is granted -a limitation shared by the present study."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::85bfd320fd6aed25614d69d9cff71acf98d111be::limitation::conclusion::002", "track": "ml", "paper_id": "85bfd320fd6aed25614d69d9cff71acf98d111be", "unit_id": "ml::T006", "topic_id": "T006", "year": 2020, "conference": "ACM Transactions on Graphics", "label_type": "limitation", "section": "conclusion", "span_start": 0, "span_end": 959, "text": "Our analysis has a number of limitations. First, the data we collected may only be partly reliable. While we spent reasonable efforts to find, run and compile codes, it is possible that we missed codes, or that additional efforts or contacting the authors for clarifications or to report bugs would result in different outcome for a few papers. Similarly, we could not fully evaluate codes that depend on specific hardware (such as spatial light modulators, microcontrollers, Hall effect sensors etc.) for 4 papers. Our analysis focused on assessing the codes provided by the authors which only assesses replicability but not reproducibility: there are instances for which papers were successfully reimplemented by other teams, which falls out of our analysis scope. It could also be expected that certain codes could be available upon request ; in fact, in a few cases, the provided code relied on data only available upon request, which we did not assess.", "sentences": ["Our analysis has a number of limitations."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::85bfd320fd6aed25614d69d9cff71acf98d111be::limitation::conclusion::003", "track": "ml", "paper_id": "85bfd320fd6aed25614d69d9cff71acf98d111be", "unit_id": "ml::T006", "topic_id": "T006", "year": 2020, "conference": "ACM Transactions on Graphics", "label_type": "limitation", "section": "conclusion", "span_start": 959, "span_end": 1193, "text": "Second, the codes we found and assessed may have evolved after the paper has been published, which we cannot control. Similarly, the published code could be a cleaned-up version of the original code, or even a full reimplementation.", "sentences": ["Second, the codes we found and assessed may have evolved after the paper has been published, which we cannot control."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::85bfd320fd6aed25614d69d9cff71acf98d111be::future_work::conclusion::004", "track": "ml", "paper_id": "85bfd320fd6aed25614d69d9cff71acf98d111be", "unit_id": "ml::T006", "topic_id": "T006", "year": 2020, "conference": "ACM Transactions on Graphics", "label_type": "future_work", "section": "conclusion", "span_start": 1193, "span_end": 1514, "text": "Third, our focus on SIGGRAPH could hide a more negative picture of the entire field. We believe that the exposure SIG-GRAPH probably gives biases our results, with a tendency to find more codes here than in smaller venues. It would be an interesting future work to compare replicability across computer graphics venues.", "sentences": ["It would be an interesting future work to compare replicability across computer graphics venues."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::4405d420721847d2adf2e0fc36f1cdfe7a286f20::limitation::conclusion::000", "track": "ml", "paper_id": "4405d420721847d2adf2e0fc36f1cdfe7a286f20", "unit_id": "ml::T010", "topic_id": "T010", "year": 2020, "conference": "Mixed Reality and Three-Dimensional Computer Graphics", "label_type": "limitation", "section": "conclusion", "span_start": 157, "span_end": 959, "text": "The key techniques used in the creation of 3D models for VR are also described. The techniques including the shading and mesh editing modifiers not only help reducing the mesh size of the 3D models but also maintaining the visual realism of the models. It is particularly important to meet the demanding computation requirement of real-time interaction in VR program. Results have also shown that bevel modifiers with a few segments can enhance the visual effects compare with the loop cut modifier. However, this feature will change the mesh size of the model. The smooth shading modifiers not only maintain the complexity of the models but also enhanced the visual realism significantly. The mesh editing and shading modifiers can also be applied based on the requirement of the models in VR program.", "sentences": ["However, this feature will change the mesh size of the model."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::908dad62c0e43d80e3e3cb3c0402f7c71c70499c::limitation::discussion::000", "track": "ml", "paper_id": "908dad62c0e43d80e3e3cb3c0402f7c71c70499c", "unit_id": "ml::T011", "topic_id": "T011", "year": 2023, "conference": "arXiv.org", "label_type": "limitation", "section": "discussion", "span_start": 0, "span_end": 1059, "text": "Document analysis also faces challenges due to the limited context windows of today's transformer models. As shown in Table  1 , both open and closed source models suffer from constrained context length (up to 128k tokens for OpenAI's models). However many documents easily surpass these lengths; for example, legal or financial documents such as Annual Reports (SEC Form 10-K) can easily pass the million token mark. Moreover, many real document analysis tasks require drawing connections across multiple such lengthy documents. Anticipating these scenarios, it becomes difficult to envision blindly scaling up context as a solution to the fixed-context problem. Recent research  (Liu et al., 2023a)  also raises doubts about the utility of simply scaling contexts, since they find uneven attention distributions in large context models (the model is more capable of recalling information at the beginning or end of its context window, vs tokens in the middle). To enable reasoning across documents, more flexible memory architectures like MemGPT are needed.", "sentences": ["However many documents easily surpass these lengths; for example, legal or financial documents such as Annual Reports (SEC Form 10-K) can easily pass the million token mark."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::5cde474869cb230a29b3ba0f6f685f5162b1a1a1::limitation::conclusion::000", "track": "ml", "paper_id": "5cde474869cb230a29b3ba0f6f685f5162b1a1a1", "unit_id": "ml::T011", "topic_id": "T011", "year": 2023, "conference": "BMC Medical Education", "label_type": "limitation", "section": "conclusion", "span_start": 0, "span_end": 650, "text": "The integration of AI in healthcare has immense potential to revolutionize patient care and outcomes. AI-driven predictive analytics can enhance the accuracy, efficiency, and cost-effectiveness of disease diagnosis and clinical laboratory testing. Additionally, AI can aid in population health management and guideline establishment, providing real-time, accurate information and optimizing medication choices. Integrating AI in virtual health and mental health support has shown promise in improving patient care. However, it is important to address limitations such as bias and lack of personalization to ensure equitable and effective use of AI.", "sentences": ["However, it is important to address limitations such as bias and lack of personalization to ensure equitable and effective use of AI."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::9e8b7b0d4c628c12b6a65ab56ac5f33a35eff2e6::contribution::introduction::000", "track": "ml", "paper_id": "9e8b7b0d4c628c12b6a65ab56ac5f33a35eff2e6", "unit_id": "ml::T003", "topic_id": "T003", "year": 2023, "conference": "IEEE Transactions on Knowledge and Data Engineering", "label_type": "contribution", "section": "introduction", "span_start": 6718, "span_end": 8133, "text": "In this article, we present a forward-looking roadmap for unifying both LLMs and KGs, to leverage their respective strengths and overcome the limitations of each approach, for various downstream tasks. We propose detailed categorization, conduct comprehensive reviews, and pinpoint emerging directions in these fast-growing fields. Our main contributions are summarized as follows:\n\n1) Roadmap. We present a forward-looking roadmap for integrating LLMs and KGs. Our roadmap, consisting of three general frameworks to unify LLMs and KGs, namely, KG-enhanced LLMs, LLMaugmented KGs, and Synergized LLMs + KGs, provides guidelines for the unification of these two distinct but complementary technologies. 2) Categorization and review. For each integration framework of our roadmap, we present a detailed categorization and novel taxonomies of research on unifying LLMs and KGs. In each category, we review the research from the perspectives of different integration strategies and tasks, which provides more insights into each framework. 3) Coverage of emerging advances. We cover the advanced techniques in both LLMs and KGs. We include the discussion of state-of-the-art LLMs like ChatGPT and GPT-4 as well as the novel KGs e.g., multi-modal knowledge graphs. 4) Summary of challenges and future directions. We highlight the challenges in existing research and present several promising future research directions.", "sentences": ["In this article, we present a forward-looking roadmap for unifying both LLMs and KGs, to leverage their respective strengths and overcome the limitations of each approach, for various downstream tasks.", "We propose detailed categorization, conduct comprehensive reviews, and pinpoint emerging directions in these fast-growing fields.", "We present a forward-looking roadmap for integrating LLMs and KGs.", "For each integration framework of our roadmap, we present a detailed categorization and novel taxonomies of research on unifying LLMs and KGs."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["introduction", "abstract", "conclusion"]}}
{"segment_id": "ml::SEG::9e8b7b0d4c628c12b6a65ab56ac5f33a35eff2e6::future_work::conclusion::001", "track": "ml", "paper_id": "9e8b7b0d4c628c12b6a65ab56ac5f33a35eff2e6", "unit_id": "ml::T003", "topic_id": "T003", "year": 2023, "conference": "IEEE Transactions on Knowledge and Data Engineering", "label_type": "future_work", "section": "conclusion", "span_start": 517, "span_end": 948, "text": "We envision that there will be multiple stages (milestones) in the roadmap of unifying KGs and LLMs, as shown in Fig.  26 . In particular, we will anticipate increasing research on three stages: Stage 1: KG-enhanced LLMs, LLM-augmented KGs, Stage 2: Synergized LLMs + KGs, and Stage 3: Graph Structure Understanding, Multi-modality, Knowledge Updating. We hope that this article will provide a guideline to advance future research.", "sentences": ["In particular, we will anticipate increasing research on three stages: Stage 1: KG-enhanced LLMs, LLM-augmented KGs, Stage 2: Synergized LLMs + KGs, and Stage 3: Graph Structure Understanding, Multi-modality, Knowledge Updating."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::3950df97ea527009a32569cb7016bc3df1383dca::contribution::introduction::000", "track": "ml", "paper_id": "3950df97ea527009a32569cb7016bc3df1383dca", "unit_id": "ml::T003", "topic_id": "T003", "year": 2021, "conference": "North American Chapter of the Association for Computational Linguistics", "label_type": "contribution", "section": "introduction", "span_start": 2507, "span_end": 3878, "text": "Here we propose QA-GNN, an end-to-end LM+KG model for question answering that addresses the above two challenges. We first encode the QA context using an LM, and retrieve a KG subgraph following prior works  (Feng et al., 2020) . Our QA-GNN has two key insights: (i) Relevance scoring: Since the KG subgraph consists of all few-hop neighbors of the topic entities, some entity nodes are more relevant than others with respect to the given QA context. We hence propose KG node relevance scoring: we score each entity on the KG subgraph by concatenating the entity with the QA context and calculating the likelihood using a pretrained LM. This presents a general framework to weight information on the KG; (ii) Joint reasoning: We design a joint graph representation of the QA context and KG, where we explicitly view the QA context as an additional node (QA context node) and connect it to the topic entities in the KG subgraph as shown in Figure  1 . This joint graph, which we term the working graph, unifies the two modalities into one graph. We then augment the feature of each node with the relevance score, and design a new attention-based GNN module for reasoning. Our joint reasoning algorithm on the working graph simultaneously updates the representation of both the KG entities and the QA context node, bridging the gap between the two sources of information.", "sentences": ["Here we propose QA-GNN, an end-to-end LM+KG model for question answering that addresses the above two challenges."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["introduction", "abstract", "conclusion"]}}
{"segment_id": "ml::SEG::42b323b6df79e49c9bf5cee2a91398a7fa3d594d::limitation::conclusion::000", "track": "ml", "paper_id": "42b323b6df79e49c9bf5cee2a91398a7fa3d594d", "unit_id": "ml::T003", "topic_id": "T003", "year": 2023, "conference": "Artificial Intelligence Review", "label_type": "limitation", "section": "conclusion", "span_start": 0, "span_end": 811, "text": "Knowledge graphs have played an instrumental role in creating many intelligent services and applications for various fields. In this survey, we provided an overview of knowledge graphs in terms of opportunities and challenges. We first introduced the definitions and existing research directions regarding knowledge graphs to provide an introductory analysis of knowledge graphs. Afterward, we discussed AI systems that take advantage of knowledge graphs. Then, we presented some representative knowledge graph applications in several fields. Furthermore, we analyzed the limitations of current knowledge graph technologies, which lead to severe technical challenges. We expect this survey to spark new ideas and insightful perspectives for future research and development activities involving knowledge graphs.", "sentences": ["Furthermore, we analyzed the limitations of current knowledge graph technologies, which lead to severe technical challenges."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::fb00016c1e048b9373803add001c1ec7e877cb23::contribution::introduction::000", "track": "ml", "paper_id": "fb00016c1e048b9373803add001c1ec7e877cb23", "unit_id": "ml::T003", "topic_id": "T003", "year": 2023, "conference": "North American Chapter of the Association for Computational Linguistics", "label_type": "contribution", "section": "introduction", "span_start": 3959, "span_end": 4246, "text": "(ii) We present an evaluation methodology accompanied by metrics designed to assess the factuality of LLMs. Our metrics allow us to distinguish hallucination and missing answers, and our evaluation method, whereas entirely automated, proves to be reliable and robust (Section 2.2-2.3).", "sentences": ["(ii) We present an evaluation methodology accompanied by metrics designed to assess the factuality of LLMs."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["introduction", "abstract", "conclusion"]}}
{"segment_id": "ml::SEG::fb00016c1e048b9373803add001c1ec7e877cb23::limitation::conclusion::001", "track": "ml", "paper_id": "fb00016c1e048b9373803add001c1ec7e877cb23", "unit_id": "ml::T003", "topic_id": "T003", "year": 2023, "conference": "North American Chapter of the Association for Computational Linguistics", "label_type": "limitation", "section": "conclusion", "span_start": 0, "span_end": 1075, "text": "Taxonomy. Our work does not discuss the effectiveness of LLMs in capturing taxonomy or type hierarchies, which could be an extension of this study. Specifically, we hypothesize that LLMs can effectively incorporate type relationships (e.g., hypernyms and synonyms), even for the fine-granularity sub-types. Hence, it may no longer be worth manually constructing a very deep and complex hierarchy in the future. Robustness to question formulation. This paper primarily aims to evaluate how much an LLM \"knows\" a fact with high confidence; we thus tested various ways of formulating factual questions and selected the least ambiguous form for this study. However, this approach does not assess the model's robustness to paraphrasing or consider the diverse ways models can be queried, such as entailment or cloze-style prompts. Our supplementary experiment in Appendix A.5 suggests that varying the form of questions does not significantly impact the evaluation results. A more thorough evaluation of robustness is beyond the scope of this paper and left for future research.", "sentences": ["Our work does not discuss the effectiveness of LLMs in capturing taxonomy or type hierarchies, which could be an extension of this study."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::fb00016c1e048b9373803add001c1ec7e877cb23::limitation::conclusion::002", "track": "ml", "paper_id": "fb00016c1e048b9373803add001c1ec7e877cb23", "unit_id": "ml::T003", "topic_id": "T003", "year": 2023, "conference": "North American Chapter of the Association for Computational Linguistics", "label_type": "limitation", "section": "conclusion", "span_start": 0, "span_end": 1075, "text": "Taxonomy. Our work does not discuss the effectiveness of LLMs in capturing taxonomy or type hierarchies, which could be an extension of this study. Specifically, we hypothesize that LLMs can effectively incorporate type relationships (e.g., hypernyms and synonyms), even for the fine-granularity sub-types. Hence, it may no longer be worth manually constructing a very deep and complex hierarchy in the future. Robustness to question formulation. This paper primarily aims to evaluate how much an LLM \"knows\" a fact with high confidence; we thus tested various ways of formulating factual questions and selected the least ambiguous form for this study. However, this approach does not assess the model's robustness to paraphrasing or consider the diverse ways models can be queried, such as entailment or cloze-style prompts. Our supplementary experiment in Appendix A.5 suggests that varying the form of questions does not significantly impact the evaluation results. A more thorough evaluation of robustness is beyond the scope of this paper and left for future research.", "sentences": ["However, this approach does not assess the model's robustness to paraphrasing or consider the diverse ways models can be queried, such as entailment or cloze-style prompts.", "Our supplementary experiment in Appendix A.5 suggests that varying the form of questions does not significantly impact the evaluation results."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::fb00016c1e048b9373803add001c1ec7e877cb23::limitation::conclusion::003", "track": "ml", "paper_id": "fb00016c1e048b9373803add001c1ec7e877cb23", "unit_id": "ml::T003", "topic_id": "T003", "year": 2023, "conference": "North American Chapter of the Association for Computational Linguistics", "label_type": "limitation", "section": "conclusion", "span_start": 1075, "span_end": 1659, "text": "We introduce Head-to-Tail, the first benchmark designed to assess the ability of LLMs to internalize head, torso, and tail facts. Alongside the dataset, we present a new evaluation methodology with appropriate metrics for automatically evaluating LLMs' factuality. Our evaluation shows that even the most advanced LLMs have notable limitations in representing factual knowledge, particularly for the torso and tail entities. Accordingly, we suggest new research areas to seamlessly blend knowledge in the symbolic form and neural form. instead of \"unsure\" when the confidence is low).", "sentences": ["Our evaluation shows that even the most advanced LLMs have notable limitations in representing factual knowledge, particularly for the torso and tail entities."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::02033e83ff310f35e4623bd339982c52d926f2d5::contribution::introduction::000", "track": "ml", "paper_id": "02033e83ff310f35e4623bd339982c52d926f2d5", "unit_id": "ml::T003", "topic_id": "T003", "year": 2023, "conference": "IEEE Transactions on Knowledge and Data Engineering", "label_type": "contribution", "section": "introduction", "span_start": 2510, "span_end": 4292, "text": "So far, numerous methods have been proposed for strengthening PLMs with KGs, which can be categorized into three types: before-training enhancement, during-training enhancement, and post-training enhancement. Although there exist a few surveys  [17] -  [19]  of knowledge-enhanced PLMs, they focus on various forms of knowledge, lacking a systematic review of knowledge graph enhanced pre-trained language model (KGPLM) methods. For instance, Wei et al.  [17]  conducted a review of knowledge enhanced PLMs based on diverse knowledge sources but only covered a small set of KGPLMs. Similarly, Yang et al.  [18]  covered various forms of knowledge enhanced PLMs but provided only a partial review of KGPLMs without technical categorization. In another study, Zhen et al.  [19]  categorized knowledge enhanced PLMs into implicit incorporation and explicit incorporation methods, yet their review encompassed only a small subset of KGPLMs. Moreover, this field is rapidly evolving with numerous new technologies consistently being introduced. Therefore, to address questions of whether constructing KGs is still necessary and how to improve the knowledge modeling ability of LLMs, we present a systematic review of relevant studies. We conducted a thorough search for papers related to the keywords \"language model\" and \"knowledge graph\". Subsequently, the papers that were most relevant to KGPLM were carefully refined and categorized. In comparison with existing surveys, this paper specifically concentrates on KGPLM and covers a broader range of up-to-date papers. Furthermore, we suggest the development of knowledge graph enhanced large language models (KGLLMs) to tackle the knowledge modeling challenge in LLMs. The main contributions of this paper are summarized as follows:", "sentences": ["Therefore, to address questions of whether constructing KGs is still necessary and how to improve the knowledge modeling ability of LLMs, we present a systematic review of relevant studies."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["introduction", "abstract", "conclusion"]}}
{"segment_id": "ml::SEG::02033e83ff310f35e4623bd339982c52d926f2d5::contribution::introduction::001", "track": "ml", "paper_id": "02033e83ff310f35e4623bd339982c52d926f2d5", "unit_id": "ml::T003", "topic_id": "T003", "year": 2023, "conference": "IEEE Transactions on Knowledge and Data Engineering", "label_type": "contribution", "section": "introduction", "span_start": 4403, "span_end": 5692, "text": "‚Ä¢ We overview research on the evaluation of LLMs and draw comparisons between LLMs and KGs. ‚Ä¢ We propose to enhance LLMs with KGs and suggest some possible future research directions, which may benefit researchers in the field of LLM. The remainder of this paper is organized as follows. Section II overviews the background of LLMs. Section III categorizes the existing methods for KGPLMs and introduces representatives from each group. Section IV introduces the applications of KGPLMs. Section V discusses whether LLMs can replace KGs with the evidence from existing studies. Section VI proposes to enhance LLMs' ability to learn factual knowledge by developing KGLLMs and presents some future research directions. Section VII draws the conclusions. II. BACKGROUND PLMs learn dense and continuous representations for words, addressing the issue of feature sparsity encountered in traditional encoding methods and significantly improving performance across various NLP tasks. Consequently, PLM-based methods have gained prominence, leading to the development of various types of PLMs. Recently, PLMs have been scaled to LLMs in order to achieve even better performance. In this section, we provide a comprehensive background of PLMs and offer an overview of their historical development.", "sentences": ["‚Ä¢ We propose to enhance LLMs with KGs and suggest some possible future research directions, which may benefit researchers in the field of LLM."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["introduction", "abstract", "conclusion"]}}
{"segment_id": "ml::SEG::02033e83ff310f35e4623bd339982c52d926f2d5::limitation::discussion::002", "track": "ml", "paper_id": "02033e83ff310f35e4623bd339982c52d926f2d5", "unit_id": "ml::T003", "topic_id": "T003", "year": 2023, "conference": "IEEE Transactions on Knowledge and Data Engineering", "label_type": "limitation", "section": "discussion", "span_start": 0, "span_end": 1090, "text": "In addition to knowledge graph enhancement methods, there are also other enhancement methods that can be used to improve LLMs' factual language modeling ability. Typically, these methods include data augmentation and retrieval augmentation. Data augmentation involves refining the training data during pretraining and emphasizing informative words, emphasizing the importance of the training corpus in equipping the model with factual knowledge. Compared with knowledge graph enhancement methods, these approaches utilize implicit knowledge to model factual knowledge in text and ignore the relationships between entities. Retrieval augmentation has emerged as a widely adopted approach, allowing LLMs to retrieve external data from databases  [149]  or tools and pass it to LLMs in the form of prompts or embeddings to improve LLMs' generations. These methods can address some challenges faced by plain LLMs, such as outdated information and the inability to memorize. However, they cannot fundamentally improve LLMs' knowledge modeling ability since they do not change LLMs' parameters.", "sentences": ["However, they cannot fundamentally improve LLMs' knowledge modeling ability since they do not change LLMs' parameters."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::02033e83ff310f35e4623bd339982c52d926f2d5::limitation::discussion::003", "track": "ml", "paper_id": "02033e83ff310f35e4623bd339982c52d926f2d5", "unit_id": "ml::T003", "topic_id": "T003", "year": 2023, "conference": "IEEE Transactions on Knowledge and Data Engineering", "label_type": "limitation", "section": "discussion", "span_start": 1844, "span_end": 2362, "text": "Improving the efficiency of KGLLMs. Due to the need for preprocessing and encoding knowledge from KGs, developing KGLLMs typically requires more computational resources and time compared to plain LLMs. However, the scaling law of KGLLMs may differ from that of plain LLMs. Previous studies on KGPLMs have demonstrated that smaller KGPLMs can even outperform larger PLMs. Therefore, a comprehensive investigation of the scaling law of KGLLMs is necessary to determine the optimal parameter size for their development.", "sentences": ["However, the scaling law of KGLLMs may differ from that of plain LLMs."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::02033e83ff310f35e4623bd339982c52d926f2d5::limitation::discussion::004", "track": "ml", "paper_id": "02033e83ff310f35e4623bd339982c52d926f2d5", "unit_id": "ml::T003", "topic_id": "T003", "year": 2023, "conference": "IEEE Transactions on Knowledge and Data Engineering", "label_type": "limitation", "section": "discussion", "span_start": 2990, "span_end": 3937, "text": "Incorporating more types of knowledge. As introduced in Section III, the majority of existing KGPLMs only utilize a single modality and static KGs. However, there exist multimodal and temporal KGs that contain multimodal and temporal knowledge. These types of knowledge can complement textual and structural knowledge, enabling LLMs to learn the relationships between entities over time. Moreover, multimodal pre-trained models have gained popularity as they have been proven to improve the performance of pre-trained models on multimodal tasks  [150]  and enhance their cognitive ability. Therefore, incorporating multimodal and temporal KGs into LLMs has the potential to improve their performance, which is worth investigating. To achieve this goal, we need to align multimodal entities, design encoders capable of processing and fusing multimodal temporal data, and establish multimodal temporal learning tasks to extract useful information.", "sentences": ["However, there exist multimodal and temporal KGs that contain multimodal and temporal knowledge."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::02033e83ff310f35e4623bd339982c52d926f2d5::limitation::discussion::005", "track": "ml", "paper_id": "02033e83ff310f35e4623bd339982c52d926f2d5", "unit_id": "ml::T003", "topic_id": "T003", "year": 2023, "conference": "IEEE Transactions on Knowledge and Data Engineering", "label_type": "limitation", "section": "discussion", "span_start": 3937, "span_end": 4996, "text": "Improving the effectiveness of knowledge incorporation. By modifying inputs, model architecture, and the fine-tuning process, diverse methods have been proposed to incorporate relational triplets into PLMs. However, each method has its own set of advantages and disadvantages, with some performing well on particular tasks but underperforming on others. For example, LUKE  [76]  exhibits superior performance over 7 https://github.com/openai/chatgpt-retrieval-plugin 8 https://www.wolfram.com/wolfram-plugin-chatgpt/ 9 https://chatonai.org/expedia-chatgpt-plugin KEPLER  [85]  in most entity typing and relation classification tasks but performs worse in a few other tasks  [89] . Besides, recent experimental analysis  [151]  reveals that existing KG-PLMs integrate only a small fraction of factual knowledge. Therefore, there is still a lot of room for research on effective knowledge integration methods. Further research is required on the selection of valuable knowledge and avoiding catastrophic forgetting when faced with vast and clashing knowledge.", "sentences": ["However, each method has its own set of advantages and disadvantages, with some performing well on particular tasks but underperforming on others."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::02033e83ff310f35e4623bd339982c52d926f2d5::limitation::discussion::006", "track": "ml", "paper_id": "02033e83ff310f35e4623bd339982c52d926f2d5", "unit_id": "ml::T003", "topic_id": "T003", "year": 2023, "conference": "IEEE Transactions on Knowledge and Data Engineering", "label_type": "limitation", "section": "discussion", "span_start": 4996, "span_end": 6174, "text": "Enhancing the interpretability of KGLLMs. Although it is widely believed that KGs can enhance the interpretability of LLMs, corresponding methods have not yet been thoroughly studied. Schuff et al.  [152]  investigated whether integrating external knowledge can improve natural language inference models' explainability by evaluating the scores of generated explanations on in-domain data and special transfer datasets. However, they found that the most commonly used metrics do not consistently align with human evaluations concerning the accuracy of explanations, incorporation of common knowledge, and grammatical and labeling correctness. To provide human-understandable explanations for LLMs, Chen et al.  [153]  proposed a knowledge-enhanced interpretation module that utilizes a KG and a GNN to extract key decision signals of LLMs. Despite a few studies attempting to improve the interpretability of PLMs, it remains unclear how to leverage KGs to improve the interpretability of KGPLMs. A feasible approach may involve searching for the relevant reasoning path in KGs based on the generated content and then generating an explanatory text based on the reasoning path.", "sentences": ["However, they found that the most commonly used metrics do not consistently align with human evaluations concerning the accuracy of explanations, incorporation of common knowledge, and grammatical and labeling correctness."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::02033e83ff310f35e4623bd339982c52d926f2d5::limitation::discussion::007", "track": "ml", "paper_id": "02033e83ff310f35e4623bd339982c52d926f2d5", "unit_id": "ml::T003", "topic_id": "T003", "year": 2023, "conference": "IEEE Transactions on Knowledge and Data Engineering", "label_type": "limitation", "section": "discussion", "span_start": 6174, "span_end": 6999, "text": "Exploring domain-specific KGLLMs. Though there is already considerable research incorporating standard KGs with general PLMs, limited work has focused on domain-specific KGLLMs. However, the rise of artificial intelligence for science will lead to an increasing demand for domain-specific KGLLMs. In comparison to general LLMs, domain-specific LLMs require greater precision and specificity in incorporating domain knowledge. As a result, constructing accurate domainspecific KGs and integrating them with LLMs warrant further exploration. In order to develop domain-specific KGLLMs, it is essential to first construct a domain KG and gather relevant corpus data with the help of domain experts. Considering the generality of language patterns, it is advisable to blend common KGs with the domain-specific KG for enhancement.", "sentences": ["However, the rise of artificial intelligence for science will lead to an increasing demand for domain-specific KGLLMs."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::02033e83ff310f35e4623bd339982c52d926f2d5::limitation::conclusion::008", "track": "ml", "paper_id": "02033e83ff310f35e4623bd339982c52d926f2d5", "unit_id": "ml::T003", "topic_id": "T003", "year": 2023, "conference": "IEEE Transactions on Knowledge and Data Engineering", "label_type": "limitation", "section": "conclusion", "span_start": 0, "span_end": 1268, "text": "The phenomenal success of ChatGPT has spurred the rapid advancement of LLMs. Given the impressive performance of LLMs on a variety of NLP tasks, some researchers wonder if they can be viewed as a type of parameterized knowledge base and replace KGs. However, LLMs still fall short in recalling and correctly using factual knowledge while generating knowledge-grounded text. In order to clarify the value of KGs in the era of LLMs, a comprehensive survey on KGPLMs was conducted in this paper. We began by examining the background of PLMs and the motivation for incorporating KGs into PLMs. Next, we categorized existing KGPLMs into three categories and provided details about each category. We also reviewed the applications of KGPLMs. After that, we analyzed whether PLMs and recent LLMs can replace KGs based on existing studies. In the end, we proposed enhancing LLMs with KGs to conduct fact-aware language modeling for improving their learning of factual knowledge. This paper addresses three questions: (1) What is the value of KGs in the era of LLMs? (2) How to incorporate KGs into LLMs to improve their performance? (3) What do we need to do for the future development of KGLLM? We hope this work will stimulate additional research advancements in LLM and KG.", "sentences": ["However, LLMs still fall short in recalling and correctly using factual knowledge while generating knowledge-grounded text."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
{"segment_id": "ml::SEG::02033e83ff310f35e4623bd339982c52d926f2d5::future_work::discussion::009", "track": "ml", "paper_id": "02033e83ff310f35e4623bd339982c52d926f2d5", "unit_id": "ml::T003", "topic_id": "T003", "year": 2023, "conference": "IEEE Transactions on Knowledge and Data Engineering", "label_type": "future_work", "section": "discussion", "span_start": 3937, "span_end": 4996, "text": "Improving the effectiveness of knowledge incorporation. By modifying inputs, model architecture, and the fine-tuning process, diverse methods have been proposed to incorporate relational triplets into PLMs. However, each method has its own set of advantages and disadvantages, with some performing well on particular tasks but underperforming on others. For example, LUKE  [76]  exhibits superior performance over 7 https://github.com/openai/chatgpt-retrieval-plugin 8 https://www.wolfram.com/wolfram-plugin-chatgpt/ 9 https://chatonai.org/expedia-chatgpt-plugin KEPLER  [85]  in most entity typing and relation classification tasks but performs worse in a few other tasks  [89] . Besides, recent experimental analysis  [151]  reveals that existing KG-PLMs integrate only a small fraction of factual knowledge. Therefore, there is still a lot of room for research on effective knowledge integration methods. Further research is required on the selection of valuable knowledge and avoiding catastrophic forgetting when faced with vast and clashing knowledge.", "sentences": ["Further research is required on the selection of valuable knowledge and avoiding catastrophic forgetting when faced with vast and clashing knowledge."], "derivation": {"method": "substring_grounding+gap_merge+paragraph_expand", "gap_chars": 350, "expand_to_paragraph": true, "section_priority": ["discussion", "conclusion"]}}
