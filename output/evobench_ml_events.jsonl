{"event_id": "ml::T006::28692beece311a90f5fa1ca2ec9d0c2ce293d069::contribution::model_contribution", "track": "ml", "unit_id": "ml::T006", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2021", "methodology": ["prompting"], "source_type": "paper", "text": "In this article, we introduce the basics of this promising paradigm, describe a unified set of mathematical notations that can cover a wide variety of existing work, and organize existing work along several dimensions, e.g., the choice of pre-trained language models, prompts, and tuning strategies.", "payload": {"paper_id": "28692beece311a90f5fa1ca2ec9d0c2ce293d069", "conference": "ACM Computing Surveys", "year": 2021, "title": "Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing", "topic_id": "T006", "methods": ["prompting"], "tasks": [], "datasets": [], "metrics": []}}
{"event_id": "ml::T002::bc1022b031dc6c7019696492e8116598097a8c12::contribution::model_contribution", "track": "ml", "unit_id": "ml::T002", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2011", "methodology": [], "source_type": "paper", "text": "We propose a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including part-of-speech tagging, chunking, named entity recognition, and semantic role labeling.", "payload": {"paper_id": "bc1022b031dc6c7019696492e8116598097a8c12", "conference": "Journal of machine learning research", "year": 2011, "title": "Natural Language Processing (Almost) from Scratch", "topic_id": "T002", "methods": [], "tasks": ["ner"], "datasets": [], "metrics": []}}
{"event_id": "ml::T000::a2f38d03fd363e920494ad65a5f0ad8bd18cd60b::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T000", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2020", "methodology": ["transformer", "bert_family"], "source_type": "paper", "text": "However, while comprehensive benchmarks and leaderboards are available for the general domains (e.g., GLUE [57] and SuperGLUE [56] ), they are still a rarity in biomedical NLP.", "payload": {"paper_id": "a2f38d03fd363e920494ad65a5f0ad8bd18cd60b", "conference": "ACM Trans. Comput. Heal.", "year": 2020, "title": "Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing", "topic_id": "T000", "methods": ["transformer", "bert_family"], "tasks": ["ner", "generation", "reasoning"], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::873a581320d928249609d3c07229d5af182a379c::contribution::model_contribution", "track": "ml", "unit_id": "ml::T011", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2023", "methodology": ["gpt_family", "prompting"], "source_type": "paper", "text": "With extensive empirical studies, we demonstrate both the effectiveness and limitations of the current version of ChatGPT.", "payload": {"paper_id": "873a581320d928249609d3c07229d5af182a379c", "conference": "Conference on Empirical Methods in Natural Language Processing", "year": 2023, "title": "Is ChatGPT a General-Purpose Natural Language Processing Task Solver?", "topic_id": "T011", "methods": ["gpt_family", "prompting"], "tasks": ["qa", "summarization", "ner", "sentiment", "dialogue", "generation", "reasoning"], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::873a581320d928249609d3c07229d5af182a379c::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T011", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2023", "methodology": ["gpt_family", "prompting"], "source_type": "paper", "text": "demonstrated the effectiveness and current limitations of ChatGPT in different types of NLP tasks.", "payload": {"paper_id": "873a581320d928249609d3c07229d5af182a379c", "conference": "Conference on Empirical Methods in Natural Language Processing", "year": 2023, "title": "Is ChatGPT a General-Purpose Natural Language Processing Task Solver?", "topic_id": "T011", "methods": ["gpt_family", "prompting"], "tasks": ["qa", "summarization", "ner", "sentiment", "dialogue", "generation", "reasoning"], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::873a581320d928249609d3c07229d5af182a379c::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T011", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2023", "methodology": ["gpt_family", "prompting"], "source_type": "paper", "text": "We hope that this study can inspire future works, such as leveraging the reasoning and dialogue capabilities of ChatGPT in NLP tasks and addressing limitations of generalist models in tasks where they currently struggle with.", "payload": {"paper_id": "873a581320d928249609d3c07229d5af182a379c", "conference": "Conference on Empirical Methods in Natural Language Processing", "year": 2023, "title": "Is ChatGPT a General-Purpose Natural Language Processing Task Solver?", "topic_id": "T011", "methods": ["gpt_family", "prompting"], "tasks": ["qa", "summarization", "ner", "sentiment", "dialogue", "generation", "reasoning"], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::873a581320d928249609d3c07229d5af182a379c::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T011", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2023", "methodology": ["gpt_family", "prompting"], "source_type": "paper", "text": "This work is an empirical study on the zero-shot learning ability of ChatGPT 3 , and it has several limitations.", "payload": {"paper_id": "873a581320d928249609d3c07229d5af182a379c", "conference": "Conference on Empirical Methods in Natural Language Processing", "year": 2023, "title": "Is ChatGPT a General-Purpose Natural Language Processing Task Solver?", "topic_id": "T011", "methods": ["gpt_family", "prompting"], "tasks": ["qa", "summarization", "ner", "sentiment", "dialogue", "generation", "reasoning"], "datasets": [], "metrics": []}}
{"event_id": "ml::T002::641a9749fe546a02bbab9a86bfc91492db1c3bc5::contribution::model_contribution", "track": "ml", "unit_id": "ml::T002", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2020", "methodology": [], "source_type": "paper", "text": "We introduce Stanza, an open-source Python natural language processing toolkit supporting 66 human languages.", "payload": {"paper_id": "641a9749fe546a02bbab9a86bfc91492db1c3bc5", "conference": "Annual Meeting of the Association for Computational Linguistics", "year": 2020, "title": "Stanza: A Python Natural Language Processing Toolkit for Many Human Languages", "topic_id": "T002", "methods": [], "tasks": ["ner", "code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T002::641a9749fe546a02bbab9a86bfc91492db1c3bc5::future::scientific_future_work", "track": "ml", "unit_id": "ml::T002", "event_type": "future", "subtype": "scientific_future_work", "timestamp": "2020", "methodology": [], "source_type": "paper", "text": "For future work, we consider the following areas of improvement in the near term: ‚Ä¢ Models downloadable in Sta n z a are largely trained on a single dataset.", "payload": {"paper_id": "641a9749fe546a02bbab9a86bfc91492db1c3bc5", "conference": "Annual Meeting of the Association for Computational Linguistics", "year": 2020, "title": "Stanza: A Python Natural Language Processing Toolkit for Many Human Languages", "topic_id": "T002", "methods": [], "tasks": ["ner", "code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T000::ff7bcaa4556cb13fc7bf03e477172493546172cd::contribution::model_contribution", "track": "ml", "unit_id": "ml::T000", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2017", "methodology": ["robustness"], "source_type": "paper", "text": "For this we present a Bayesian deep learning framework combining input-dependent aleatoric uncertainty together with epistemic uncertainty.", "payload": {"paper_id": "ff7bcaa4556cb13fc7bf03e477172493546172cd", "conference": "Neural Information Processing Systems", "year": 2017, "title": "What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?", "topic_id": "T000", "methods": ["robustness"], "tasks": [], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::913d86a84afae61b51281a1bce2edbd72b7c7acb::contribution::model_contribution", "track": "ml", "unit_id": "ml::T011", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2023", "methodology": ["transformer"], "source_type": "paper", "text": "We present a comprehensive analysis of YOLO‚Äôs evolution, examining the innovations and contributions in each iteration from the original YOLO up to YOLOv8, YOLO-NAS, and YOLO with transformers.", "payload": {"paper_id": "913d86a84afae61b51281a1bce2edbd72b7c7acb", "conference": "Machine Learning and Knowledge Extraction", "year": 2023, "title": "A Comprehensive Review of YOLO Architectures in Computer Vision: From YOLOv1 to YOLOv8 and YOLO-NAS", "topic_id": "T011", "methods": ["transformer"], "tasks": [], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::ad06c8a5fd292af518f878c7ced132b61739cdd8::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T011", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2024", "methodology": [], "source_type": "paper", "text": "As a review, this paper will inevitably suffer from the following shortcomings: First, it is limited by the scope of literature and time, resulting in the failure to comprehensively cover all relevant research work.", "payload": {"paper_id": "ad06c8a5fd292af518f878c7ced132b61739cdd8", "conference": "Artificial Intelligence Review", "year": 2024, "title": "A review of convolutional neural networks in computer vision", "topic_id": "T011", "methods": [], "tasks": ["mt", "sentiment", "generation"], "datasets": ["imagenet"], "metrics": []}}
{"event_id": "ml::T011::ad06c8a5fd292af518f878c7ced132b61739cdd8::future::scientific_future_work", "track": "ml", "unit_id": "ml::T011", "event_type": "future", "subtype": "scientific_future_work", "timestamp": "2024", "methodology": [], "source_type": "paper", "text": "As a result, in future studies, we will need to sift through the relevant literature more thoroughly and deal with the subjective factors more cautiously in order to comprehend and investigate the application of CNN in computer vision in a more comprehensive and in-depth manner.", "payload": {"paper_id": "ad06c8a5fd292af518f878c7ced132b61739cdd8", "conference": "Artificial Intelligence Review", "year": 2024, "title": "A review of convolutional neural networks in computer vision", "topic_id": "T011", "methods": [], "tasks": ["mt", "sentiment", "generation"], "datasets": ["imagenet"], "metrics": []}}
{"event_id": "ml::T002::c8b25fab5608c3e033d34b4483ec47e68ba109b7::contribution::model_contribution", "track": "ml", "unit_id": "ml::T002", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2021", "methodology": ["transformer"], "source_type": "paper", "text": "To address these differences, we propose a hierarchical Transformer whose representation is computed with Shifted windows.", "payload": {"paper_id": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "conference": "IEEE International Conference on Computer Vision", "year": 2021, "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows", "topic_id": "T002", "methods": ["transformer"], "tasks": ["code", "multimodal"], "datasets": ["imagenet"], "metrics": []}}
{"event_id": "ml::T002::c8b25fab5608c3e033d34b4483ec47e68ba109b7::contribution::model_contribution", "track": "ml", "unit_id": "ml::T002", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2021", "methodology": ["transformer"], "source_type": "paper", "text": "To overcome these issues, we propose a generalpurpose Transformer backbone, called Swin Transformer, which constructs hierarchical feature maps and has linear computational complexity to image size.", "payload": {"paper_id": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "conference": "IEEE International Conference on Computer Vision", "year": 2021, "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows", "topic_id": "T002", "methods": ["transformer"], "tasks": ["code", "multimodal"], "datasets": ["imagenet"], "metrics": []}}
{"event_id": "ml::T011::6351ebb4a3287f5f3e1273464b3b91e5df5a16d7::contribution::model_contribution", "track": "ml", "unit_id": "ml::T011", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2021", "methodology": ["seq2seq"], "source_type": "paper", "text": "First, we develop an asymmetric encoder-decoder architecture, with an encoder that operates only on the visible subset of patches (without mask tokens), along with a lightweight decoder that reconstructs the original image from the latent representation and mask tokens.", "payload": {"paper_id": "6351ebb4a3287f5f3e1273464b3b91e5df5a16d7", "conference": "Computer Vision and Pattern Recognition", "year": 2021, "title": "Masked Autoencoders Are Scalable Vision Learners", "topic_id": "T011", "methods": ["seq2seq"], "tasks": [], "datasets": ["imagenet"], "metrics": [{"name": "accuracy", "value": 224.0}]}}
{"event_id": "ml::T011::6351ebb4a3287f5f3e1273464b3b91e5df5a16d7::contribution::model_contribution", "track": "ml", "unit_id": "ml::T011", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2021", "methodology": ["seq2seq"], "source_type": "paper", "text": "For each triplet, we show the masked image (left), our MAE reconstruction ‚Ä† (middle), and the ground-truth (right).", "payload": {"paper_id": "6351ebb4a3287f5f3e1273464b3b91e5df5a16d7", "conference": "Computer Vision and Pattern Recognition", "year": 2021, "title": "Masked Autoencoders Are Scalable Vision Learners", "topic_id": "T011", "methods": ["seq2seq"], "tasks": [], "datasets": ["imagenet"], "metrics": [{"name": "accuracy", "value": 224.0}]}}
{"event_id": "ml::T011::6351ebb4a3287f5f3e1273464b3b91e5df5a16d7::contribution::model_contribution", "track": "ml", "unit_id": "ml::T011", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2021", "methodology": ["seq2seq"], "source_type": "paper", "text": "To overcome this difference and encourage learning useful features, we show that a simple strategy works well in computer vision: masking a very high portion of random patches.", "payload": {"paper_id": "6351ebb4a3287f5f3e1273464b3b91e5df5a16d7", "conference": "Computer Vision and Pattern Recognition", "year": 2021, "title": "Masked Autoencoders Are Scalable Vision Learners", "topic_id": "T011", "methods": ["seq2seq"], "tasks": [], "datasets": ["imagenet"], "metrics": [{"name": "accuracy", "value": 224.0}]}}
{"event_id": "ml::T011::6351ebb4a3287f5f3e1273464b3b91e5df5a16d7::contribution::model_contribution", "track": "ml", "unit_id": "ml::T011", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2021", "methodology": ["seq2seq"], "source_type": "paper", "text": "Driven by this analysis, we present a simple, effective, and scalable form of a masked autoencoder (MAE) for visual representation learning.", "payload": {"paper_id": "6351ebb4a3287f5f3e1273464b3b91e5df5a16d7", "conference": "Computer Vision and Pattern Recognition", "year": 2021, "title": "Masked Autoencoders Are Scalable Vision Learners", "topic_id": "T011", "methods": ["seq2seq"], "tasks": [], "datasets": ["imagenet"], "metrics": [{"name": "accuracy", "value": 224.0}]}}
{"event_id": "ml::T011::6351ebb4a3287f5f3e1273464b3b91e5df5a16d7::future::scientific_future_work", "track": "ml", "unit_id": "ml::T011", "event_type": "future", "subtype": "scientific_future_work", "timestamp": "2021", "methodology": ["seq2seq"], "source_type": "paper", "text": "We hope this perspective will inspire future work.", "payload": {"paper_id": "6351ebb4a3287f5f3e1273464b3b91e5df5a16d7", "conference": "Computer Vision and Pattern Recognition", "year": 2021, "title": "Masked Autoencoders Are Scalable Vision Learners", "topic_id": "T011", "methods": ["seq2seq"], "tasks": [], "datasets": ["imagenet"], "metrics": [{"name": "accuracy", "value": 224.0}]}}
{"event_id": "ml::T011::6351ebb4a3287f5f3e1273464b3b91e5df5a16d7::future::scientific_future_work", "track": "ml", "unit_id": "ml::T011", "event_type": "future", "subtype": "scientific_future_work", "timestamp": "2021", "methodology": ["seq2seq"], "source_type": "paper", "text": "These issues warrant further research and consideration when building upon this work to generate images.", "payload": {"paper_id": "6351ebb4a3287f5f3e1273464b3b91e5df5a16d7", "conference": "Computer Vision and Pattern Recognition", "year": 2021, "title": "Masked Autoencoders Are Scalable Vision Learners", "topic_id": "T011", "methods": ["seq2seq"], "tasks": [], "datasets": ["imagenet"], "metrics": [{"name": "accuracy", "value": 224.0}]}}
{"event_id": "ml::T002::f9c602cc436a9ea2f9e7db48c77d924e09ce3c32::contribution::model_contribution", "track": "ml", "unit_id": "ml::T002", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2017", "methodology": [], "source_type": "paper", "text": "We present Fashion-MNIST, a new dataset comprising of 28x28 grayscale images of 70,000 fashion products from 10 categories, with 7,000 images per category.", "payload": {"paper_id": "f9c602cc436a9ea2f9e7db48c77d924e09ce3c32", "conference": "arXiv.org", "year": 2017, "title": "Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms", "topic_id": "T002", "methods": [], "tasks": [], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::0090023afc66cd2741568599057f4e82b566137c::contribution::model_contribution", "track": "ml", "unit_id": "ml::T011", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2019", "methodology": [], "source_type": "paper", "text": "Next, in Section 4, we present the different ways that the concept of fairness has been operationalized and studied in the literature.", "payload": {"paper_id": "0090023afc66cd2741568599057f4e82b566137c", "conference": "ACM Computing Surveys", "year": 2019, "title": "A Survey on Bias and Fairness in Machine Learning", "topic_id": "T011", "methods": [], "tasks": [], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::0090023afc66cd2741568599057f4e82b566137c::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T011", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2019", "methodology": [], "source_type": "paper", "text": "We then further subdivided the fields into a more fine-grained analysis of each subdomain and the work being done to address fairness constraints in each.", "payload": {"paper_id": "0090023afc66cd2741568599057f4e82b566137c", "conference": "ACM Computing Surveys", "year": 2019, "title": "A Survey on Bias and Fairness in Machine Learning", "topic_id": "T011", "methods": [], "tasks": [], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::0090023afc66cd2741568599057f4e82b566137c::future::scientific_future_work", "track": "ml", "unit_id": "ml::T011", "event_type": "future", "subtype": "scientific_future_work", "timestamp": "2019", "methodology": [], "source_type": "paper", "text": "Other possible future work and directions can be taken to address the existing problems and biases in AI that we discussed in the previous sections.", "payload": {"paper_id": "0090023afc66cd2741568599057f4e82b566137c", "conference": "ACM Computing Surveys", "year": 2019, "title": "A Survey on Bias and Fairness in Machine Learning", "topic_id": "T011", "methods": [], "tasks": [], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::f0dcc9aa31dc9b31b836bcac1b140c8c94a2982d::contribution::model_contribution", "track": "ml", "unit_id": "ml::T011", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2016", "methodology": [], "source_type": "paper", "text": "Using realistic datasets and classification tasks, including a hospital discharge dataset whose membership is sensitive from the privacy perspective, we show that these models can be vulnerable to membership inference attacks.", "payload": {"paper_id": "f0dcc9aa31dc9b31b836bcac1b140c8c94a2982d", "conference": "IEEE Symposium on Security and Privacy", "year": 2016, "title": "Membership Inference Attacks Against Machine Learning Models", "topic_id": "T011", "methods": [], "tasks": ["generation"], "datasets": ["cifar10"], "metrics": []}}
{"event_id": "ml::T011::f0dcc9aa31dc9b31b836bcac1b140c8c94a2982d::contribution::model_contribution", "track": "ml", "unit_id": "ml::T011", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2016", "methodology": [], "source_type": "paper", "text": "Our contributions.", "payload": {"paper_id": "f0dcc9aa31dc9b31b836bcac1b140c8c94a2982d", "conference": "IEEE Symposium on Security and Privacy", "year": 2016, "title": "Membership Inference Attacks Against Machine Learning Models", "topic_id": "T011", "methods": [], "tasks": ["generation"], "datasets": ["cifar10"], "metrics": []}}
{"event_id": "ml::T011::f0dcc9aa31dc9b31b836bcac1b140c8c94a2982d::contribution::model_contribution", "track": "ml", "unit_id": "ml::T011", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2016", "methodology": [], "source_type": "paper", "text": "All inference attacks we demonstrate in this paper are performed entirely through the services' standard APIs.", "payload": {"paper_id": "f0dcc9aa31dc9b31b836bcac1b140c8c94a2982d", "conference": "IEEE Symposium on Security and Privacy", "year": 2016, "title": "Membership Inference Attacks Against Machine Learning Models", "topic_id": "T011", "methods": [], "tasks": ["generation"], "datasets": ["cifar10"], "metrics": []}}
{"event_id": "ml::T011::f0dcc9aa31dc9b31b836bcac1b140c8c94a2982d::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T011", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2016", "methodology": [], "source_type": "paper", "text": "In the case of synthetic data generated from the target model itself, the attack does not require any prior knowledge about the distribution of the target model's training data.", "payload": {"paper_id": "f0dcc9aa31dc9b31b836bcac1b140c8c94a2982d", "conference": "IEEE Symposium on Security and Privacy", "year": 2016, "title": "Membership Inference Attacks Against Machine Learning Models", "topic_id": "T011", "methods": [], "tasks": ["generation"], "datasets": ["cifar10"], "metrics": []}}
{"event_id": "ml::T011::7872f34e2a164c5cf3c34a7a7433dc3342b6c7ea::contribution::model_contribution", "track": "ml", "unit_id": "ml::T011", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2021", "methodology": [], "source_type": "paper", "text": "In this paper, we present a comprehensive view on these machine learning algorithms that can be applied to enhance the intelligence and the capabilities of an application.", "payload": {"paper_id": "7872f34e2a164c5cf3c34a7a7433dc3342b6c7ea", "conference": "SN Computer Science", "year": 2021, "title": "Machine Learning: Algorithms, Real-World Applications and Research Directions", "topic_id": "T011", "methods": [], "tasks": [], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::f9c990b1b5724e50e5632b94fdb7484ece8a6ce7::contribution::model_contribution", "track": "ml", "unit_id": "ml::T011", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2015", "methodology": [], "source_type": "paper", "text": "By extending the fully connected LSTM (FC-LSTM) to have convolutional structures in both the input-to-state and state-to-state transitions, we propose the convolutional LSTM (ConvLSTM) and use it to build an end-to-end trainable model for the precipitation nowcasting problem.", "payload": {"paper_id": "f9c990b1b5724e50e5632b94fdb7484ece8a6ce7", "conference": "Neural Information Processing Systems", "year": 2015, "title": "Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting", "topic_id": "T011", "methods": [], "tasks": [], "datasets": [], "metrics": []}}
{"event_id": "ml::T004::807600ef43073cd9c59d4208ee710e90cf14efa8::contribution::model_contribution", "track": "ml", "unit_id": "ml::T004", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2021", "methodology": ["prompting", "sparsity_moe", "robustness"], "source_type": "paper", "text": "To address this, and to facilitate researchers to broadly evaluate the effectiveness of their models, we introduce Benchmarking-IR (BEIR), a robust and heterogeneous evaluation benchmark for information retrieval.", "payload": {"paper_id": "807600ef43073cd9c59d4208ee710e90cf14efa8", "conference": "NeurIPS Datasets and Benchmarks", "year": 2021, "title": "BEIR: A Heterogenous Benchmark for Zero-shot Evaluation of Information Retrieval Models", "topic_id": "T004", "methods": ["prompting", "sparsity_moe", "robustness"], "tasks": ["retrieval"], "datasets": [], "metrics": []}}
{"event_id": "ml::T004::4f4a409f701f7552d45c46a5b0fea69dca6f8e84::contribution::model_contribution", "track": "ml", "unit_id": "ml::T004", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2021", "methodology": ["sparsity_moe", "contrastive"], "source_type": "paper", "text": "We show that our unsupervised models can perform cross-lingual retrieval between different scripts, such as retrieving English documents from Arabic queries, which would not be possible with term matching methods.", "payload": {"paper_id": "4f4a409f701f7552d45c46a5b0fea69dca6f8e84", "conference": "Trans. Mach. Learn. Res.", "year": 2021, "title": "Unsupervised Dense Information Retrieval with Contrastive Learning", "topic_id": "T004", "methods": ["sparsity_moe", "contrastive"], "tasks": ["retrieval"], "datasets": [], "metrics": []}}
{"event_id": "ml::T000::fd1cf28a2b8caf2fe29af5e7fa9191cecfedf84d::contribution::model_contribution", "track": "ml", "unit_id": "ml::T000", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2022", "methodology": ["transformer", "robustness"], "source_type": "paper", "text": "In this paper, we present a model class, dubbed Robotics Transformer, that exhibits promising scalable model properties.", "payload": {"paper_id": "fd1cf28a2b8caf2fe29af5e7fa9191cecfedf84d", "conference": "Robotics: Science and Systems", "year": 2022, "title": "RT-1: Robotics Transformer for Real-World Control at Scale", "topic_id": "T000", "methods": ["transformer", "robustness"], "tasks": [], "datasets": [], "metrics": []}}
{"event_id": "ml::T000::fd1cf28a2b8caf2fe29af5e7fa9191cecfedf84d::contribution::model_contribution", "track": "ml", "unit_id": "ml::T000", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2022", "methodology": ["transformer", "robustness"], "source_type": "paper", "text": "We propose a novel architecture that we call RT-1 (Robotics Transformer 1), which by encoding high-dimensional inputs and outputs, including camera images, instructions and motor commands into compact token representations to be used by the Transformer, allows for efficient inference at runtime to make real-time control feasible.", "payload": {"paper_id": "fd1cf28a2b8caf2fe29af5e7fa9191cecfedf84d", "conference": "Robotics: Science and Systems", "year": 2022, "title": "RT-1: Robotics Transformer for Real-World Control at Scale", "topic_id": "T000", "methods": ["transformer", "robustness"], "tasks": [], "datasets": [], "metrics": []}}
{"event_id": "ml::T000::fd1cf28a2b8caf2fe29af5e7fa9191cecfedf84d::contribution::model_contribution", "track": "ml", "unit_id": "ml::T000", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2022", "methodology": ["transformer", "robustness"], "source_type": "paper", "text": "Our contribution is the RT-1 model and experiments with this model on a large and broad dataset of real-world robotic tasks.", "payload": {"paper_id": "fd1cf28a2b8caf2fe29af5e7fa9191cecfedf84d", "conference": "Robotics: Science and Systems", "year": 2022, "title": "RT-1: Robotics Transformer for Real-World Control at Scale", "topic_id": "T000", "methods": ["transformer", "robustness"], "tasks": [], "datasets": [], "metrics": []}}
{"event_id": "ml::T000::fd1cf28a2b8caf2fe29af5e7fa9191cecfedf84d::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T000", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2022", "methodology": ["transformer", "robustness"], "source_type": "paper", "text": "While RT-1 presents a promising step towards large-scale robot learning with an data-absorbent model, it comes with a number of limitations.", "payload": {"paper_id": "fd1cf28a2b8caf2fe29af5e7fa9191cecfedf84d", "conference": "Robotics: Science and Systems", "year": 2022, "title": "RT-1: Robotics Transformer for Real-World Control at Scale", "topic_id": "T000", "methods": ["transformer", "robustness"], "tasks": [], "datasets": [], "metrics": []}}
{"event_id": "ml::T000::fd1cf28a2b8caf2fe29af5e7fa9191cecfedf84d::future::scientific_future_work", "track": "ml", "unit_id": "ml::T000", "event_type": "future", "subtype": "scientific_future_work", "timestamp": "2022", "methodology": ["transformer", "robustness"], "source_type": "paper", "text": "We plan to continue extending the set of instructions that RT-1 enables and generalizes to to address this challenge.", "payload": {"paper_id": "fd1cf28a2b8caf2fe29af5e7fa9191cecfedf84d", "conference": "Robotics: Science and Systems", "year": 2022, "title": "RT-1: Robotics Transformer for Real-World Control at Scale", "topic_id": "T000", "methods": ["transformer", "robustness"], "tasks": [], "datasets": [], "metrics": []}}
{"event_id": "ml::T000::0ba581718f294db1d7b3dbc159cc3d3380f74606::contribution::model_contribution", "track": "ml", "unit_id": "ml::T000", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2023", "methodology": ["gpt_family", "prompting"], "source_type": "paper", "text": "We show that ChatGPT can be effective at solving several of such tasks, while allowing users to interact with it primarily via natural language instructions.", "payload": {"paper_id": "0ba581718f294db1d7b3dbc159cc3d3380f74606", "conference": "IEEE Access", "year": 2023, "title": "ChatGPT for Robotics: Design Principles and Model Abilities", "topic_id": "T000", "methods": ["gpt_family", "prompting"], "tasks": ["dialogue", "reasoning", "code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T000::0ba581718f294db1d7b3dbc159cc3d3380f74606::contribution::model_contribution", "track": "ml", "unit_id": "ml::T000", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2023", "methodology": ["gpt_family", "prompting"], "source_type": "paper", "text": "In addition to these studies, we introduce an open-sourced research tool called PromptCraft, which contains a platform where researchers can collaboratively upload and vote on examples of good prompting schemes for robotics applications, as well as a sample robotics simulator with ChatGPT integration, making it easier for users to get started with using ChatGPT for robotics.", "payload": {"paper_id": "0ba581718f294db1d7b3dbc159cc3d3380f74606", "conference": "IEEE Access", "year": 2023, "title": "ChatGPT for Robotics: Design Principles and Model Abilities", "topic_id": "T000", "methods": ["gpt_family", "prompting"], "tasks": ["dialogue", "reasoning", "code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T000::5f0b826ffe17faa2cdec21752e7d1863bd909f2c::contribution::model_contribution", "track": "ml", "unit_id": "ml::T000", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2023", "methodology": ["prompting", "alignment"], "source_type": "paper", "text": "In Section III, we present a review of how foundation models are integrated into different tasks for decision-making in robotics.", "payload": {"paper_id": "5f0b826ffe17faa2cdec21752e7d1863bd909f2c", "conference": "Int. J. Robotics Res.", "year": 2023, "title": "Foundation models in robotics: Applications, challenges, and the future", "topic_id": "T000", "methods": ["prompting", "alignment"], "tasks": ["generation", "reasoning", "code", "multimodal"], "datasets": [], "metrics": []}}
{"event_id": "ml::T000::5f0b826ffe17faa2cdec21752e7d1863bd909f2c::contribution::model_contribution", "track": "ml", "unit_id": "ml::T000", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2023", "methodology": ["prompting", "alignment"], "source_type": "paper", "text": "In Section V, we present papers about Embodied AI agents, generalist AI agents, as well as simulators and benchmarks developed for embodied AI research.", "payload": {"paper_id": "5f0b826ffe17faa2cdec21752e7d1863bd909f2c", "conference": "Int. J. Robotics Res.", "year": 2023, "title": "Foundation models in robotics: Applications, challenges, and the future", "topic_id": "T000", "methods": ["prompting", "alignment"], "tasks": ["generation", "reasoning", "code", "multimodal"], "datasets": [], "metrics": []}}
{"event_id": "ml::T000::5f0b826ffe17faa2cdec21752e7d1863bd909f2c::contribution::model_contribution", "track": "ml", "unit_id": "ml::T000", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2023", "methodology": ["prompting", "alignment"], "source_type": "paper", "text": "In the rest of this section, we introduce LLMs, vision transformers, VLMs, embodied multi-modal language models, and visual generative models.", "payload": {"paper_id": "5f0b826ffe17faa2cdec21752e7d1863bd909f2c", "conference": "Int. J. Robotics Res.", "year": 2023, "title": "Foundation models in robotics: Applications, challenges, and the future", "topic_id": "T000", "methods": ["prompting", "alignment"], "tasks": ["generation", "reasoning", "code", "multimodal"], "datasets": [], "metrics": []}}
{"event_id": "ml::T000::5f0b826ffe17faa2cdec21752e7d1863bd909f2c::contribution::model_contribution", "track": "ml", "unit_id": "ml::T000", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2023", "methodology": ["prompting", "alignment"], "source_type": "paper", "text": "In the last part of this section, we introduce different training methods that are used to train foundation models.", "payload": {"paper_id": "5f0b826ffe17faa2cdec21752e7d1863bd909f2c", "conference": "Int. J. Robotics Res.", "year": 2023, "title": "Foundation models in robotics: Applications, challenges, and the future", "topic_id": "T000", "methods": ["prompting", "alignment"], "tasks": ["generation", "reasoning", "code", "multimodal"], "datasets": [], "metrics": []}}
{"event_id": "ml::T000::5f0b826ffe17faa2cdec21752e7d1863bd909f2c::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T000", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2023", "methodology": ["prompting", "alignment"], "source_type": "paper", "text": "However, as we navigate through this paradigm shift in incorporating foundation models in robotics applications, it is imperative to recognize the challenges and potential risks that must be addressed in future research.", "payload": {"paper_id": "5f0b826ffe17faa2cdec21752e7d1863bd909f2c", "conference": "Int. J. Robotics Res.", "year": 2023, "title": "Foundation models in robotics: Applications, challenges, and the future", "topic_id": "T000", "methods": ["prompting", "alignment"], "tasks": ["generation", "reasoning", "code", "multimodal"], "datasets": [], "metrics": []}}
{"event_id": "ml::T000::5f0b826ffe17faa2cdec21752e7d1863bd909f2c::future::robustness_future_work", "track": "ml", "unit_id": "ml::T000", "event_type": "future", "subtype": "robustness_future_work", "timestamp": "2023", "methodology": ["prompting", "alignment"], "source_type": "paper", "text": "However, as we navigate through this paradigm shift in incorporating foundation models in robotics applications, it is imperative to recognize the challenges and potential risks that must be addressed in future research.", "payload": {"paper_id": "5f0b826ffe17faa2cdec21752e7d1863bd909f2c", "conference": "Int. J. Robotics Res.", "year": 2023, "title": "Foundation models in robotics: Applications, challenges, and the future", "topic_id": "T000", "methods": ["prompting", "alignment"], "tasks": ["generation", "reasoning", "code", "multimodal"], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::3396609b96dd24cac3b1542aec686ce362f32fe2::contribution::model_contribution", "track": "ml", "unit_id": "ml::T011", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2023", "methodology": ["contrastive"], "source_type": "paper", "text": "First, we demonstrate that existing representations yield inconsistent results across these tasks: masked autoencoding approaches pick up on low-level spatial features at the cost of high-level semantics, while contrastive learning approaches capture the opposite.", "payload": {"paper_id": "3396609b96dd24cac3b1542aec686ce362f32fe2", "conference": "Robotics: Science and Systems", "year": 2023, "title": "Language-Driven Representation Learning for Robotics", "topic_id": "T011", "methods": ["contrastive"], "tasks": ["generation", "reasoning", "code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::3396609b96dd24cac3b1542aec686ce362f32fe2::contribution::model_contribution", "track": "ml", "unit_id": "ml::T011", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2023", "methodology": ["contrastive"], "source_type": "paper", "text": "Motivated by this, we present Voltron, a framework for languagedriven visual representation learning for robotics that learns representations that capture both low-level and high-level features, empirically outperforming prior approaches over all applications.", "payload": {"paper_id": "3396609b96dd24cac3b1542aec686ce362f32fe2", "conference": "Robotics: Science and Systems", "year": 2023, "title": "Language-Driven Representation Learning for Robotics", "topic_id": "T011", "methods": ["contrastive"], "tasks": ["generation", "reasoning", "code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::3396609b96dd24cac3b1542aec686ce362f32fe2::contribution::model_contribution", "track": "ml", "unit_id": "ml::T011", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2023", "methodology": ["contrastive"], "source_type": "paper", "text": "We introduce a suite of evaluation problems spanning five applications within robotics, including grasp affordance prediction, referring expression grounding, single-task visuomotor control (in simulation), language-conditioned imitation learning (on a real robot), and intent scoring.", "payload": {"paper_id": "3396609b96dd24cac3b1542aec686ce362f32fe2", "conference": "Robotics: Science and Systems", "year": 2023, "title": "Language-Driven Representation Learning for Robotics", "topic_id": "T011", "methods": ["contrastive"], "tasks": ["generation", "reasoning", "code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::3396609b96dd24cac3b1542aec686ce362f32fe2::contribution::model_contribution", "track": "ml", "unit_id": "ml::T011", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2023", "methodology": ["contrastive"], "source_type": "paper", "text": "Through experiments controlling for pretraining data and model capacity, we show that the simplest Voltron representations (from V -Cond) strictly outperform both MVP and R3M representations across all evaluation domains.", "payload": {"paper_id": "3396609b96dd24cac3b1542aec686ce362f32fe2", "conference": "Robotics: Science and Systems", "year": 2023, "title": "Language-Driven Representation Learning for Robotics", "topic_id": "T011", "methods": ["contrastive"], "tasks": ["generation", "reasoning", "code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::3396609b96dd24cac3b1542aec686ce362f32fe2::contribution::model_contribution", "track": "ml", "unit_id": "ml::T011", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2023", "methodology": ["contrastive"], "source_type": "paper", "text": "Furthermore, by adapting our models to learn from multiple frame contexts and that favor generation (e.g., with V -Dual and V -Gen), we show that we can further boost performance on evaluations requiring higher-level features such as with language-conditioned policy learning (on a real robot) and intent scoring.", "payload": {"paper_id": "3396609b96dd24cac3b1542aec686ce362f32fe2", "conference": "Robotics: Science and Systems", "year": 2023, "title": "Language-Driven Representation Learning for Robotics", "topic_id": "T011", "methods": ["contrastive"], "tasks": ["generation", "reasoning", "code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::3396609b96dd24cac3b1542aec686ce362f32fe2::contribution::model_contribution", "track": "ml", "unit_id": "ml::T011", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2023", "methodology": ["contrastive"], "source_type": "paper", "text": "1) We present Voltron, a framework for languagedriven visual representation learning.", "payload": {"paper_id": "3396609b96dd24cac3b1542aec686ce362f32fe2", "conference": "Robotics: Science and Systems", "year": 2023, "title": "Language-Driven Representation Learning for Robotics", "topic_id": "T011", "methods": ["contrastive"], "tasks": ["generation", "reasoning", "code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::3396609b96dd24cac3b1542aec686ce362f32fe2::contribution::model_contribution", "track": "ml", "unit_id": "ml::T011", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2023", "methodology": ["contrastive"], "source_type": "paper", "text": "Through controlled experiments and comprehensive ablations we demonstrate that Voltron's representations strictly outperform the prior art across 2) a new evaluation suite composed of five distinct problem domains within robotics.", "payload": {"paper_id": "3396609b96dd24cac3b1542aec686ce362f32fe2", "conference": "Robotics: Science and Systems", "year": 2023, "title": "Language-Driven Representation Learning for Robotics", "topic_id": "T011", "methods": ["contrastive"], "tasks": ["generation", "reasoning", "code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::3396609b96dd24cac3b1542aec686ce362f32fe2::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T011", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2023", "methodology": ["contrastive"], "source_type": "paper", "text": "Second, the respective results for each evaluation application are on par with the corresponding results for the R-MVP model, demonstrating that the performance of Voltron models does not stem from the architecture.", "payload": {"paper_id": "3396609b96dd24cac3b1542aec686ce362f32fe2", "conference": "Robotics: Science and Systems", "year": 2023, "title": "Language-Driven Representation Learning for Robotics", "topic_id": "T011", "methods": ["contrastive"], "tasks": ["generation", "reasoning", "code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::3396609b96dd24cac3b1542aec686ce362f32fe2::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T011", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2023", "methodology": ["contrastive"], "source_type": "paper", "text": "However, we worry that with ùõº = 1, we might suffer doubly for 1) never conditioning on language, which is so clearly helpful from our results, and 2) potentially fall into the same failure mode as the R-M3AE multimodal masked autoencoder from Section ¬ß6 in the main text, overfitting to the language loss.", "payload": {"paper_id": "3396609b96dd24cac3b1542aec686ce362f32fe2", "conference": "Robotics: Science and Systems", "year": 2023, "title": "Language-Driven Representation Learning for Robotics", "topic_id": "T011", "methods": ["contrastive"], "tasks": ["generation", "reasoning", "code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::3396609b96dd24cac3b1542aec686ce362f32fe2::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T011", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2023", "methodology": ["contrastive"], "source_type": "paper", "text": "While Voltron expects a dataset of videos and associated language narrations, there is a wealth of visually diverse and relevant data that does not subscribe to this type signature:: datasets of standalone images from curated datasets [Deng et al.", "payload": {"paper_id": "3396609b96dd24cac3b1542aec686ce362f32fe2", "conference": "Robotics: Science and Systems", "year": 2023, "title": "Language-Driven Representation Learning for Robotics", "topic_id": "T011", "methods": ["contrastive"], "tasks": ["generation", "reasoning", "code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::3396609b96dd24cac3b1542aec686ce362f32fe2::future::scientific_future_work", "track": "ml", "unit_id": "ml::T011", "event_type": "future", "subtype": "scientific_future_work", "timestamp": "2023", "methodology": ["contrastive"], "source_type": "paper", "text": "A possible explanation is that the masked language modeling conditioned on visual contexts in datasets annotated with short, predictable narrations leads to degenerate representations, while generative language modeling is not susceptible to the same types of collapse; looking at ways to mitigate this seems like a promising direction for future work.", "payload": {"paper_id": "3396609b96dd24cac3b1542aec686ce362f32fe2", "conference": "Robotics: Science and Systems", "year": 2023, "title": "Language-Driven Representation Learning for Robotics", "topic_id": "T011", "methods": ["contrastive"], "tasks": ["generation", "reasoning", "code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::3396609b96dd24cac3b1542aec686ce362f32fe2::future::scientific_future_work", "track": "ml", "unit_id": "ml::T011", "event_type": "future", "subtype": "scientific_future_work", "timestamp": "2023", "methodology": ["contrastive"], "source_type": "paper", "text": "While there is not a silver bullet yet we hope that future work takes a deep, grounded look at these questions, identifying what existing representations capture -and more importantly, what they miss.", "payload": {"paper_id": "3396609b96dd24cac3b1542aec686ce362f32fe2", "conference": "Robotics: Science and Systems", "year": 2023, "title": "Language-Driven Representation Learning for Robotics", "topic_id": "T011", "methods": ["contrastive"], "tasks": ["generation", "reasoning", "code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::3396609b96dd24cac3b1542aec686ce362f32fe2::future::scientific_future_work", "track": "ml", "unit_id": "ml::T011", "event_type": "future", "subtype": "scientific_future_work", "timestamp": "2023", "methodology": ["contrastive"], "source_type": "paper", "text": "That being said, it is a promising avenue for future work to understand if this is inherent or a problem with the specific optimization procedure we used -perhaps changing the relative scaling of the two losses over the course of pretraining may mitigate this issue, or even adaptively clipping the gradient updates depending on the relative contribution of the visual reconstructor or language generator.", "payload": {"paper_id": "3396609b96dd24cac3b1542aec686ce362f32fe2", "conference": "Robotics: Science and Systems", "year": 2023, "title": "Language-Driven Representation Learning for Robotics", "topic_id": "T011", "methods": ["contrastive"], "tasks": ["generation", "reasoning", "code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::65438e0ba226c1f97bd8a36333ebc3297b1a32fd::contribution::model_contribution", "track": "ml", "unit_id": "ml::T011", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2013", "methodology": [], "source_type": "paper", "text": "By analyzing a simple problem in some detail we demonstrate how reinforcement learning approaches may be profitably applied, and we note throughout open questions and the tremendous potential for future research.", "payload": {"paper_id": "65438e0ba226c1f97bd8a36333ebc3297b1a32fd", "conference": "Int. J. Robotics Res.", "year": 2013, "title": "Reinforcement learning in robotics: A survey", "topic_id": "T011", "methods": [], "tasks": [], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::651adaa058f821a890f2c5d1053d69eb481a8352::contribution::model_contribution", "track": "ml", "unit_id": "ml::T011", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2018", "methodology": ["robustness"], "source_type": "paper", "text": "We describe characteristic behaviors of defenses exhibiting the effect, and for each of the three types of obfuscated gradients we discover, we develop attack techniques to overcome it.", "payload": {"paper_id": "651adaa058f821a890f2c5d1053d69eb481a8352", "conference": "International Conference on Machine Learning", "year": 2018, "title": "Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples", "topic_id": "T011", "methods": ["robustness"], "tasks": [], "datasets": [], "metrics": []}}
{"event_id": "ml::T006::63e2740dc581b4186b4e277a9955e8048c414521::contribution::model_contribution", "track": "ml", "unit_id": "ml::T006", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2023", "methodology": ["robustness"], "source_type": "paper", "text": "We propose a novel learning-based approach called SVEN to solve this task.", "payload": {"paper_id": "63e2740dc581b4186b4e277a9955e8048c414521", "conference": "Conference on Computer and Communications Security", "year": 2023, "title": "Large Language Models for Code: Security Hardening and Adversarial Testing", "topic_id": "T006", "methods": ["robustness"], "tasks": ["generation", "code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T009::0dee68e74a3a8b8e6f24ad27e73da295e6074dbe::contribution::model_contribution", "track": "ml", "unit_id": "ml::T009", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2022", "methodology": ["privacy_dp"], "source_type": "paper", "text": "In this paper, we present a comprehensive survey of the fundamentals, security, and privacy of metaverse.", "payload": {"paper_id": "0dee68e74a3a8b8e6f24ad27e73da295e6074dbe", "conference": "IEEE Communications Surveys and Tutorials", "year": 2022, "title": "A Survey on Metaverse: Fundamentals, Security, and Privacy", "topic_id": "T009", "methods": ["privacy_dp"], "tasks": [], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::44dc896ec1d1abf65a88a8f076515d26b54c6047::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T011", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2001", "methodology": [], "source_type": "paper", "text": "It is stressed however that the partitioning is somewhat arbitrary and all topics are of course inter-related.", "payload": {"paper_id": "44dc896ec1d1abf65a88a8f076515d26b54c6047", "conference": "Proceedings IEEE International Conference on Cluster Computing", "year": 2001, "title": "Universally composable security: a new paradigm for cryptographic protocols", "topic_id": "T011", "methods": [], "tasks": [], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::44dc896ec1d1abf65a88a8f076515d26b54c6047::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T011", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2001", "methodology": [], "source_type": "paper", "text": "It is stressed, however, that the UC theorem is, in general, false in settings where systems of ITMs cannot be simulated on a single ITM from the same class.", "payload": {"paper_id": "44dc896ec1d1abf65a88a8f076515d26b54c6047", "conference": "Proceedings IEEE International Conference on Cluster Computing", "year": 2001, "title": "Universally composable security: a new paradigm for cryptographic protocols", "topic_id": "T011", "methods": [], "tasks": [], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::44dc896ec1d1abf65a88a8f076515d26b54c6047::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T011", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2001", "methodology": [], "source_type": "paper", "text": "Then we present a protocol œÅ, that calls two sessions of the ideal protocol for F, and such that œÅ F ‚ÜíœÄ does not UC-emulate œÅ.", "payload": {"paper_id": "44dc896ec1d1abf65a88a8f076515d26b54c6047", "conference": "Proceedings IEEE International Conference on Cluster Computing", "year": 2001, "title": "Universally composable security: a new paradigm for cryptographic protocols", "topic_id": "T011", "methods": [], "tasks": [], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::44dc896ec1d1abf65a88a8f076515d26b54c6047::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T011", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2001", "methodology": [], "source_type": "paper", "text": "In fact, for any PPT œÄ we have that œÅ F ‚ÜíœÄ does not emulate œÅ.", "payload": {"paper_id": "44dc896ec1d1abf65a88a8f076515d26b54c6047", "conference": "Proceedings IEEE International Conference on Cluster Computing", "year": 2001, "title": "Universally composable security: a new paradigm for cryptographic protocols", "topic_id": "T011", "methods": [], "tasks": [], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::44dc896ec1d1abf65a88a8f076515d26b54c6047::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T011", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2001", "methodology": [], "source_type": "paper", "text": "However, œÅ F ‚ÜíœÄ never outputs success.", "payload": {"paper_id": "44dc896ec1d1abf65a88a8f076515d26b54c6047", "conference": "Proceedings IEEE International Conference on Cluster Computing", "year": 2001, "title": "Universally composable security: a new paradigm for cryptographic protocols", "topic_id": "T011", "methods": [], "tasks": [], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::44dc896ec1d1abf65a88a8f076515d26b54c6047::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T011", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2001", "methodology": [], "source_type": "paper", "text": "It also does not provide explicit ways to express leakage of information from computing devices.", "payload": {"paper_id": "44dc896ec1d1abf65a88a8f076515d26b54c6047", "conference": "Proceedings IEEE International Conference on Cluster Computing", "year": 2001, "title": "Universally composable security: a new paradigm for cryptographic protocols", "topic_id": "T011", "methods": [], "tasks": [], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::44dc896ec1d1abf65a88a8f076515d26b54c6047::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T011", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2001", "methodology": [], "source_type": "paper", "text": "Indeed, the bare model does not immediately provide natural ways to represent realistic protocols, attacks, or security requirements.", "payload": {"paper_id": "44dc896ec1d1abf65a88a8f076515d26b54c6047", "conference": "Proceedings IEEE International Conference on Cluster Computing", "year": 2001, "title": "Universally composable security: a new paradigm for cryptographic protocols", "topic_id": "T011", "methods": [], "tasks": [], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::80fd362544b593bd2250e8f5f3799882fa133ca1::contribution::model_contribution", "track": "ml", "unit_id": "ml::T011", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "1998", "methodology": ["robustness"], "source_type": "paper", "text": "We propose a new clustering algorithm called CURE that is more robust to outliers, and identifies clusters having non-spherical shapes and wide variances in size.", "payload": {"paper_id": "80fd362544b593bd2250e8f5f3799882fa133ca1", "conference": "ACM SIGMOD Conference", "year": 1998, "title": "CURE: an efficient clustering algorithm for large databases", "topic_id": "T011", "methods": ["robustness"], "tasks": [], "datasets": [], "metrics": []}}
{"event_id": "ml::T008::1c3c531fc0fbe79f97f367ed3648de8467caeeaa::contribution::model_contribution", "track": "ml", "unit_id": "ml::T008", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2024", "methodology": [], "source_type": "paper", "text": "As a result of this exploration, we introduce SWE-agent: a system that facilitates LM agents to autonomously use computers to solve software engineering tasks.", "payload": {"paper_id": "1c3c531fc0fbe79f97f367ed3648de8467caeeaa", "conference": "Neural Information Processing Systems", "year": 2024, "title": "SWE-agent: Agent-Computer Interfaces Enable Automated Software Engineering", "topic_id": "T008", "methods": [], "tasks": ["code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T008::27e57cc2f22c1921d2a1c3954d5062e3fe391553::contribution::model_contribution", "track": "ml", "unit_id": "ml::T008", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2009", "methodology": [], "source_type": "paper", "text": "We present recommended practices for software engineering case studies as well as empirically derived and evaluated checklists for researchers and readers of case study research.", "payload": {"paper_id": "27e57cc2f22c1921d2a1c3954d5062e3fe391553", "conference": "Empirical Software Engineering", "year": 2009, "title": "Guidelines for conducting and reporting case study research in software engineering", "topic_id": "T008", "methods": [], "tasks": ["qa", "generation"], "datasets": [], "metrics": []}}
{"event_id": "ml::T008::27e57cc2f22c1921d2a1c3954d5062e3fe391553::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T008", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2009", "methodology": [], "source_type": "paper", "text": "However, in practice, many cases are selected based on availability (Benbasat et al.", "payload": {"paper_id": "27e57cc2f22c1921d2a1c3954d5062e3fe391553", "conference": "Empirical Software Engineering", "year": 2009, "title": "Guidelines for conducting and reporting case study research in software engineering", "topic_id": "T008", "methods": [], "tasks": ["qa", "generation"], "datasets": [], "metrics": []}}
{"event_id": "ml::T008::27e57cc2f22c1921d2a1c3954d5062e3fe391553::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T008", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2009", "methodology": [], "source_type": "paper", "text": "However, the investigated approaches are based on existing methods that, to some extent, already have been investigated.", "payload": {"paper_id": "27e57cc2f22c1921d2a1c3954d5062e3fe391553", "conference": "Empirical Software Engineering", "year": 2009, "title": "Guidelines for conducting and reporting case study research in software engineering", "topic_id": "T008", "methods": [], "tasks": ["qa", "generation"], "datasets": [], "metrics": []}}
{"event_id": "ml::T008::27e57cc2f22c1921d2a1c3954d5062e3fe391553::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T008", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2009", "methodology": [], "source_type": "paper", "text": "However, not only can information be sensitive when leaking outside a company.", "payload": {"paper_id": "27e57cc2f22c1921d2a1c3954d5062e3fe391553", "conference": "Empirical Software Engineering", "year": 2009, "title": "Guidelines for conducting and reporting case study research in software engineering", "topic_id": "T008", "methods": [], "tasks": ["qa", "generation"], "datasets": [], "metrics": []}}
{"event_id": "ml::T008::27e57cc2f22c1921d2a1c3954d5062e3fe391553::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T008", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2009", "methodology": [], "source_type": "paper", "text": "However, it is important to remember that it is not always sufficient to remove names of companies or individuals.", "payload": {"paper_id": "27e57cc2f22c1921d2a1c3954d5062e3fe391553", "conference": "Empirical Software Engineering", "year": 2009, "title": "Guidelines for conducting and reporting case study research in software engineering", "topic_id": "T008", "methods": [], "tasks": ["qa", "generation"], "datasets": [], "metrics": []}}
{"event_id": "ml::T008::27e57cc2f22c1921d2a1c3954d5062e3fe391553::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T008", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2009", "methodology": [], "source_type": "paper", "text": "However, there would probably have been possibilities to conduct more complementary analyses in order to corroborate or develop the results from the qualitative analysis.", "payload": {"paper_id": "27e57cc2f22c1921d2a1c3954d5062e3fe391553", "conference": "Empirical Software Engineering", "year": 2009, "title": "Guidelines for conducting and reporting case study research in software engineering", "topic_id": "T008", "methods": [], "tasks": ["qa", "generation"], "datasets": [], "metrics": []}}
{"event_id": "ml::T008::27e57cc2f22c1921d2a1c3954d5062e3fe391553::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T008", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2009", "methodology": [], "source_type": "paper", "text": "However, how to do this must be decided for every case study.", "payload": {"paper_id": "27e57cc2f22c1921d2a1c3954d5062e3fe391553", "conference": "Empirical Software Engineering", "year": 2009, "title": "Guidelines for conducting and reporting case study research in software engineering", "topic_id": "T008", "methods": [], "tasks": ["qa", "generation"], "datasets": [], "metrics": []}}
{"event_id": "ml::T008::27e57cc2f22c1921d2a1c3954d5062e3fe391553::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T008", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2009", "methodology": [], "source_type": "paper", "text": "However, in some cases standard tools such as word processors and spreadsheet tools are useful when managing the textual data.", "payload": {"paper_id": "27e57cc2f22c1921d2a1c3954d5062e3fe391553", "conference": "Empirical Software Engineering", "year": 2009, "title": "Guidelines for conducting and reporting case study research in software engineering", "topic_id": "T008", "methods": [], "tasks": ["qa", "generation"], "datasets": [], "metrics": []}}
{"event_id": "ml::T008::27e57cc2f22c1921d2a1c3954d5062e3fe391553::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T008", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2009", "methodology": [], "source_type": "paper", "text": "However, this analysis would probably benefit from being conducted in a more structured way, e.g.", "payload": {"paper_id": "27e57cc2f22c1921d2a1c3954d5062e3fe391553", "conference": "Empirical Software Engineering", "year": 2009, "title": "Guidelines for conducting and reporting case study research in software engineering", "topic_id": "T008", "methods": [], "tasks": ["qa", "generation"], "datasets": [], "metrics": []}}
{"event_id": "ml::T010::420af69e5ae3686b709c14a8cec7dc9f90a85681::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T010", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2024", "methodology": ["transformer", "gpt_family", "rlhf", "privacy_dp"], "source_type": "paper", "text": "However, it is important to understand that ChatGPT should not be the sole source of information and the analysis results need to be interpreted judiciously by humans.", "payload": {"paper_id": "420af69e5ae3686b709c14a8cec7dc9f90a85681", "conference": "Frontiers Artif. Intell.", "year": 2024, "title": "ChatGPT: perspectives from human‚Äìcomputer interaction and psychology", "topic_id": "T010", "methods": ["transformer", "gpt_family", "rlhf", "privacy_dp"], "tasks": ["dialogue", "generation", "multimodal"], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::df2e4f151e8b7bf0f04712d240f6fdf7d5808725::contribution::model_contribution", "track": "ml", "unit_id": "ml::T011", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2023", "methodology": [], "source_type": "paper", "text": "We present a literature survey of past and current metrics for cognitive workload used throughout HCI literature to address this challenge.", "payload": {"paper_id": "df2e4f151e8b7bf0f04712d240f6fdf7d5808725", "conference": "ACM Computing Surveys", "year": 2023, "title": "A Survey on Measuring Cognitive Workload in Human-Computer Interaction", "topic_id": "T011", "methods": [], "tasks": [], "datasets": [], "metrics": []}}
{"event_id": "ml::T002::d89f6b942c4a8c0b09945462688290484493ed6b::contribution::model_contribution", "track": "ml", "unit_id": "ml::T002", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2023", "methodology": ["prompting", "alignment"], "source_type": "paper", "text": "We present ACL OCL, a scholarly corpus derived from the ACL Anthology to assist Open scientific research in the Computational Linguistics domain.", "payload": {"paper_id": "d89f6b942c4a8c0b09945462688290484493ed6b", "conference": "Conference on Empirical Methods in Natural Language Processing", "year": 2023, "title": "The ACL OCL Corpus: advancing Open science in Computational Linguistics", "topic_id": "T002", "methods": ["prompting", "alignment"], "tasks": ["summarization", "mt", "nli", "multimodal"], "datasets": ["mnli"], "metrics": [{"name": "accuracy", "value": 1.0}, {"name": "f1", "value": 1.0}]}}
{"event_id": "ml::T002::d89f6b942c4a8c0b09945462688290484493ed6b::contribution::model_contribution", "track": "ml", "unit_id": "ml::T002", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2023", "methodology": ["prompting", "alignment"], "source_type": "paper", "text": "We present the ACL OCL (or OCL for short), an enriched and contemporary scholarly corpus that builds upon the strengths of its predecessors while addressing their limitations.", "payload": {"paper_id": "d89f6b942c4a8c0b09945462688290484493ed6b", "conference": "Conference on Empirical Methods in Natural Language Processing", "year": 2023, "title": "The ACL OCL Corpus: advancing Open science in Computational Linguistics", "topic_id": "T002", "methods": ["prompting", "alignment"], "tasks": ["summarization", "mt", "nli", "multimodal"], "datasets": ["mnli"], "metrics": [{"name": "accuracy", "value": 1.0}, {"name": "f1", "value": 1.0}]}}
{"event_id": "ml::T002::d89f6b942c4a8c0b09945462688290484493ed6b::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T002", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2023", "methodology": ["prompting", "alignment"], "source_type": "paper", "text": "As a result, it is not a comprehensive corpus like S2ORC (Lo et al., 2020) , since it does not include any other sources beyond the ACL Anthology.", "payload": {"paper_id": "d89f6b942c4a8c0b09945462688290484493ed6b", "conference": "Conference on Empirical Methods in Natural Language Processing", "year": 2023, "title": "The ACL OCL Corpus: advancing Open science in Computational Linguistics", "topic_id": "T002", "methods": ["prompting", "alignment"], "tasks": ["summarization", "mt", "nli", "multimodal"], "datasets": ["mnli"], "metrics": [{"name": "accuracy", "value": 1.0}, {"name": "f1", "value": 1.0}]}}
{"event_id": "ml::T002::d89f6b942c4a8c0b09945462688290484493ed6b::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T002", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2023", "methodology": ["prompting", "alignment"], "source_type": "paper", "text": "Due to constraints on budget, only open-source toolkits are considered, although it is acknowledged that some paid PDF2text services might yield higher-quality full texts.", "payload": {"paper_id": "d89f6b942c4a8c0b09945462688290484493ed6b", "conference": "Conference on Empirical Methods in Natural Language Processing", "year": 2023, "title": "The ACL OCL Corpus: advancing Open science in Computational Linguistics", "topic_id": "T002", "methods": ["prompting", "alignment"], "tasks": ["summarization", "mt", "nli", "multimodal"], "datasets": ["mnli"], "metrics": [{"name": "accuracy", "value": 1.0}, {"name": "f1", "value": 1.0}]}}
{"event_id": "ml::T002::d89f6b942c4a8c0b09945462688290484493ed6b::future::scientific_future_work", "track": "ml", "unit_id": "ml::T002", "event_type": "future", "subtype": "scientific_future_work", "timestamp": "2023", "methodology": ["prompting", "alignment"], "source_type": "paper", "text": "In the future, we will work on the data currency of OCL, which aims to keep OCL up-to-date with the ACL Anthology data.", "payload": {"paper_id": "d89f6b942c4a8c0b09945462688290484493ed6b", "conference": "Conference on Empirical Methods in Natural Language Processing", "year": 2023, "title": "The ACL OCL Corpus: advancing Open science in Computational Linguistics", "topic_id": "T002", "methods": ["prompting", "alignment"], "tasks": ["summarization", "mt", "nli", "multimodal"], "datasets": ["mnli"], "metrics": [{"name": "accuracy", "value": 1.0}, {"name": "f1", "value": 1.0}]}}
{"event_id": "ml::T002::d89f6b942c4a8c0b09945462688290484493ed6b::future::scientific_future_work", "track": "ml", "unit_id": "ml::T002", "event_type": "future", "subtype": "scientific_future_work", "timestamp": "2023", "methodology": ["prompting", "alignment"], "source_type": "paper", "text": "We plan to update OCL by year to keep it alive.", "payload": {"paper_id": "d89f6b942c4a8c0b09945462688290484493ed6b", "conference": "Conference on Empirical Methods in Natural Language Processing", "year": 2023, "title": "The ACL OCL Corpus: advancing Open science in Computational Linguistics", "topic_id": "T002", "methods": ["prompting", "alignment"], "tasks": ["summarization", "mt", "nli", "multimodal"], "datasets": ["mnli"], "metrics": [{"name": "accuracy", "value": 1.0}, {"name": "f1", "value": 1.0}]}}
{"event_id": "ml::T006::7c9975fedb81929f0115f1fb1f7b7535121f8c4e::contribution::model_contribution", "track": "ml", "unit_id": "ml::T006", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2022", "methodology": [], "source_type": "paper", "text": "‚Ä¢ We propose four recommendations to address major issues affecting reproducibility.", "payload": {"paper_id": "7c9975fedb81929f0115f1fb1f7b7535121f8c4e", "conference": "Conference on Empirical Methods in Natural Language Processing", "year": 2022, "title": "Reproducibility in Computational Linguistics: Is Source Code Enough?", "topic_id": "T006", "methods": [], "tasks": ["generation", "code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T006::7c9975fedb81929f0115f1fb1f7b7535121f8c4e::contribution::model_contribution", "track": "ml", "unit_id": "ml::T006", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2022", "methodology": [], "source_type": "paper", "text": "Unfortunately, as we show in the following sections, reproducing publications that follow these good practices is not easy.", "payload": {"paper_id": "7c9975fedb81929f0115f1fb1f7b7535121f8c4e", "conference": "Conference on Empirical Methods in Natural Language Processing", "year": 2022, "title": "Reproducibility in Computational Linguistics: Is Source Code Enough?", "topic_id": "T006", "methods": [], "tasks": ["generation", "code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T006::7c9975fedb81929f0115f1fb1f7b7535121f8c4e::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T006", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2022", "methodology": [], "source_type": "paper", "text": "Unfortunately, our results suggest that submitting the code alone does not seem to be enough, as the released code does not meet a minimum requirement for reproducibility, defined as achieving the results reported in the paper using the provided source code.", "payload": {"paper_id": "7c9975fedb81929f0115f1fb1f7b7535121f8c4e", "conference": "Conference on Empirical Methods in Natural Language Processing", "year": 2022, "title": "Reproducibility in Computational Linguistics: Is Source Code Enough?", "topic_id": "T006", "methods": [], "tasks": ["generation", "code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T006::7c9975fedb81929f0115f1fb1f7b7535121f8c4e::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T006", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2022", "methodology": [], "source_type": "paper", "text": "However, we have also identified a few limitations.", "payload": {"paper_id": "7c9975fedb81929f0115f1fb1f7b7535121f8c4e", "conference": "Conference on Empirical Methods in Natural Language Processing", "year": 2022, "title": "Reproducibility in Computational Linguistics: Is Source Code Enough?", "topic_id": "T006", "methods": [], "tasks": ["generation", "code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T006::7c9975fedb81929f0115f1fb1f7b7535121f8c4e::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T006", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2022", "methodology": [], "source_type": "paper", "text": "However, in practice and without help from the authors, it is unclear how long this would take, and we believe that such an approach would amount to a complete reimplementation of the original paper, which is outside of the scope of this work.", "payload": {"paper_id": "7c9975fedb81929f0115f1fb1f7b7535121f8c4e", "conference": "Conference on Empirical Methods in Natural Language Processing", "year": 2022, "title": "Reproducibility in Computational Linguistics: Is Source Code Enough?", "topic_id": "T006", "methods": [], "tasks": ["generation", "code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T006::7c9975fedb81929f0115f1fb1f7b7535121f8c4e::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T006", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2022", "methodology": [], "source_type": "paper", "text": "However, this may not be achievable in every case.", "payload": {"paper_id": "7c9975fedb81929f0115f1fb1f7b7535121f8c4e", "conference": "Conference on Empirical Methods in Natural Language Processing", "year": 2022, "title": "Reproducibility in Computational Linguistics: Is Source Code Enough?", "topic_id": "T006", "methods": [], "tasks": ["generation", "code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T002::284fcc96d0e51902b466ba15ac76973086a5841d::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T002", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2022", "methodology": [], "source_type": "paper", "text": "However, the most important feature of modern research is a vast expansion of research problems and accuracy increase resulting from the abilities of artificial neural networks to learn and modify.", "payload": {"paper_id": "284fcc96d0e51902b466ba15ac76973086a5841d", "conference": "Russian Journal of Linguistics", "year": 2022, "title": "Computational linguistics and discourse complexology: Paradigms and research methods", "topic_id": "T002", "methods": [], "tasks": ["mt", "retrieval", "generation"], "datasets": [], "metrics": []}}
{"event_id": "ml::T002::44a5d4b7ab16910c101755b0d7d78594f6c58bb3::contribution::model_contribution", "track": "ml", "unit_id": "ml::T002", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2019", "methodology": [], "source_type": "paper", "text": "Building up on (Pulman, 1995) , we develop a unificationbased analysis of focus which we show favourably compares with two prominent theories of focus, Rooth's Alternative Semantics and Krifka's Structured Meanings theory.", "payload": {"paper_id": "44a5d4b7ab16910c101755b0d7d78594f6c58bb3", "conference": "International Conference of the Pacific Association for Computaitonal Linguistics", "year": 2019, "title": "Computational Linguistics: 16th International Conference of the Pacific Association for Computational Linguistics, PACLING 2019, Hanoi, Vietnam, October 11‚Äì13, 2019, Revised Selected Papers", "topic_id": "T002", "methods": [], "tasks": [], "datasets": [], "metrics": []}}
{"event_id": "ml::T002::44a5d4b7ab16910c101755b0d7d78594f6c58bb3::contribution::model_contribution", "track": "ml", "unit_id": "ml::T002", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2019", "methodology": [], "source_type": "paper", "text": "For data which is generally viewed as a test-bed for focus theory (utterances with multiple focus operators and second occurrence expressions), we show that contrary to Rooth's and Krifka's theories, the HOU treatment yields a transparent analysis while avoiding under-and over-generation.", "payload": {"paper_id": "44a5d4b7ab16910c101755b0d7d78594f6c58bb3", "conference": "International Conference of the Pacific Association for Computaitonal Linguistics", "year": 2019, "title": "Computational Linguistics: 16th International Conference of the Pacific Association for Computational Linguistics, PACLING 2019, Hanoi, Vietnam, October 11‚Äì13, 2019, Revised Selected Papers", "topic_id": "T002", "methods": [], "tasks": [], "datasets": [], "metrics": []}}
{"event_id": "ml::T002::44a5d4b7ab16910c101755b0d7d78594f6c58bb3::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T002", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2019", "methodology": [], "source_type": "paper", "text": "However, since the NP the letters that SUE 2 sent to PAUL 1 is a scope island, quantifier raising is impossible.", "payload": {"paper_id": "44a5d4b7ab16910c101755b0d7d78594f6c58bb3", "conference": "International Conference of the Pacific Association for Computaitonal Linguistics", "year": 2019, "title": "Computational Linguistics: 16th International Conference of the Pacific Association for Computational Linguistics, PACLING 2019, Hanoi, Vietnam, October 11‚Äì13, 2019, Revised Selected Papers", "topic_id": "T002", "methods": [], "tasks": [], "datasets": [], "metrics": []}}
{"event_id": "ml::T002::44a5d4b7ab16910c101755b0d7d78594f6c58bb3::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T002", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2019", "methodology": [], "source_type": "paper", "text": "Von Fintel points out that in certain cases of adverbial quantification, a focus operator associates with an unmarked focus and does not associate with a marked focus occurring in its scope -as should be clear from this article, this is unproblematic for our analysis.", "payload": {"paper_id": "44a5d4b7ab16910c101755b0d7d78594f6c58bb3", "conference": "International Conference of the Pacific Association for Computaitonal Linguistics", "year": 2019, "title": "Computational Linguistics: 16th International Conference of the Pacific Association for Computational Linguistics, PACLING 2019, Hanoi, Vietnam, October 11‚Äì13, 2019, Revised Selected Papers", "topic_id": "T002", "methods": [], "tasks": [], "datasets": [], "metrics": []}}
{"event_id": "ml::T014::a1b751e594bcffd85cc15788d603b700a7f56e2c::contribution::model_contribution", "track": "ml", "unit_id": "ml::T014", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2022", "methodology": [], "source_type": "paper", "text": "Moreover, we propose the concurrent use of multiple communication paths of a SmartNIC and present a pioneering guideline to expose new optimization opportunities for various distributed systems.", "payload": {"paper_id": "a1b751e594bcffd85cc15788d603b700a7f56e2c", "conference": "USENIX Symposium on Operating Systems Design and Implementation", "year": 2022, "title": "Characterizing Off-path SmartNIC for Accelerating Distributed Systems", "topic_id": "T014", "methods": [], "tasks": [], "datasets": [], "metrics": []}}
{"event_id": "ml::T002::b87a87e4394dd3fbd0e5167d06afdc9ce00ca42a::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T002", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2019", "methodology": [], "source_type": "paper", "text": "One limitation of the analysis above is that it is based on stipulated keywords, which may exclude pertinent topics.", "payload": {"paper_id": "b87a87e4394dd3fbd0e5167d06afdc9ce00ca42a", "conference": "Scientometrics", "year": 2019, "title": "A bibliometric analysis of publications in computer networking research", "topic_id": "T002", "methods": [], "tasks": [], "datasets": [], "metrics": []}}
{"event_id": "ml::T002::b87a87e4394dd3fbd0e5167d06afdc9ce00ca42a::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T002", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2019", "methodology": [], "source_type": "paper", "text": "Although we cannot make strong claims about causality or the parameters responsible for the acceptance/rejection of an article since we did not have access to missing data (rejected articles), we believe that our analyses provide an insightful look into the publication culture in the networking community and can help develop a more nuanced understanding of this research field especially in the light of the limited existing bibliometric work that focused on the computer networking community.", "payload": {"paper_id": "b87a87e4394dd3fbd0e5167d06afdc9ce00ca42a", "conference": "Scientometrics", "year": 2019, "title": "A bibliometric analysis of publications in computer networking research", "topic_id": "T002", "methods": [], "tasks": [], "datasets": [], "metrics": []}}
{"event_id": "ml::T006::0fe2636446cd686830da3d971b31a004d6094b3c::contribution::model_contribution", "track": "ml", "unit_id": "ml::T006", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2020", "methodology": ["transformer", "prompting"], "source_type": "paper", "text": "We present CodeBERT, a bimodal pre-trained model for programming language (PL) and natural language (NL).", "payload": {"paper_id": "0fe2636446cd686830da3d971b31a004d6094b3c", "conference": "Findings", "year": 2020, "title": "CodeBERT: A Pre-Trained Model for Programming and Natural Languages", "topic_id": "T006", "methods": ["transformer", "prompting"], "tasks": ["generation", "code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T006::0fe2636446cd686830da3d971b31a004d6094b3c::contribution::model_contribution", "track": "ml", "unit_id": "ml::T006", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2020", "methodology": ["transformer", "prompting"], "source_type": "paper", "text": "We develop CodeBERT with Transformer-based neural architecture, and train it with a hybrid objective function that incorporates the pre-training task of replaced token detection, which is to detect plausible alternatives sampled from generators.", "payload": {"paper_id": "0fe2636446cd686830da3d971b31a004d6094b3c", "conference": "Findings", "year": 2020, "title": "CodeBERT: A Pre-Trained Model for Programming and Natural Languages", "topic_id": "T006", "methods": ["transformer", "prompting"], "tasks": ["generation", "code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T006::0fe2636446cd686830da3d971b31a004d6094b3c::contribution::model_contribution", "track": "ml", "unit_id": "ml::T006", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2020", "methodology": ["transformer", "prompting"], "source_type": "paper", "text": "In this work, we present CodeBERT, a bimodal pre-trained model for natural language (NL) and programming language (PL) like Python, Java, JavaScript, etc.", "payload": {"paper_id": "0fe2636446cd686830da3d971b31a004d6094b3c", "conference": "Findings", "year": 2020, "title": "CodeBERT: A Pre-Trained Model for Programming and Natural Languages", "topic_id": "T006", "methods": ["transformer", "prompting"], "tasks": ["generation", "code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T006::0fe2636446cd686830da3d971b31a004d6094b3c::future::scientific_future_work", "track": "ml", "unit_id": "ml::T006", "event_type": "future", "subtype": "scientific_future_work", "timestamp": "2020", "methodology": ["transformer", "prompting"], "source_type": "paper", "text": "There are many potential directions for further research on this field.", "payload": {"paper_id": "0fe2636446cd686830da3d971b31a004d6094b3c", "conference": "Findings", "year": 2020, "title": "CodeBERT: A Pre-Trained Model for Programming and Natural Languages", "topic_id": "T006", "methods": ["transformer", "prompting"], "tasks": ["generation", "code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T006::0fe2636446cd686830da3d971b31a004d6094b3c::future::scientific_future_work", "track": "ml", "unit_id": "ml::T006", "event_type": "future", "subtype": "scientific_future_work", "timestamp": "2020", "methodology": ["transformer", "prompting"], "source_type": "paper", "text": "Third, we plan to apply CodeBERT to more NL-PL related tasks, and extend it to more programming languages.", "payload": {"paper_id": "0fe2636446cd686830da3d971b31a004d6094b3c", "conference": "Findings", "year": 2020, "title": "CodeBERT: A Pre-Trained Model for Programming and Natural Languages", "topic_id": "T006", "methods": ["transformer", "prompting"], "tasks": ["generation", "code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T006::df56748cd4f52a58973b4ac52c0bf9156c5f52f0::contribution::model_contribution", "track": "ml", "unit_id": "ml::T006", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2020", "methodology": [], "source_type": "paper", "text": "In this paper, we propose to leverage recent approaches in unsupervised machine translation to train a fully unsupervised neural transcompiler.", "payload": {"paper_id": "df56748cd4f52a58973b4ac52c0bf9156c5f52f0", "conference": "Neural Information Processing Systems", "year": 2020, "title": "Unsupervised Translation of Programming Languages", "topic_id": "T006", "methods": [], "tasks": ["mt", "code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T006::df56748cd4f52a58973b4ac52c0bf9156c5f52f0::contribution::model_contribution", "track": "ml", "unit_id": "ml::T006", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2020", "methodology": [], "source_type": "paper", "text": "We show that our model outperforms rule-based commercial baselines by a significant margin.", "payload": {"paper_id": "df56748cd4f52a58973b4ac52c0bf9156c5f52f0", "conference": "Neural Information Processing Systems", "year": 2020, "title": "Unsupervised Translation of Programming Languages", "topic_id": "T006", "methods": [], "tasks": ["mt", "code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T006::0dac0e73dc0d6f0ebbbd45ea2e3bc60d437200e1::contribution::model_contribution", "track": "ml", "unit_id": "ml::T006", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2022", "methodology": [], "source_type": "paper", "text": "In light of this, we propose to employ the recent pre-trained model T5 as the skeleton and build a repair model that can fix bugs across languages.", "payload": {"paper_id": "0dac0e73dc0d6f0ebbbd45ea2e3bc60d437200e1", "conference": "International Symposium on Software Testing and Analysis", "year": 2022, "title": "CIRCLE: continual repair across programming languages", "topic_id": "T006", "methods": [], "tasks": ["mt", "generation", "code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T006::3a1efac4a8aa2f40a8128e034c01f18660652dd5::contribution::model_contribution", "track": "ml", "unit_id": "ml::T006", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2021", "methodology": ["bert_family"], "source_type": "paper", "text": "In this paper, we introduce a new pre-training objective, DOBF, that leverages the structural aspect of programming languages and pre-trains a model to recover the original version of obfuscated source code.", "payload": {"paper_id": "3a1efac4a8aa2f40a8128e034c01f18660652dd5", "conference": "Neural Information Processing Systems", "year": 2021, "title": "DOBF: A Deobfuscation Pre-Training Objective for Programming Languages", "topic_id": "T006", "methods": ["bert_family"], "tasks": ["code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T006::3a1efac4a8aa2f40a8128e034c01f18660652dd5::contribution::model_contribution", "track": "ml", "unit_id": "ml::T006", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2021", "methodology": ["bert_family"], "source_type": "paper", "text": "We show that models pre-trained with DOBF significantly outperform existing approaches on multiple downstream tasks, providing relative improvements of up to 13% in unsupervised code translation, and 24% in natural language code search.", "payload": {"paper_id": "3a1efac4a8aa2f40a8128e034c01f18660652dd5", "conference": "Neural Information Processing Systems", "year": 2021, "title": "DOBF: A Deobfuscation Pre-Training Objective for Programming Languages", "topic_id": "T006", "methods": ["bert_family"], "tasks": ["code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::ae17c900f9cd235f71d8e6dc13b52142f4a54fd5::contribution::model_contribution", "track": "ml", "unit_id": "ml::T011", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2021", "methodology": [], "source_type": "paper", "text": "Second, we present a second large study in order to provide a validation of our previous energy ranking that uses a more idiomatic and day-to-day code example base.", "payload": {"paper_id": "ae17c900f9cd235f71d8e6dc13b52142f4a54fd5", "conference": "Science of Computer Programming", "year": 2021, "title": "Ranking programming languages by energy efficiency", "topic_id": "T011", "methods": [], "tasks": ["code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::ae17c900f9cd235f71d8e6dc13b52142f4a54fd5::contribution::model_contribution", "track": "ml", "unit_id": "ml::T011", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2021", "methodology": [], "source_type": "paper", "text": "Thus, in this paper we present and answer the following research questions: ‚Ä¢ RQ1: Can we compare the energy efficiency of software languages?", "payload": {"paper_id": "ae17c900f9cd235f71d8e6dc13b52142f4a54fd5", "conference": "Science of Computer Programming", "year": 2021, "title": "Ranking programming languages by energy efficiency", "topic_id": "T011", "methods": [], "tasks": ["code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::ae17c900f9cd235f71d8e6dc13b52142f4a54fd5::contribution::model_contribution", "track": "ml", "unit_id": "ml::T011", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2021", "methodology": [], "source_type": "paper", "text": "Section 6 presents the related work, and finally, in Section 7 we present the conclusions of our work.", "payload": {"paper_id": "ae17c900f9cd235f71d8e6dc13b52142f4a54fd5", "conference": "Science of Computer Programming", "year": 2021, "title": "Ranking programming languages by energy efficiency", "topic_id": "T011", "methods": [], "tasks": ["code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::ae17c900f9cd235f71d8e6dc13b52142f4a54fd5::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T011", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2021", "methodology": [], "source_type": "paper", "text": "The Remove-duplicates task, however, does not require the sorting of the resulting elements.", "payload": {"paper_id": "ae17c900f9cd235f71d8e6dc13b52142f4a54fd5", "conference": "Science of Computer Programming", "year": 2021, "title": "Ranking programming languages by energy efficiency", "topic_id": "T011", "methods": [], "tasks": ["code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::ae17c900f9cd235f71d8e6dc13b52142f4a54fd5::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T011", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2021", "methodology": [], "source_type": "paper", "text": "A remarkable outlier, however, is observed for the Chapel implementation: although it is very well ranked based on CLBG, it is the most inefficient language for this task!", "payload": {"paper_id": "ae17c900f9cd235f71d8e6dc13b52142f4a54fd5", "conference": "Science of Computer Programming", "year": 2021, "title": "Ranking programming languages by energy efficiency", "topic_id": "T011", "methods": [], "tasks": ["code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::ae17c900f9cd235f71d8e6dc13b52142f4a54fd5::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T011", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2021", "methodology": [], "source_type": "paper", "text": "In spite of our best effort in trying to understand this corner case, we believe it deserves a more detailed study of its own, that we leave for future reference, and ideally with the involvement of an expert of Chapel.", "payload": {"paper_id": "ae17c900f9cd235f71d8e6dc13b52142f4a54fd5", "conference": "Science of Computer Programming", "year": 2021, "title": "Ranking programming languages by energy efficiency", "topic_id": "T011", "methods": [], "tasks": ["code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::ae17c900f9cd235f71d8e6dc13b52142f4a54fd5::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T011", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2021", "methodology": [], "source_type": "paper", "text": "Thus, we are not searching for a particular result, and as such, this threat does not apply to our study.", "payload": {"paper_id": "ae17c900f9cd235f71d8e6dc13b52142f4a54fd5", "conference": "Science of Computer Programming", "year": 2021, "title": "Ranking programming languages by energy efficiency", "topic_id": "T011", "methods": [], "tasks": ["code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::ae17c900f9cd235f71d8e6dc13b52142f4a54fd5::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T011", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2021", "methodology": [], "source_type": "paper", "text": "However, the measured results are quite consistent, and thus reliable.", "payload": {"paper_id": "ae17c900f9cd235f71d8e6dc13b52142f4a54fd5", "conference": "Science of Computer Programming", "year": 2021, "title": "Ranking programming languages by energy efficiency", "topic_id": "T011", "methods": [], "tasks": ["code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::ae17c900f9cd235f71d8e6dc13b52142f4a54fd5::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T011", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2021", "methodology": [], "source_type": "paper", "text": "However, these are simple scripts used to call RAPL for measurement during the execution of programs.", "payload": {"paper_id": "ae17c900f9cd235f71d8e6dc13b52142f4a54fd5", "conference": "Science of Computer Programming", "year": 2021, "title": "Ranking programming languages by energy efficiency", "topic_id": "T011", "methods": [], "tasks": ["code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::ae17c900f9cd235f71d8e6dc13b52142f4a54fd5::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T011", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2021", "methodology": [], "source_type": "paper", "text": "However, both known to be very precise for measuring energy, time, and memory, thus their results are reliable.", "payload": {"paper_id": "ae17c900f9cd235f71d8e6dc13b52142f4a54fd5", "conference": "Science of Computer Programming", "year": 2021, "title": "Ranking programming languages by energy efficiency", "topic_id": "T011", "methods": [], "tasks": ["code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::ae17c900f9cd235f71d8e6dc13b52142f4a54fd5::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T011", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2021", "methodology": [], "source_type": "paper", "text": "However, we have used different and independent programs to evaluate the languages.", "payload": {"paper_id": "ae17c900f9cd235f71d8e6dc13b52142f4a54fd5", "conference": "Science of Computer Programming", "year": 2021, "title": "Ranking programming languages by energy efficiency", "topic_id": "T011", "methods": [], "tasks": ["code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::ae17c900f9cd235f71d8e6dc13b52142f4a54fd5::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T011", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2021", "methodology": [], "source_type": "paper", "text": "Overall however, the results seem to maintain their tendencies [17, 4] In general, in this category of threats it is paramount to report the characteristics of the experiment in order to understand its applicability to other contexts [41] .", "payload": {"paper_id": "ae17c900f9cd235f71d8e6dc13b52142f4a54fd5", "conference": "Science of Computer Programming", "year": 2021, "title": "Ranking programming languages by energy efficiency", "topic_id": "T011", "methods": [], "tasks": ["code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::ae17c900f9cd235f71d8e6dc13b52142f4a54fd5::future::scientific_future_work", "track": "ml", "unit_id": "ml::T011", "event_type": "future", "subtype": "scientific_future_work", "timestamp": "2021", "methodology": [], "source_type": "paper", "text": "In the following subsections, we will present an analysis and discussion on the results of our study.", "payload": {"paper_id": "ae17c900f9cd235f71d8e6dc13b52142f4a54fd5", "conference": "Science of Computer Programming", "year": 2021, "title": "Ranking programming languages by energy efficiency", "topic_id": "T011", "methods": [], "tasks": ["code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::ae17c900f9cd235f71d8e6dc13b52142f4a54fd5::future::scientific_future_work", "track": "ml", "unit_id": "ml::T011", "event_type": "future", "subtype": "scientific_future_work", "timestamp": "2021", "methodology": [], "source_type": "paper", "text": "While our main focus is on understanding the energy efficiency in languages, we will also try to understand how energy, time, and memory relate.", "payload": {"paper_id": "ae17c900f9cd235f71d8e6dc13b52142f4a54fd5", "conference": "Science of Computer Programming", "year": 2021, "title": "Ranking programming languages by energy efficiency", "topic_id": "T011", "methods": [], "tasks": ["code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::ae17c900f9cd235f71d8e6dc13b52142f4a54fd5::future::scientific_future_work", "track": "ml", "unit_id": "ml::T011", "event_type": "future", "subtype": "scientific_future_work", "timestamp": "2021", "methodology": [], "source_type": "paper", "text": "Additionally, in this section we will try to answer the following three research questions, each with their own designated subsection.", "payload": {"paper_id": "ae17c900f9cd235f71d8e6dc13b52142f4a54fd5", "conference": "Science of Computer Programming", "year": 2021, "title": "Ranking programming languages by energy efficiency", "topic_id": "T011", "methods": [], "tasks": ["code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::ae17c900f9cd235f71d8e6dc13b52142f4a54fd5::future::scientific_future_work", "track": "ml", "unit_id": "ml::T011", "event_type": "future", "subtype": "scientific_future_work", "timestamp": "2021", "methodology": [], "source_type": "paper", "text": "Thus we believe these results can be further generalized, and other researchers and industry can replicate our methodology for future work.", "payload": {"paper_id": "ae17c900f9cd235f71d8e6dc13b52142f4a54fd5", "conference": "Science of Computer Programming", "year": 2021, "title": "Ranking programming languages by energy efficiency", "topic_id": "T011", "methods": [], "tasks": ["code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T006::ea11192b7f351071f1efaf6ce37f47bc9af6dfb4::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T006", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2020", "methodology": [], "source_type": "paper", "text": "Beta oscillations, however, have become increasingly associated with online language processes 28 .", "payload": {"paper_id": "ea11192b7f351071f1efaf6ce37f47bc9af6dfb4", "conference": "Scientific Reports", "year": 2020, "title": "Relating Natural Language Aptitude to Individual Differences in Learning Programming Languages", "topic_id": "T006", "methods": [], "tasks": ["reasoning"], "datasets": [], "metrics": [{"name": "accuracy", "value": 50.1}]}}
{"event_id": "ml::T006::ea11192b7f351071f1efaf6ce37f47bc9af6dfb4::future::scientific_future_work", "track": "ml", "unit_id": "ml::T006", "event_type": "future", "subtype": "scientific_future_work", "timestamp": "2020", "methodology": [], "source_type": "paper", "text": "Important future work is needed to determine the extent to which our results will translate to classroom learning environments, to less \"user friendly\" languages such as Java that are more widely employed in software engineering spaces, and to higher programming proficiency levels.", "payload": {"paper_id": "ea11192b7f351071f1efaf6ce37f47bc9af6dfb4", "conference": "Scientific Reports", "year": 2020, "title": "Relating Natural Language Aptitude to Individual Differences in Learning Programming Languages", "topic_id": "T006", "methods": [], "tasks": ["reasoning"], "datasets": [], "metrics": [{"name": "accuracy", "value": 50.1}]}}
{"event_id": "ml::T010::6433b460bd25bfb60f153d8700364335ba3cd29c::contribution::model_contribution", "track": "ml", "unit_id": "ml::T010", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2021", "methodology": [], "source_type": "paper", "text": "We introduce a selected set of protocols inspired from the Soft Matter Physics community in order to validate Computer Graphics simulators of slender elastic structures possibly subject to dry frictional contact.", "payload": {"paper_id": "6433b460bd25bfb60f153d8700364335ba3cd29c", "conference": "ACM Transactions on Graphics", "year": 2021, "title": "Physical validation of simulators in computer graphics", "topic_id": "T010", "methods": [], "tasks": [], "datasets": [], "metrics": []}}
{"event_id": "ml::T006::85bfd320fd6aed25614d69d9cff71acf98d111be::contribution::model_contribution", "track": "ml", "unit_id": "ml::T006", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2020", "methodology": [], "source_type": "paper", "text": "Our contributions are twofold.", "payload": {"paper_id": "85bfd320fd6aed25614d69d9cff71acf98d111be", "conference": "ACM Transactions on Graphics", "year": 2020, "title": "Code replicability in computer graphics", "topic_id": "T006", "methods": [], "tasks": ["code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T006::85bfd320fd6aed25614d69d9cff71acf98d111be::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T006", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2020", "methodology": [], "source_type": "paper", "text": "As replicability scores are subjective, we first perform an analysis of variance (ANOVA), despite some limitations here (see Norman [2010] for a full discussion), aimed at determining two things: is there a dependence on the reviewer of the code on replicability scores?", "payload": {"paper_id": "85bfd320fd6aed25614d69d9cff71acf98d111be", "conference": "ACM Transactions on Graphics", "year": 2020, "title": "Code replicability in computer graphics", "topic_id": "T006", "methods": [], "tasks": ["code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T006::85bfd320fd6aed25614d69d9cff71acf98d111be::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T006", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2020", "methodology": [], "source_type": "paper", "text": "A limitation is that these scripts are only guaranteed to work at the time when the stamp is granted -a limitation shared by the present study.", "payload": {"paper_id": "85bfd320fd6aed25614d69d9cff71acf98d111be", "conference": "ACM Transactions on Graphics", "year": 2020, "title": "Code replicability in computer graphics", "topic_id": "T006", "methods": [], "tasks": ["code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T006::85bfd320fd6aed25614d69d9cff71acf98d111be::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T006", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2020", "methodology": [], "source_type": "paper", "text": "Our analysis has a number of limitations.", "payload": {"paper_id": "85bfd320fd6aed25614d69d9cff71acf98d111be", "conference": "ACM Transactions on Graphics", "year": 2020, "title": "Code replicability in computer graphics", "topic_id": "T006", "methods": [], "tasks": ["code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T006::85bfd320fd6aed25614d69d9cff71acf98d111be::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T006", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2020", "methodology": [], "source_type": "paper", "text": "Second, the codes we found and assessed may have evolved after the paper has been published, which we cannot control.", "payload": {"paper_id": "85bfd320fd6aed25614d69d9cff71acf98d111be", "conference": "ACM Transactions on Graphics", "year": 2020, "title": "Code replicability in computer graphics", "topic_id": "T006", "methods": [], "tasks": ["code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T006::85bfd320fd6aed25614d69d9cff71acf98d111be::future::scientific_future_work", "track": "ml", "unit_id": "ml::T006", "event_type": "future", "subtype": "scientific_future_work", "timestamp": "2020", "methodology": [], "source_type": "paper", "text": "It would be an interesting future work to compare replicability across computer graphics venues.", "payload": {"paper_id": "85bfd320fd6aed25614d69d9cff71acf98d111be", "conference": "ACM Transactions on Graphics", "year": 2020, "title": "Code replicability in computer graphics", "topic_id": "T006", "methods": [], "tasks": ["code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T010::4405d420721847d2adf2e0fc36f1cdfe7a286f20::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T010", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2020", "methodology": [], "source_type": "paper", "text": "However, this feature will change the mesh size of the model.", "payload": {"paper_id": "4405d420721847d2adf2e0fc36f1cdfe7a286f20", "conference": "Mixed Reality and Three-Dimensional Computer Graphics", "year": 2020, "title": "3D Modeling and Computer Graphics in Virtual Reality", "topic_id": "T010", "methods": [], "tasks": [], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::908dad62c0e43d80e3e3cb3c0402f7c71c70499c::contribution::model_contribution", "track": "ml", "unit_id": "ml::T011", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2023", "methodology": ["gpt_family"], "source_type": "paper", "text": "To enable using context beyond limited context windows, we propose virtual context management, a technique drawing inspiration from hierarchical memory systems in traditional operating systems that provide the appearance of large memory resources through data movement between fast and slow memory.", "payload": {"paper_id": "908dad62c0e43d80e3e3cb3c0402f7c71c70499c", "conference": "arXiv.org", "year": 2023, "title": "MemGPT: Towards LLMs as Operating Systems", "topic_id": "T011", "methods": ["gpt_family"], "tasks": ["reasoning", "code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::908dad62c0e43d80e3e3cb3c0402f7c71c70499c::contribution::model_contribution", "track": "ml", "unit_id": "ml::T011", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2023", "methodology": ["gpt_family"], "source_type": "paper", "text": "Using this technique, we introduce MemGPT (Memory-GPT), a system that intelligently manages different memory tiers in order to effectively provide extended context within the LLM's limited context window, and utilizes interrupts to manage control flow between itself and the user.", "payload": {"paper_id": "908dad62c0e43d80e3e3cb3c0402f7c71c70499c", "conference": "arXiv.org", "year": 2023, "title": "MemGPT: Towards LLMs as Operating Systems", "topic_id": "T011", "methods": ["gpt_family"], "tasks": ["reasoning", "code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::908dad62c0e43d80e3e3cb3c0402f7c71c70499c::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T011", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2023", "methodology": ["gpt_family"], "source_type": "paper", "text": "However many documents easily surpass these lengths; for example, legal or financial documents such as Annual Reports (SEC Form 10-K) can easily pass the million token mark.", "payload": {"paper_id": "908dad62c0e43d80e3e3cb3c0402f7c71c70499c", "conference": "arXiv.org", "year": 2023, "title": "MemGPT: Towards LLMs as Operating Systems", "topic_id": "T011", "methods": ["gpt_family"], "tasks": ["reasoning", "code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T013::3742fb44509913d3435cd5ade90be779c6389ea3::contribution::model_contribution", "track": "ml", "unit_id": "ml::T013", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2019", "methodology": [], "source_type": "paper", "text": "In this paper, we present brief overview of different IoT OSs, supported hardware, and future research directions.", "payload": {"paper_id": "3742fb44509913d3435cd5ade90be779c6389ea3", "conference": "Italian National Conference on Sensors", "year": 2019, "title": "Internet of Things (IoT) Operating Systems Management: Opportunities, Challenges, and Solution", "topic_id": "T013", "methods": [], "tasks": [], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::8dbd57469bb32e6d57f23f5e765bf1c9ac8e080c::contribution::model_contribution", "track": "ml", "unit_id": "ml::T011", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2023", "methodology": ["gpt_family", "prompting"], "source_type": "paper", "text": "We demonstrate that, beyond its mastery of language, GPT-4 can solve novel and difficult tasks that span mathematics, coding, vision, medicine, law, psychology and more, without needing any special prompting.", "payload": {"paper_id": "8dbd57469bb32e6d57f23f5e765bf1c9ac8e080c", "conference": "arXiv.org", "year": 2023, "title": "Sparks of Artificial General Intelligence: Early experiments with GPT-4", "topic_id": "T011", "methods": ["gpt_family", "prompting"], "tasks": [], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::530a059cb48477ad1e3d4f8f4b153274c8997332::contribution::model_contribution", "track": "ml", "unit_id": "ml::T011", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2019", "methodology": ["robustness"], "source_type": "paper", "text": "Grounded on a first elaboration of concepts and terms used in XAI-related research, we propose a novel definition of explainability that places audience (Figure 2 ) as a key aspect to be considered when explaining a ML model.", "payload": {"paper_id": "530a059cb48477ad1e3d4f8f4b153274c8997332", "conference": "Information Fusion", "year": 2019, "title": "Explainable Artificial Intelligence (XAI): Concepts, Taxonomies, Opportunities and Challenges toward Responsible AI", "topic_id": "T011", "methods": ["robustness"], "tasks": ["reasoning"], "datasets": [], "metrics": []}}
{"event_id": "ml::T011::5cde474869cb230a29b3ba0f6f685f5162b1a1a1::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T011", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2023", "methodology": ["privacy_dp"], "source_type": "paper", "text": "However, it is important to address limitations such as bias and lack of personalization to ensure equitable and effective use of AI.", "payload": {"paper_id": "5cde474869cb230a29b3ba0f6f685f5162b1a1a1", "conference": "BMC Medical Education", "year": 2023, "title": "Revolutionizing healthcare: the role of artificial intelligence in clinical practice", "topic_id": "T011", "methods": ["privacy_dp"], "tasks": ["mt", "sentiment", "generation", "reasoning"], "datasets": [], "metrics": []}}
{"event_id": "ml::T000::9faa2b0e5cb93f20df0555c3c350fab0b2eccf3a::contribution::model_contribution", "track": "ml", "unit_id": "ml::T000", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2023", "methodology": [], "source_type": "paper", "text": "We propose a new paradigm for medical AI, which we refer to as generalist medical AI (GMAI).", "payload": {"paper_id": "9faa2b0e5cb93f20df0555c3c350fab0b2eccf3a", "conference": "Nature", "year": 2023, "title": "Foundation models for generalist medical artificial intelligence", "topic_id": "T000", "methods": [], "tasks": ["reasoning"], "datasets": [], "metrics": []}}
{"event_id": "ml::T003::845b4941d8c016aa5f8967da2f86d38ef6c18fa3::contribution::model_contribution", "track": "ml", "unit_id": "ml::T003", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2020", "methodology": [], "source_type": "paper", "text": "We propose a full-view categorization and new taxonomies on these topics.", "payload": {"paper_id": "845b4941d8c016aa5f8967da2f86d38ef6c18fa3", "conference": "IEEE Transactions on Neural Networks and Learning Systems", "year": 2020, "title": "A Survey on Knowledge Graphs: Representation, Acquisition, and Applications", "topic_id": "T003", "methods": [], "tasks": ["reasoning"], "datasets": [], "metrics": []}}
{"event_id": "ml::T003::9e8b7b0d4c628c12b6a65ab56ac5f33a35eff2e6::contribution::model_contribution", "track": "ml", "unit_id": "ml::T003", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2023", "methodology": ["gpt_family"], "source_type": "paper", "text": "In this article, we present a forward-looking roadmap for the unification of LLMs and KGs.", "payload": {"paper_id": "9e8b7b0d4c628c12b6a65ab56ac5f33a35eff2e6", "conference": "IEEE Transactions on Knowledge and Data Engineering", "year": 2023, "title": "Unifying Large Language Models and Knowledge Graphs: A Roadmap", "topic_id": "T003", "methods": ["gpt_family"], "tasks": ["qa", "summarization", "mt", "generation", "reasoning", "code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T003::9e8b7b0d4c628c12b6a65ab56ac5f33a35eff2e6::contribution::model_contribution", "track": "ml", "unit_id": "ml::T003", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2023", "methodology": ["gpt_family"], "source_type": "paper", "text": "In this article, we present a forward-looking roadmap for unifying both LLMs and KGs, to leverage their respective strengths and overcome the limitations of each approach, for various downstream tasks.", "payload": {"paper_id": "9e8b7b0d4c628c12b6a65ab56ac5f33a35eff2e6", "conference": "IEEE Transactions on Knowledge and Data Engineering", "year": 2023, "title": "Unifying Large Language Models and Knowledge Graphs: A Roadmap", "topic_id": "T003", "methods": ["gpt_family"], "tasks": ["qa", "summarization", "mt", "generation", "reasoning", "code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T003::9e8b7b0d4c628c12b6a65ab56ac5f33a35eff2e6::contribution::model_contribution", "track": "ml", "unit_id": "ml::T003", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2023", "methodology": ["gpt_family"], "source_type": "paper", "text": "We propose detailed categorization, conduct comprehensive reviews, and pinpoint emerging directions in these fast-growing fields.", "payload": {"paper_id": "9e8b7b0d4c628c12b6a65ab56ac5f33a35eff2e6", "conference": "IEEE Transactions on Knowledge and Data Engineering", "year": 2023, "title": "Unifying Large Language Models and Knowledge Graphs: A Roadmap", "topic_id": "T003", "methods": ["gpt_family"], "tasks": ["qa", "summarization", "mt", "generation", "reasoning", "code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T003::9e8b7b0d4c628c12b6a65ab56ac5f33a35eff2e6::contribution::model_contribution", "track": "ml", "unit_id": "ml::T003", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2023", "methodology": ["gpt_family"], "source_type": "paper", "text": "We present a forward-looking roadmap for integrating LLMs and KGs.", "payload": {"paper_id": "9e8b7b0d4c628c12b6a65ab56ac5f33a35eff2e6", "conference": "IEEE Transactions on Knowledge and Data Engineering", "year": 2023, "title": "Unifying Large Language Models and Knowledge Graphs: A Roadmap", "topic_id": "T003", "methods": ["gpt_family"], "tasks": ["qa", "summarization", "mt", "generation", "reasoning", "code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T003::9e8b7b0d4c628c12b6a65ab56ac5f33a35eff2e6::contribution::model_contribution", "track": "ml", "unit_id": "ml::T003", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2023", "methodology": ["gpt_family"], "source_type": "paper", "text": "For each integration framework of our roadmap, we present a detailed categorization and novel taxonomies of research on unifying LLMs and KGs.", "payload": {"paper_id": "9e8b7b0d4c628c12b6a65ab56ac5f33a35eff2e6", "conference": "IEEE Transactions on Knowledge and Data Engineering", "year": 2023, "title": "Unifying Large Language Models and Knowledge Graphs: A Roadmap", "topic_id": "T003", "methods": ["gpt_family"], "tasks": ["qa", "summarization", "mt", "generation", "reasoning", "code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T003::9e8b7b0d4c628c12b6a65ab56ac5f33a35eff2e6::future::scientific_future_work", "track": "ml", "unit_id": "ml::T003", "event_type": "future", "subtype": "scientific_future_work", "timestamp": "2023", "methodology": ["gpt_family"], "source_type": "paper", "text": "In particular, we will anticipate increasing research on three stages: Stage 1: KG-enhanced LLMs, LLM-augmented KGs, Stage 2: Synergized LLMs + KGs, and Stage 3: Graph Structure Understanding, Multi-modality, Knowledge Updating.", "payload": {"paper_id": "9e8b7b0d4c628c12b6a65ab56ac5f33a35eff2e6", "conference": "IEEE Transactions on Knowledge and Data Engineering", "year": 2023, "title": "Unifying Large Language Models and Knowledge Graphs: A Roadmap", "topic_id": "T003", "methods": ["gpt_family"], "tasks": ["qa", "summarization", "mt", "generation", "reasoning", "code"], "datasets": [], "metrics": []}}
{"event_id": "ml::T004::b708e0f49d8e9708bc649debd9a9372748fffa3d::contribution::model_contribution", "track": "ml", "unit_id": "ml::T004", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2024", "methodology": ["rag"], "source_type": "paper", "text": "We introduce a novel customer service question-answering method that amalgamates RAG with a knowledge graph (KG).", "payload": {"paper_id": "b708e0f49d8e9708bc649debd9a9372748fffa3d", "conference": "Annual International ACM SIGIR Conference on Research and Development in Information Retrieval", "year": 2024, "title": "Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering", "topic_id": "T004", "methods": ["rag"], "tasks": ["summarization", "mt", "retrieval", "generation"], "datasets": [], "metrics": []}}
{"event_id": "ml::T003::3950df97ea527009a32569cb7016bc3df1383dca::contribution::model_contribution", "track": "ml", "unit_id": "ml::T003", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2021", "methodology": ["bert_family", "t5_family", "gnn"], "source_type": "paper", "text": "Here we propose a new model, QA-GNN, which addresses the above challenges through two key innovations: (i) relevance scoring, where we use LMs to estimate the importance of KG nodes relative to the given QA context, and (ii) joint reasoning, where we connect the QA context and KG to form a joint graph, and mutually update their representations through graph-based message passing.", "payload": {"paper_id": "3950df97ea527009a32569cb7016bc3df1383dca", "conference": "North American Chapter of the Association for Computational Linguistics", "year": 2021, "title": "QA-GNN: Reasoning with Language Models and Knowledge Graphs for Question Answering", "topic_id": "T003", "methods": ["bert_family", "t5_family", "gnn"], "tasks": ["qa", "reasoning"], "datasets": [], "metrics": []}}
{"event_id": "ml::T003::3950df97ea527009a32569cb7016bc3df1383dca::contribution::model_contribution", "track": "ml", "unit_id": "ml::T003", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2021", "methodology": ["bert_family", "t5_family", "gnn"], "source_type": "paper", "text": "Here we propose QA-GNN, an end-to-end LM+KG model for question answering that addresses the above two challenges.", "payload": {"paper_id": "3950df97ea527009a32569cb7016bc3df1383dca", "conference": "North American Chapter of the Association for Computational Linguistics", "year": 2021, "title": "QA-GNN: Reasoning with Language Models and Knowledge Graphs for Question Answering", "topic_id": "T003", "methods": ["bert_family", "t5_family", "gnn"], "tasks": ["qa", "reasoning"], "datasets": [], "metrics": []}}
{"event_id": "ml::T003::42b323b6df79e49c9bf5cee2a91398a7fa3d594d::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T003", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2023", "methodology": ["sparsity_moe", "gnn"], "source_type": "paper", "text": "Furthermore, we analyzed the limitations of current knowledge graph technologies, which lead to severe technical challenges.", "payload": {"paper_id": "42b323b6df79e49c9bf5cee2a91398a7fa3d594d", "conference": "Artificial Intelligence Review", "year": 2023, "title": "Knowledge Graphs: Opportunities and Challenges", "topic_id": "T003", "methods": ["sparsity_moe", "gnn"], "tasks": ["qa", "retrieval", "reasoning"], "datasets": [], "metrics": []}}
{"event_id": "ml::T003::fb00016c1e048b9373803add001c1ec7e877cb23::contribution::model_contribution", "track": "ml", "unit_id": "ml::T003", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2023", "methodology": ["gpt_family", "prompting", "robustness"], "source_type": "paper", "text": "Through a comprehensive evaluation of 16 publicly available LLMs, we show that existing LLMs are still far from being perfect in terms of their grasp of factual knowledge, especially for facts of torso-to-tail entities.", "payload": {"paper_id": "fb00016c1e048b9373803add001c1ec7e877cb23", "conference": "North American Chapter of the Association for Computational Linguistics", "year": 2023, "title": "Head-to-Tail: How Knowledgeable are Large Language Models (LLMs)? A.K.A. Will LLMs Replace Knowledge Graphs?", "topic_id": "T003", "methods": ["gpt_family", "prompting", "robustness"], "tasks": ["qa", "generation"], "datasets": [], "metrics": []}}
{"event_id": "ml::T003::fb00016c1e048b9373803add001c1ec7e877cb23::contribution::model_contribution", "track": "ml", "unit_id": "ml::T003", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2023", "methodology": ["gpt_family", "prompting", "robustness"], "source_type": "paper", "text": "Our main contributions are as follows: (i) We introduce Head-to-Tail, the first benchmark focused on comprehensively assessing the effectiveness of LLMs in incorporating factual knowledge encompassing the head, torso, and tail portions of knowledge graphs (Section 2.1).", "payload": {"paper_id": "fb00016c1e048b9373803add001c1ec7e877cb23", "conference": "North American Chapter of the Association for Computational Linguistics", "year": 2023, "title": "Head-to-Tail: How Knowledgeable are Large Language Models (LLMs)? A.K.A. Will LLMs Replace Knowledge Graphs?", "topic_id": "T003", "methods": ["gpt_family", "prompting", "robustness"], "tasks": ["qa", "generation"], "datasets": [], "metrics": []}}
{"event_id": "ml::T003::fb00016c1e048b9373803add001c1ec7e877cb23::contribution::model_contribution", "track": "ml", "unit_id": "ml::T003", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2023", "methodology": ["gpt_family", "prompting", "robustness"], "source_type": "paper", "text": "(ii) We present an evaluation methodology accompanied by metrics designed to assess the factuality of LLMs.", "payload": {"paper_id": "fb00016c1e048b9373803add001c1ec7e877cb23", "conference": "North American Chapter of the Association for Computational Linguistics", "year": 2023, "title": "Head-to-Tail: How Knowledgeable are Large Language Models (LLMs)? A.K.A. Will LLMs Replace Knowledge Graphs?", "topic_id": "T003", "methods": ["gpt_family", "prompting", "robustness"], "tasks": ["qa", "generation"], "datasets": [], "metrics": []}}
{"event_id": "ml::T003::fb00016c1e048b9373803add001c1ec7e877cb23::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T003", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2023", "methodology": ["gpt_family", "prompting", "robustness"], "source_type": "paper", "text": "Our work does not discuss the effectiveness of LLMs in capturing taxonomy or type hierarchies, which could be an extension of this study.", "payload": {"paper_id": "fb00016c1e048b9373803add001c1ec7e877cb23", "conference": "North American Chapter of the Association for Computational Linguistics", "year": 2023, "title": "Head-to-Tail: How Knowledgeable are Large Language Models (LLMs)? A.K.A. Will LLMs Replace Knowledge Graphs?", "topic_id": "T003", "methods": ["gpt_family", "prompting", "robustness"], "tasks": ["qa", "generation"], "datasets": [], "metrics": []}}
{"event_id": "ml::T003::fb00016c1e048b9373803add001c1ec7e877cb23::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T003", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2023", "methodology": ["gpt_family", "prompting", "robustness"], "source_type": "paper", "text": "However, this approach does not assess the model's robustness to paraphrasing or consider the diverse ways models can be queried, such as entailment or cloze-style prompts.", "payload": {"paper_id": "fb00016c1e048b9373803add001c1ec7e877cb23", "conference": "North American Chapter of the Association for Computational Linguistics", "year": 2023, "title": "Head-to-Tail: How Knowledgeable are Large Language Models (LLMs)? A.K.A. Will LLMs Replace Knowledge Graphs?", "topic_id": "T003", "methods": ["gpt_family", "prompting", "robustness"], "tasks": ["qa", "generation"], "datasets": [], "metrics": []}}
{"event_id": "ml::T003::fb00016c1e048b9373803add001c1ec7e877cb23::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T003", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2023", "methodology": ["gpt_family", "prompting", "robustness"], "source_type": "paper", "text": "Our supplementary experiment in Appendix A.5 suggests that varying the form of questions does not significantly impact the evaluation results.", "payload": {"paper_id": "fb00016c1e048b9373803add001c1ec7e877cb23", "conference": "North American Chapter of the Association for Computational Linguistics", "year": 2023, "title": "Head-to-Tail: How Knowledgeable are Large Language Models (LLMs)? A.K.A. Will LLMs Replace Knowledge Graphs?", "topic_id": "T003", "methods": ["gpt_family", "prompting", "robustness"], "tasks": ["qa", "generation"], "datasets": [], "metrics": []}}
{"event_id": "ml::T003::fb00016c1e048b9373803add001c1ec7e877cb23::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T003", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2023", "methodology": ["gpt_family", "prompting", "robustness"], "source_type": "paper", "text": "Our evaluation shows that even the most advanced LLMs have notable limitations in representing factual knowledge, particularly for the torso and tail entities.", "payload": {"paper_id": "fb00016c1e048b9373803add001c1ec7e877cb23", "conference": "North American Chapter of the Association for Computational Linguistics", "year": 2023, "title": "Head-to-Tail: How Knowledgeable are Large Language Models (LLMs)? A.K.A. Will LLMs Replace Knowledge Graphs?", "topic_id": "T003", "methods": ["gpt_family", "prompting", "robustness"], "tasks": ["qa", "generation"], "datasets": [], "metrics": []}}
{"event_id": "ml::T003::02033e83ff310f35e4623bd339982c52d926f2d5::contribution::model_contribution", "track": "ml", "unit_id": "ml::T003", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2023", "methodology": ["gpt_family"], "source_type": "paper", "text": "Therefore, to address questions of whether constructing KGs is still necessary and how to improve the knowledge modeling ability of LLMs, we present a systematic review of relevant studies.", "payload": {"paper_id": "02033e83ff310f35e4623bd339982c52d926f2d5", "conference": "IEEE Transactions on Knowledge and Data Engineering", "year": 2023, "title": "Give us the Facts: Enhancing Large Language Models With Knowledge Graphs for Fact-Aware Language Modeling", "topic_id": "T003", "methods": ["gpt_family"], "tasks": ["summarization", "ner", "sentiment", "dialogue", "generation", "reasoning"], "datasets": [], "metrics": []}}
{"event_id": "ml::T003::02033e83ff310f35e4623bd339982c52d926f2d5::contribution::model_contribution", "track": "ml", "unit_id": "ml::T003", "event_type": "contribution", "subtype": "model_contribution", "timestamp": "2023", "methodology": ["gpt_family"], "source_type": "paper", "text": "‚Ä¢ We propose to enhance LLMs with KGs and suggest some possible future research directions, which may benefit researchers in the field of LLM.", "payload": {"paper_id": "02033e83ff310f35e4623bd339982c52d926f2d5", "conference": "IEEE Transactions on Knowledge and Data Engineering", "year": 2023, "title": "Give us the Facts: Enhancing Large Language Models With Knowledge Graphs for Fact-Aware Language Modeling", "topic_id": "T003", "methods": ["gpt_family"], "tasks": ["summarization", "ner", "sentiment", "dialogue", "generation", "reasoning"], "datasets": [], "metrics": []}}
{"event_id": "ml::T003::02033e83ff310f35e4623bd339982c52d926f2d5::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T003", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2023", "methodology": ["gpt_family"], "source_type": "paper", "text": "However, they cannot fundamentally improve LLMs' knowledge modeling ability since they do not change LLMs' parameters.", "payload": {"paper_id": "02033e83ff310f35e4623bd339982c52d926f2d5", "conference": "IEEE Transactions on Knowledge and Data Engineering", "year": 2023, "title": "Give us the Facts: Enhancing Large Language Models With Knowledge Graphs for Fact-Aware Language Modeling", "topic_id": "T003", "methods": ["gpt_family"], "tasks": ["summarization", "ner", "sentiment", "dialogue", "generation", "reasoning"], "datasets": [], "metrics": []}}
{"event_id": "ml::T003::02033e83ff310f35e4623bd339982c52d926f2d5::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T003", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2023", "methodology": ["gpt_family"], "source_type": "paper", "text": "However, the scaling law of KGLLMs may differ from that of plain LLMs.", "payload": {"paper_id": "02033e83ff310f35e4623bd339982c52d926f2d5", "conference": "IEEE Transactions on Knowledge and Data Engineering", "year": 2023, "title": "Give us the Facts: Enhancing Large Language Models With Knowledge Graphs for Fact-Aware Language Modeling", "topic_id": "T003", "methods": ["gpt_family"], "tasks": ["summarization", "ner", "sentiment", "dialogue", "generation", "reasoning"], "datasets": [], "metrics": []}}
{"event_id": "ml::T003::02033e83ff310f35e4623bd339982c52d926f2d5::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T003", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2023", "methodology": ["gpt_family"], "source_type": "paper", "text": "However, there exist multimodal and temporal KGs that contain multimodal and temporal knowledge.", "payload": {"paper_id": "02033e83ff310f35e4623bd339982c52d926f2d5", "conference": "IEEE Transactions on Knowledge and Data Engineering", "year": 2023, "title": "Give us the Facts: Enhancing Large Language Models With Knowledge Graphs for Fact-Aware Language Modeling", "topic_id": "T003", "methods": ["gpt_family"], "tasks": ["summarization", "ner", "sentiment", "dialogue", "generation", "reasoning"], "datasets": [], "metrics": []}}
{"event_id": "ml::T003::02033e83ff310f35e4623bd339982c52d926f2d5::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T003", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2023", "methodology": ["gpt_family"], "source_type": "paper", "text": "However, each method has its own set of advantages and disadvantages, with some performing well on particular tasks but underperforming on others.", "payload": {"paper_id": "02033e83ff310f35e4623bd339982c52d926f2d5", "conference": "IEEE Transactions on Knowledge and Data Engineering", "year": 2023, "title": "Give us the Facts: Enhancing Large Language Models With Knowledge Graphs for Fact-Aware Language Modeling", "topic_id": "T003", "methods": ["gpt_family"], "tasks": ["summarization", "ner", "sentiment", "dialogue", "generation", "reasoning"], "datasets": [], "metrics": []}}
{"event_id": "ml::T003::02033e83ff310f35e4623bd339982c52d926f2d5::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T003", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2023", "methodology": ["gpt_family"], "source_type": "paper", "text": "However, they found that the most commonly used metrics do not consistently align with human evaluations concerning the accuracy of explanations, incorporation of common knowledge, and grammatical and labeling correctness.", "payload": {"paper_id": "02033e83ff310f35e4623bd339982c52d926f2d5", "conference": "IEEE Transactions on Knowledge and Data Engineering", "year": 2023, "title": "Give us the Facts: Enhancing Large Language Models With Knowledge Graphs for Fact-Aware Language Modeling", "topic_id": "T003", "methods": ["gpt_family"], "tasks": ["summarization", "ner", "sentiment", "dialogue", "generation", "reasoning"], "datasets": [], "metrics": []}}
{"event_id": "ml::T003::02033e83ff310f35e4623bd339982c52d926f2d5::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T003", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2023", "methodology": ["gpt_family"], "source_type": "paper", "text": "However, the rise of artificial intelligence for science will lead to an increasing demand for domain-specific KGLLMs.", "payload": {"paper_id": "02033e83ff310f35e4623bd339982c52d926f2d5", "conference": "IEEE Transactions on Knowledge and Data Engineering", "year": 2023, "title": "Give us the Facts: Enhancing Large Language Models With Knowledge Graphs for Fact-Aware Language Modeling", "topic_id": "T003", "methods": ["gpt_family"], "tasks": ["summarization", "ner", "sentiment", "dialogue", "generation", "reasoning"], "datasets": [], "metrics": []}}
{"event_id": "ml::T003::02033e83ff310f35e4623bd339982c52d926f2d5::gap::evaluation_gap", "track": "ml", "unit_id": "ml::T003", "event_type": "gap", "subtype": "evaluation_gap", "timestamp": "2023", "methodology": ["gpt_family"], "source_type": "paper", "text": "However, LLMs still fall short in recalling and correctly using factual knowledge while generating knowledge-grounded text.", "payload": {"paper_id": "02033e83ff310f35e4623bd339982c52d926f2d5", "conference": "IEEE Transactions on Knowledge and Data Engineering", "year": 2023, "title": "Give us the Facts: Enhancing Large Language Models With Knowledge Graphs for Fact-Aware Language Modeling", "topic_id": "T003", "methods": ["gpt_family"], "tasks": ["summarization", "ner", "sentiment", "dialogue", "generation", "reasoning"], "datasets": [], "metrics": []}}
{"event_id": "ml::T003::02033e83ff310f35e4623bd339982c52d926f2d5::future::scientific_future_work", "track": "ml", "unit_id": "ml::T003", "event_type": "future", "subtype": "scientific_future_work", "timestamp": "2023", "methodology": ["gpt_family"], "source_type": "paper", "text": "Further research is required on the selection of valuable knowledge and avoiding catastrophic forgetting when faced with vast and clashing knowledge.", "payload": {"paper_id": "02033e83ff310f35e4623bd339982c52d926f2d5", "conference": "IEEE Transactions on Knowledge and Data Engineering", "year": 2023, "title": "Give us the Facts: Enhancing Large Language Models With Knowledge Graphs for Fact-Aware Language Modeling", "topic_id": "T003", "methods": ["gpt_family"], "tasks": ["summarization", "ner", "sentiment", "dialogue", "generation", "reasoning"], "datasets": [], "metrics": []}}
